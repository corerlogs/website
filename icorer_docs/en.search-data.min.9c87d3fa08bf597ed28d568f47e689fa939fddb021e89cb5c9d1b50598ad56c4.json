[{"id":0,"href":"/icorer_docs/doccenter/redishub/module_test/2.1/","title":"2.1 NetHandle组件测试","section":"系统模块测试","content":" NetHandle # This is a library for building high-performance TCP server applications, standing on the shoulders of Go giants and redcon\n1. Features # High performance, low resource consumption Very easy to use development interface 2. Install # go get -u uriModule/NetHandle\n3. Performance Testing: # 3.1 50*10000 (50 threads X 10000 requests) # 3.2 50*20000 (50 threads X 20000 requests) # 3.3 100*10000 (100 threads X 10000 requests) # "},{"id":1,"href":"/icorer_docs/doccenter/pulseflow/pulgin_designed/2.1/","title":"2.1 扩展总览","section":"PulseFlow插件端","content":" NetHandle # This is a library for building high-performance TCP server applications, standing on the shoulders of Go giants and redcon\n1. Features # High performance, low resource consumption Very easy to use development interface 2. Install # go get -u uriModule/NetHandle\n3. Performance Testing: # 3.1 50*10000 (50 threads X 10000 requests) # 3.2 50*20000 (50 threads X 20000 requests) # 3.3 100*10000 (100 threads X 10000 requests) # "},{"id":2,"href":"/icorer_docs/doccenter/pulseflow/plugin_backend/3.1/","title":"3.1 后台总览","section":"PulseFlow后台端","content":"PulseFLow还有一部分功能是集中在信息后端的，当PHP引擎发送信息给后端程序后，后端程序再把信息进行组装，发给下一级程序。\n一 . 组成部分 # 后端程序，分为以下几个部分：\n配置中心：（配置文件 + 配置解析器）（采用ini文件配置格式）。\n进程管理器：维持进程池，保持进程池的存活量。\n信息发送： 信息组装 + 信息发送（UDP发送）\n二. 工作流程 # 2.1 总体流程图 # 2.2 系统模型（进程池模型） # 后端组件采用进程池模型，主程序启动时，首先读取配置文件中关于进程池大小的配置选项，然后启动相关数量的子工作进程。\n随后主进程进入稳定性极高的进程池监控流程，如果拦截到子进程有挂掉的情况发生，读取挂掉的状态并在相应的进程池位置开辟新的工作子进程。\n通过进程池可以大大提高进程读取内核消息队列的效率，通过进程池管理程序可以大大提高整体后端程序的稳定性。\n2.3 功能分配 # 1. 主进程负责【管理进程池】，负责【创建可用的内核消息队列】。 # 2. 工作子进程负责 【监控内核消息队列】\u0026mdash;\u0026gt;【读取消息】\u0026mdash;\u0026gt;【组装信息】\u0026mdash;\u0026gt;【UDP发送下游】 # "},{"id":3,"href":"/icorer_docs/doccenter/redishub/deploy/3.1/","title":"3.1 部署文档","section":"中间件部署","content":" 一. 系统设计 # 1.1 背景描述 # Redis单实例模式下，出现了机器存储过高,因此进行单实例向集群化的改造，但是由于存在以下两种原因，造成需要自研中间件：\nRedis标准集群不支持跨数据槽的MGET、MSET指令。 PHP生态缺乏并发支持，造成在M指令上性能很差。 最终我们设计RedisHub集群中间件，一方面用它来支持跨数据槽的MSET、MGET指令，一方面借助它的并发优势为PHP底层的M指令指令提高性能。\n1.2 总体设计 # 中间件的总体结构设计图如下所示:\n1.3 设计阐述 # 如图所示，PHP通过Unix Domain Socket途径和中间件进行IPC通信，然后中间件把PHP的redis请求进行处理，并转发到下游的Redis集群中，为PHP业务系统提供无缝的单实例到集群的改造，相关的网络模型如下：\n二. 组件部署文档 # RedisHub中间件 部署主要分为两个部分, 安装相关安装包 和 修改配置并运行.\n2.1 部署准备 # Linux 64bit 操作系统 RedisHub 二进制文件 调整Redishub配置文件：rh_config.yaml RedisHub进程监控工具 ,例如Supervisor 2.2 应用体安装 # 2.2.1 程序体运行 # 由于中间件是个可以方便运行的二进制体，但是我们在运行的时候需要制定配置文件路径，例如以下命令：\n./RedisHub -c /home/corerman/DATA/ICODE/GoLang/RedisHub/config/rh_config.yaml\n具体运行参数，运维伙伴可以自行调整。\n三. 配置文件详解 # 配置文件（rh_config.yaml）是这个系统运行的基础，所以这里将讲解配置文件的相关信息.\n#RedisHub YAML config file #RedisHub Net Config net: listen_uri: unix:/tmp/redis.sock #Unix Domain Socket的监听路径：PHP推荐使用这种模式 #listen_uri: tcp:10.100.183.180:16379 #TCP的监控IP及端口 #RedisHub cluster Config cluster: start_nodes: 10.54.2.8:9736,10.54.2.9:9736,10.54.2.10:9736 #Redis集群的节点，这里可以根据线上实际情况进行配置，多个只是为了保障高可用 conn_timeout: 50 #Redis节点的TCP连接超时时间 （单位：毫秒） conn_read_timeout: 50 #Redis节点的TCP读取超时时间 （单位：毫秒） conn_write_timeout: 50 #Redis节点的TCP写入超时时间 （单位：毫秒） conn_alive_timeout: 60 #Redis节点的TCP最大空闲时间 （单位：秒） conn_pool_size: 150 #针对每一个Redis集群节点的TCP连接池最大值 （单位：个） #RedisHub api config api: http_listen_address: #RedisHub log config # log 相关配置 log: # 日否开启日志 enable: true #是否开启日志功能（true 或 false） # 日志输出位置，支持std(终端) kafka # 注：std仅在调试时使用 output: \u0026#34;kafka\u0026#34; # kafka server的地址 需要修改到指定环境的kafka kafka_address: [\u0026#34;192.168.205.10:9092\u0026#34;, \u0026#34;192.168.205.11:9092\u0026#34;, \u0026#34;192.168.205.12:9092\u0026#34;] kafka_info_topic: \u0026#34;ltlog-info\u0026#34; kafka_error_topic: \u0026#34;ltlog-error\u0026#34; # 日志输出级别控制, 可省略, 默认输出到 error 级别 # 高级别的可以输出低级别的日志， 级别 trace \u0026gt; debug \u0026gt; error \u0026gt; warning \u0026gt; info # 例如 level = error时，不可输出trace和debug级别的日志 level: \u0026#34;error\u0026#34; # 日志中是否报告函数调用信息,可省略 默认为false report_call: false # 机器ip，可为空，默认自动查找 ip: \u0026#34;\u0026#34; # 机器hostname，可为空，默认自动查找 hostname: \u0026#34;\u0026#34; # app_name 默认为 RedisHub app_name: \u0026#34;RedisHub\u0026#34; # 周期上报redis执行信息 （当前是数量） heartbeat_report_second: 120 四 . 稳定性保障方案 # 4.1 进程稳定保障 # RedisHub中间件采用多线程-协程-多核编程,有很好的并发处理能力,经过较为严格的测试没出现过崩溃情况,但是对操作系统目前指抛出一个进程,为了保障RedisHub的运行稳定性 , 所以需要给予配置一个进程监控程序,可以使用Supervisor .\n4.2 更新配置 # 目前仅能通过修改配置文件来更新配置文件,如果需要更新配置,执行的操作有以下两步:\n更新配置文件 重启应用体 五. 运行校验 # 可以通过redis-cli工具连接redisHub中间件，然后测试set\\get\\mset\\mget指令的运行状况，从而判断中间件的运行状况。\n"},{"id":4,"href":"/icorer_docs/doccenter/redishub/system_access/4.1/","title":"4.1 phpredis对接redishub","section":"系统接入","content":" phpredis 对接 RedisHub 改造方案 # 一、背景描述 # phpredis进行Redis集群化改造，对接 RedisHub 中间件，并调整phpredis底层，增加业务降级逻辑。\n二、改造方案 # 2.1、Agent 连接 # 由于 RedisHub 采用 UNIX domain连接，本地部署 Agent 的方式，不存在 port端口，故 redis连接时，无法再传递该参数，需要去掉，具体连接代码如下\npublic function __construct($config, $prefix = \u0026#39;prefix:\u0026#39;) { $this-\u0026gt;prefixH = $prefix; $this-\u0026gt;redisconf = $config; $this-\u0026gt;redis = new \\Redis(); try { $this-\u0026gt;redis-\u0026gt;connect($this-\u0026gt;redisconf[\u0026#39;host\u0026#39;]); } catch (\\Exception $exception) { Logger::getInstance()-\u0026gt;error(\u0026#39;Redis agent connect error, \u0026#39; . $exception-\u0026gt;getMessage() . \u0026#39;, \u0026#39; . $this-\u0026gt;redisconf[\u0026#39;host\u0026#39;]); try { //redis集群中间件服务不可用，降级 $this-\u0026gt;redis = new \\RedisCluster(null, $this-\u0026gt;redisconf[\u0026#39;cluster\u0026#39;][\u0026#39;node\u0026#39;], $this-\u0026gt;redisconf[\u0026#39;cluster\u0026#39;][\u0026#39;timeout\u0026#39;], $this-\u0026gt;redisconf[\u0026#39;cluster\u0026#39;][\u0026#39;readTimeout\u0026#39;], $this-\u0026gt;redisconf[\u0026#39;cluster\u0026#39;][\u0026#39;persistent\u0026#39;]); } catch (\\Exception $exception) { Logger::getInstance()-\u0026gt;error(\u0026#39;RedisCluster connect error, \u0026#39; . $exception-\u0026gt;getMessage()); } } $this-\u0026gt;redis-\u0026gt;setOption(\\Redis::OPT_PREFIX, $prefix); } 我们可以看到，原先的连接方式几乎没有改动，只是去掉了port参数\n2.2、降级方案 # 针对 Agent可能产生异常的情形，我们做了降级方案，代码如上。当检测到连接异常时，采用 PHPRedis原生的集群方案，并发送错误日志，此降级对业务是无感知的\n三、过多 KEY 分片 # 为了避免 mget操作大数量级的 key，造成性能的下降，针对超过 200（可自定义）数量级的 key进行分片操作，代码如下\npublic function getMultiple($keys) { try { if (count($keys) \u0026gt; self::CHUNK_SIZE) { $data = array(); try { //针对200key以上分片读取 foreach (array_chunk($keys, self::CHUNK_SIZE) as $val) { $data = array_merge($data, $this-\u0026gt;redis-\u0026gt;mget($val)); } return $data; } catch (\\Exception $exception) { Logger::getInstance()-\u0026gt;warn(\u0026#39;redis getMultiple(mget) error, error message : \u0026#39; . $exception-\u0026gt;getMessage()); return false; } } return $this-\u0026gt;redis-\u0026gt;mget($keys); } catch (\\Exception $ex) { if (strpos($ex-\u0026gt;getMessage(), \u0026#39;protocol error\u0026#39;) !== false) { Logger::getInstance()-\u0026gt;warn(\u0026#39;protocol error : php redis getMultiple(mget) error, the key is \u0026#39; . implode($keys) . \u0026#39;. error message : \u0026#39; . $ex-\u0026gt;getMessage()); $this-\u0026gt;repconnect(); } return false; } } 我们定义了一个常量 CHUNK_SIZE，设置为 200，当 key数量大于 200 时，进行分片，每 200 key为单位，分批请求，再将结果进行合并返回，一旦中间出现任何错误，函数终止，返回 false\n四、配置文件 # 业务框架需要配合修改redis.php配置文件,deom 如下\n\u0026lt;?php // phpredis配置文件 return [ \u0026#39;cache\u0026#39; =\u0026gt; [ \u0026#39;host\u0026#39; =\u0026gt; \u0026#39;/tmp/redis.sock\u0026#39;, \u0026#39;port\u0026#39; =\u0026gt; \u0026#39;16379\u0026#39;, \u0026#39;cluster\u0026#39; =\u0026gt; [ \u0026#39;node\u0026#39; =\u0026gt; [ \u0026#39;node1\u0026#39;, \u0026#39;node2\u0026#39;, \u0026#39;node3\u0026#39;, \u0026#39;node4\u0026#39; ], \u0026#39;timeout\u0026#39; =\u0026gt; 1.5, \u0026#39;readTimeout\u0026#39; =\u0026gt; 1.5, \u0026#39;persistent\u0026#39; =\u0026gt; true ] ], \u0026#39;log\u0026#39; =\u0026gt; [ \u0026#39;host\u0026#39; =\u0026gt; \u0026#39;127.0.0.1\u0026#39;, \u0026#39;port\u0026#39; =\u0026gt; \u0026#39;6379\u0026#39; ], ]; host为Agent的UNIX domain文件地址\nport 可以不填\n新增 cluster 节点，node 为集群地址，timeout 为集群连接超时时间，readTimeout 为读取超时时间，persistent 为长连接参数\n以上参数请根据线上环境自行填写\n五、注意 # 5.1、为了应对降级方案，在使用 RedisCluster 对象的时候，目前线上版本的 PHPRdis为 5.0.0，此版本在集群模式下会有导致 php-fpm 进程崩溃的风险，需要升级到 5.0.2\n5.2、为了提升原生 RedisCluster 的性能，需要在 php.ini 文件中加上 redis.clusters.cache_slots = 1\n"},{"id":5,"href":"/icorer_docs/doccenter/pulseflow/run_status/4.1/","title":"4.1 运行跟踪报告","section":"运行情况","content":" 经过2018年9月26日下午两点 到 2018年9月27日 上午 九点半 线上运行，主要针对以下几个方面做第一期运行报告总结。 # 一. PulseFlow_IPC_Backend 后台进程池稳定性 # 1.1后台进程池截图： # 进程状态正常，没有僵尸或异常进程存在，观察 进程 PID可发现，所有进程均为最初创建的进程池内的进程，代表每个进程一直在正常运行，没有出现过异常退出。 # 二. 内核消息队列状态 # ipcs 通过观察，可以发现内核消息队列 无任何 数据积压，所有的数据均转发下游服务，内核队列数量安全，内核队列吞吐满足当前线上环境。 # 三. UDP 系统状态 # 3.1 UDP系统连接情况： # netstat -au\n通过观察，UDP连接数稳定，系统内部没有PulseFlow所残留的连接 ，没有对系统 UDP 环境进行任何损坏。 # 3.2 UDP 数据包缓冲区情况 # netstat -anus 由于线上这台机器的系统是 基于 centos6 ，内核版本较低，没有看到我关注的udp s ， 从上图没有看到异常情况end buffer errors情况 ， 从上图没有看到异常情况 # 四. php-fpm 运行状态 # 从上图可以观察出扩展上线后，自2018年9月27日凌晨6点03分起 ，至今总共处理过将近500万个请求，没有造成过量慢请求，php-fpm进程池稳定运行，扩展没有对php-fpm进程造成不良影响。 # "},{"id":6,"href":"/icorer_docs/doccenter/ak-2019/designs/overview/","title":"OverView","section":"系统设计","content":" OverView # "},{"id":7,"href":"/icorer_docs/doccenter/logdarts/designs/overview/","title":"OverView","section":"风险分析","content":" OverView # "},{"id":8,"href":"/icorer_docs/doccenter/pulseflow/overviews/overview/","title":"OverView","section":"PulseFlow概览","content":" OverView # "},{"id":9,"href":"/icorer_docs/doccenter/redishub/designs/overview/","title":"OverView","section":"系统设计","content":" OverView # "},{"id":10,"href":"/icorer_docs/doccenter/redistun/designs/overview/","title":"OverView","section":"系统设计","content":" OverView # "},{"id":11,"href":"/icorer_docs/doccenter/redishub/","title":"RedisHub","section":"项目总览","content":"RedisHub 是一款Redis集群中间件，帮助PHP环境平滑迁移Redis集群模式，通过中间件可以解耦业务代码和redis集群之间的关系，降低开发人员对于redis集群的理解心智。中间件实现高性能网络通信、RESP协议与Redis集群协议解析，实现集群模式下的MSET/MGET指令跨槽及并发流水吞吐，为PHP请求远程Redis集群提供更高的性能及稳定性。\n一. 总体设计 # RedisHub在组件设计上分为以下几部分:\nAgent配置解析器：负责对于配置文件进行解析（后续增加统一配置中心的支持） 通信组件: 包括UNIX本地监听组 和 远端Redis集群TCP长连接及连接池。 协议分析器: 提供稳定的Redis协议解析及组装功能组件。 协议拦截器: 主要对某些Redis命令进行拦截,调用协议插件组进行功能扩展. 协议插件组: 为协议分析器添加一系列插件,对通信进行优化和功能扩展，例如集群的mset、mget、del操作。 容灾器: 为Agent运行提供必要的安全保障,主要包括进程资源监控,迭代更新监控. 具体的组件总体架构如下图: 二. 网络代理设计 # RedisHub很重要的是网络代理部分,在网络代理方面由三部分组成.\n第一部分是对远程redis集群的连接池. 第二部分是对本地众多php-fpm客户端的UNIX请求连接管理. 第三部分是对这三端之间redis通信协议进行兼容. "},{"id":12,"href":"/icorer_docs/doccenter/pulseflow/overviews/1.1/","title":"1.1 安装文档","section":"PulseFlow概览","content":" PulseFlow 组件安装文档 # 一. 系统介绍 # 随着公司PHP项目体的不断增大，随着不同工程师的功能迭代，如何有效获取PHP项目的执行性能，对于系统整体模块显得异常重要，PulseFlow是一个公司团队内部自研地性能跟踪扩展，它可以在程序员无感知的情况下有效跟踪每一个函数的执行效率，主要分析CPU时间消耗、内存大小消耗，执行次数这三个指标，下面我们将从 PHP生命期 到 组件设计 到 性能优化这三个方面来进行阐述组件。\n二 . PulseFLow 扩展端架构 # 2.1 功能架构 # 2.2 流程架构 # 三 . PulseFLow 后端程序架构 # 3.1 后端程序流程 # 后台数据转发程序，它负责从信息通道里读取PHP扩展写入的信息，并转发给相应的下一级程序，相关流程图如下。\n3.2 后端总体架构 # 四. 系统安装手册 # （请一定按照顺序操作）\n下面是详细的安装文档，目的是让阅读者能够顺利编译安装PulseFLow扩展。\n4.1. 环境准备 # Centos 7系统\nPHP 7.0 版本以上\n4.2. 内核参数调整（编辑 /etc/sysctl.conf 文件） # 扩展依赖UDP数据包发送 和 Linux 内核消息队列，所以需要调整以下两方面参数。\n特殊说明：配置完毕后 采用 sudo sysctl -p生效\n4.2.1 调整UDP发送缓冲区大小 # 为了减少UDP发送丢包，因此调大UDP数据包发送缓冲区，经过实验，分配256MB就可以足够。配置选项如下\nnet.core.wmem_max = 268435456\n4.2.2 调整Linux内核消息队列大小 # 由于默认的Linux对于内核消息队列的相关参数普遍很小，不能满足程序运行需要，因此需要进行相关参数调整：\nkernel.msgmni = 10240\nkernel.msgmax = 120000\nkernel.msgmnb = 1228800000\n第一个代表调大Linux系统允许的最大消息队列数量，第二个代表调大系统允许的每条内核消息大小，第三个代表调大操作系统允许的内核消息队列总共大小。\n特殊说明：配置完毕后 采用 sudo sysctl -p生效\n4.3. 编译插件 # 4.3.1. 克隆代码 # git clone http://gitlab.shein.com:8088/NineWorlds/PulseFlow.git 4.3.2. 编译安装 # phpize ./configure // 这行可能需要配置 --with-php-config=php-config文件路径 make sudo make install 4.3.3. 创建一个文件 # 这个文件主要用于内核队列标识的生成，所以这个文件需要放在可以稳定存储的路径，并赋予读写权限，可以给予777权限，(文件内容可以为空) ，样例操作如下:\nsudo touch /PulseFlow_sv_ipc sudo chmod 777 /PulseFlow_sv_ipc 4.3.4. 修改php.ini配置 (不要携带注释内容） # 在文件选择空白处，添加以下配置:\nextension = /usr/local/php/lib/php/extensions/debug-non-zts-20170718/PulseFlow.so //扩展编译后存储的路径 PulseFlow.enabled = true //开启插件 PulseFlow.svipc_name=/PulseFlow_sv_ipc //第三步中创建的文件 的完整路径 4.4. 编译后端程序 # 4.4.1. 克隆代码 # git clone http://gitlab.shein.com:8088/NineWorlds/PulseFlow_IPC_Backend.git 4.4.2. 编译安装 # cd PulseFlow_IPC_Backend mkdir build cd build cmake ../ make cp ../config.ini ./ 4.4.3. 配置 config.ini # config.ini 包含后端程序的相关运行参数\nmode = svipc （监听System V 内核消息队列 ，v1.0.0稳定支持版本)\noutput =1 (是否开启终端输出，1代表开启; 0 代表关闭）\nworkernum = 8 （后台进程数量，推荐数字为CPU核心数的2倍)\nfileuri = /PulseFlow_sv_ipc (3.3 节中的文件路径）\nip = 127.0.0.1 (发送数据包的UDP IP地址 JAVA提供）\nport = 8002 (发送数据包的UDP 端口地址 JAVA提供）\n其他参数不需要调动，上述参数只需要按需改动即可。\n4.4.4 .后端程序启动 # 终端启动程序，直接给予程序执行权限，即可运行。\n推荐使用脚本启动，还需要麻烦运维小伙伴编写启动脚本。\n4.4.5 后端程序稳定性 # 后端程序的稳定性主要围绕 主进程 和 进程池 两方面。\n在程序体内部采用了主从模式，主进程会监控子进程池的状态，所有的进程名称均相同，主进程的PID是进程组的第一个数值，目前我们能够保障子进程池的稳定，如果子进程挂掉了，主进程会负责调控生成新的子进程。\n主进程的稳定性还需要运维小伙伴根据主进程PID做监控，如果发现主进程挂掉了，重启主进程。\n4.4.6 服务器部署 注意点 # 部署需要重启php-fpm，所以为了业务保险起见，可以先把nginx下线再重启PHP-FPM，避免业务损失。\n"},{"id":13,"href":"/icorer_docs/doccenter/logdarts/designs/1.1/","title":"1.1 数据结构分析","section":"风险分析","content":" 二. 数据结构分析 # 2.1 数据结构构造（已审查） # 组件数据结构采用数组进行存储，数组的数据结构如下图：\n数组结构的各部分阐述如下：\nTOTAL_COUNT：记录的总数量\nTOTAL_SIZE ： 数据包的总大小，通过这个参数可以控制每次UDP数据包的大小临界值。\n每一个数据元包括：log_str、log_struct、log_length这三部分。\nlog_str：这个元素是一个数组，每个元素就是一个完整的日志字符串。\nlog_struct：这个元素是一个数组，每个数组元素是个三元组，是构造log_str的源数据。\nlog_length：这个元素是一个数组，每个元素都是一个数值型数据，代表当前id对应的字符串的长度。\n2.2 数据结构操作：(添加、删除）(已审查) # 2.2.1 添加操作 （已审查） # 当调用set和count函数添加数据时，组件会同时添加log_str、log_struct、log_length三个元素，由于这三个元素添加时数组ID均相同，所以三个元素在结构上是可以通过id进行统一索引的，类似的模型代码如下。\n$log_size = strlen($log); self::$gauae_metrics_logs[\u0026#39;LOGS_DATA\u0026#39;][\u0026#39;log_str\u0026#39;][] = $log; self::$gauae_metrics_logs[\u0026#39;LOGS_DATA\u0026#39;][\u0026#39;log_struct\u0026#39;][] = $logPacker; self::$gauae_metrics_logs[\u0026#39;LOGS_DATA\u0026#39;][\u0026#39;log_length\u0026#39;][] = $log_size; self::$gauae_metrics_logs[\u0026#39;TOTAL_COUNT\u0026#39;]++; self::$gauae_metrics_logs[\u0026#39;TOTAL_SIZE\u0026#39;] += $log_size; TOTAL_COUNT在添加的时候会进行递增，TOTAL_SIZE会在添加的时候自动把当前的数据包长度进行添加。\n2.2.1 删除操作 （已审查） # 当调用send_count_metrics_log、send_gauae_metrics_log函数发送发送数据是，组件会同时删除log_str、log_struct、log_length三个元素，并同时调整TOTAL_COUNT、TOTAL_SIZE数值。\nforeach (self::$gauae_metrics_logs[\u0026#39;LOGS_DATA\u0026#39;][\u0026#39;log_str\u0026#39;] as $key =\u0026gt; $val) { $udpPakData .= $val; //发送前组装最终字符串 $log_size = self::$gauae_metrics_logs[\u0026#39;LOGS_DATA\u0026#39;][\u0026#39;log_length\u0026#39;][$key]; //获取当前位置的长度 unset(self::$gauae_metrics_logs[\u0026#39;LOGS_DATA\u0026#39;][\u0026#39;log_str\u0026#39;][$key]); unset(self::$gauae_metrics_logs[\u0026#39;LOGS_DATA\u0026#39;][\u0026#39;log_length\u0026#39;][$key]); unset(self::$gauae_metrics_logs[\u0026#39;LOGS_DATA\u0026#39;][\u0026#39;log_struct\u0026#39;][$key]); self::$gauae_metrics_logs[\u0026#39;TOTAL_COUNT\u0026#39;]--; self::$gauae_metrics_logs[\u0026#39;TOTAL_SIZE\u0026#39;] -= $log_size; } self::sendUdpPackage(self::$IP, self::$PORT, $udpPakData); //发送UDP TOTAL_COUNT在删除的时候会进行递减，TOTAL_SIZE会在删除的时候自动把当前的数据包长度进行缩减。\n2.2.3 数据构造总结 # 通过添加、删除操作进行数据结构的构造，可以保障数据结构的平衡，通过TOTAL_SIZE和UDP协议的数据包大小上限进行控制。\n"},{"id":14,"href":"/icorer_docs/doccenter/redishub/designs/1.1/","title":"1.1基础运行框架","section":"系统设计","content":" 一. 基础运行框架 # 1.1 设计概述 # 基础运行框架也可以成为程序组织结构,一个项目必须要有足够清晰的工程文件结构. 在清晰的工程结构下,系统的各个模块才会有适合自己的存储位置,从存储位置可以上升为代码的调用路径,好的基础运行框架,既可以让系统的源码结构清楚很多,也可以降低模块间的耦合度,提高系统的稳定性.\n1.2 工程框架组成部分 # 在此项目工程结构中,最外层的文件结构主要包括以下几部分, 项目工程一级文件结构如下图所示:\ncmd目录 : 此目录是工程运行体的源码目录,也就是最终会编译出来的可执行体的源码目录,这个目录包括 proxy,daemon目录. config目录 : 配置文件存储目录. deploy目录 : 工程部署目录,里面会包含一些部署脚本和部署工具. doc目录 : 文档目录 ,里面包括一系列的子文件夹,用来保存每个子功能的描述文档. example目录 : 样例目录,对于一些对外提供的功能模块做一些功能示例. script目录 : 脚本目录,里面的脚本相对与deploy目录里的脚本更偏向于一些模块测试脚本. src目录 : 模块源代码目录, 这个目录是工程框架中最重要的一部分,主要包括工程的模块元素,其中包括models 、pkg、 proxy 、redishub、 redis、util目录,后面会做更加详细的阐述. vender目录 : 外部库目录,因为外部的包不断更新,这里的vender更偏向于把适合工程的外部依赖库进行镜像保存,主要是为了提高工程的稳定性. 二. 重要部分拆分设计 # 2.1 cmd目录 # 这个是运行体目录,主要存储main包结构的文件源码,目前里面包含两部分:\nRedisHub目录 : RedisHub主程序体 2.2 SRC目录结构 # SRC目录的结构如下图:\n这个目录会包含一些子目录文件夹,主要存储功能包级别的源码文件及源码目录,主要包括:\nmodels目录 : 数据结构目录,存储系统用到的数据结构相关定义 proxy目录 : 代理模块,这个模块专门储存redis代理相关的功能,既包括本地监听级别的backend,也包括协议解析部分的redis目录,还包括plugin插件目录. redhub目录: 这个目录是核心目录,主要的工作任务在于承上启下,因为在src目录下基础单元都是一个个独立的包,但是如何被cmd层的代码顺利调用,还需要redtun在src功能包基础上抽象cmd层调用的操作单元. utils目录 : 框架的套件目录,主要用来存储框架所使用的一系列套件包,例如errors , log , math , redis-client , trace , unsafe , rpc , sync , resolver , usage 等 pkg目录：包含codis redis协议解析器 redis目录：包含redis集群核心功能代码。 "},{"id":15,"href":"/icorer_docs/doccenter/redistun/designs/1.1/","title":"1.1基础运行框架","section":"系统设计","content":" 一. 基础运行框架 # 1.1 设计概述 # 基础运行框架也可以成为程序组织结构,一个项目必须要有足够清晰的工程文件结构. 在清晰的工程结构下,系统的各个模块才会有适合自己的存储位置,从存储位置可以上升为代码的调用路径,好的基础运行框架,既可以让系统的源码结构清楚很多,也可以降低模块间的耦合度,提高系统的稳定性.\n1.2 工程框架组成部分 # 在此项目工程结构中,最外层的文件结构主要包括以下几部分, 项目工程一级文件结构如下图所示:\ncmd目录 : 此目录是工程运行体的源码目录,也就是最终会编译出来的可执行体的源码目录,这个目录包括 proxy,daemon目录. config目录 : 配置文件存储目录. deploy目录 : 工程部署目录,里面会包含一些部署脚本和部署工具. doc目录 : 文档目录 ,里面包括一系列的子文件夹,用来保存每个子功能的描述文档. example目录 : 样例目录,对于一些对外提供的功能模块做一些功能示例. script目录 : 脚本目录,里面的脚本相对与deploy目录里的脚本更偏向于一些模块测试脚本. src目录 : 模块源代码目录, 这个目录是工程框架中最重要的一部分,主要包括工程的模块元素,其中包括models , proxy , redtun , utils目录,后面会做更加详细的阐述. vender目录 : 外部库目录,因为外部的包不断更新,这里的vender更偏向于把适合工程的外部依赖库进行镜像保存,主要是为了提高工程的稳定性. 二. 重要部分拆分设计 # 2.1 cmd目录 # 这个是运行体目录,主要存储main包结构的文件源码,目前里面包含两部分:\nproxy目录 : redisTunel主程序体 daemon目录 : redisTunel的容灾器程序体 2.2 SRC目录结构 # SRC目录的结构如下图:\n这个目录会包含一些子目录文件夹,主要存储功能包级别的源码文件及源码目录,主要包括:\nmodels目录 : 数据结构目录,存储系统用到的数据结构相关定义 proxy目录 : 代理模块,这个模块专门储存redis代理相关的功能,既包括本地监听级别的backend,也包括协议解析部分的redis目录,还包括plugin插件目录. redtun目录: 这个目录是核心目录,主要的工作任务在于承上启下,因为在src目录下基础单元都是一个个独立的包,但是如何被cmd层的代码顺利调用,还需要redtun在src功能包基础上抽象cmd层调用的操作单元. utils目录 : 框架的套件目录,主要用来存储框架所使用的一系列套件包,例如errors , log , math , redis-client , trace , unsafe , rpc , sync , resolver , usage 等 "},{"id":16,"href":"/icorer_docs/doccenter/redishub/module_test/2.2/","title":"2.2 中间件完整测试","section":"系统模块测试","content":" 零、亿级数据压测 # // 测试脚本 \u0026lt;?php $redis = new Redis(); try { //connect 是 异常级别 $redis-\u0026gt;connect(\u0026#39;/tmp/redis.socks\u0026#39;); $ret = $redis-\u0026gt;set(\u0026#34;hello\u0026#34;, \u0026#34;helloworld\u0026#34;,2); var_dump($ret); $ret = $redis-\u0026gt;get(\u0026#34;hello\u0026#34;); var_dump($ret); $ret = $redis-\u0026gt;del(\u0026#34;hello\u0026#34;); var_dump($ret); $ret = $redis-\u0026gt;mset([\u0026#34;test1\u0026#34; =\u0026gt; \u0026#39;value1\u0026#39;, \u0026#34;test2\u0026#34; =\u0026gt; \u0026#39;value2\u0026#39;]); var_dump($ret); $ret = $redis-\u0026gt;del(\u0026#34;test1\u0026#34;, \u0026#34;test2\u0026#34;, \u0026#34;test3\u0026#34;); var_dump($ret); $ret = $redis-\u0026gt;mget([\u0026#34;test1\u0026#34;, \u0026#34;test2\u0026#34;, \u0026#34;test3\u0026#34;, \u0026#34;test4\u0026#34;, \u0026#34;test5\u0026#34;, \u0026#34;test6\u0026#34;, \u0026#34;test7\u0026#34;, \u0026#34;test8\u0026#34;, \u0026#34;test9\u0026#34;, \u0026#34;test10\u0026#34;, \u0026#34;test11\u0026#34;, \u0026#34;test12\u0026#34;, \u0026#34;test13\u0026#34;, \u0026#34;test14\u0026#34;, \u0026#34;test15\u0026#34;, \u0026#34;test16\u0026#34;, \u0026#34;test17\u0026#34;, \u0026#34;test18\u0026#34;, \u0026#34;test19\u0026#34;, \u0026#34;test20\u0026#34;]); var_dump($ret); $ret = $redis-\u0026gt;rPush(\u0026#34;push\u0026#34;,\u0026#34;key1\u0026#34;,2019,\u0026#34;key2\u0026#34;); var_dump($ret); $val1 = $redis-\u0026gt;lPop(\u0026#34;push\u0026#34;); var_dump($val1); $val1 = $redis-\u0026gt;lPop(\u0026#34;push\u0026#34;); var_dump($val1); $val1 = $redis-\u0026gt;lPop(\u0026#34;push\u0026#34;); var_dump($val1); } catch (\\Exception $ex) { var_dump($ex-\u0026gt;getMessage()); } # 终端输出 ______ _ _ _ _ _ (_____ \\ | (_) (_) (_) | | _____) )_____ __| |_ ___ _______ _ _| |__ | __ /| ___ |/ _ | |/___) ___ | | | | _ \\ | | \\ \\| ____( (_| | |___ | | | | |_| | |_) ) |_| |_|_____)\\____|_(___/|_| |_|____/|____/ 2019/09/15 09:40:27 main.go:69: UNIX-Server: /tmp/redis.socks {\u0026#34;appName\u0026#34;:\u0026#34;RedisHub\u0026#34;,\u0026#34;host\u0026#34;:\u0026#34;corerman-WorkStation\u0026#34;,\u0026#34;ip\u0026#34;:\u0026#34;\u0026#34;,\u0026#34;level\u0026#34;:\u0026#34;INFO\u0026#34;,\u0026#34;message\u0026#34;:\u0026#34;RedisHub Heart-Beat-Report running.\u0026#34;,\u0026#34;timestamp\u0026#34;:\u0026#34;2019-09-15T09:40:27.222+0800\u0026#34;} {\u0026#34;appName\u0026#34;:\u0026#34;RedisHub\u0026#34;,\u0026#34;host\u0026#34;:\u0026#34;corerman-WorkStation\u0026#34;,\u0026#34;ip\u0026#34;:\u0026#34;\u0026#34;,\u0026#34;level\u0026#34;:\u0026#34;INFO\u0026#34;,\u0026#34;message\u0026#34;:\u0026#34;RedisHub-UNIX begin running\u0026#34;,\u0026#34;timestamp\u0026#34;:\u0026#34;2019-09-15T09:40:27.222+0800\u0026#34;} {\u0026#34;appName\u0026#34;:\u0026#34;RedisHub\u0026#34;,\u0026#34;host\u0026#34;:\u0026#34;corerman-WorkStation\u0026#34;,\u0026#34;ip\u0026#34;:\u0026#34;\u0026#34;,\u0026#34;level\u0026#34;:\u0026#34;INFO\u0026#34;,\u0026#34;message\u0026#34;:\u0026#34;heartbeat report info: command parse count : 1978910\u0026#34;,\u0026#34;timestamp\u0026#34;:\u0026#34;2019-09-15T09:42:27.222+0800\u0026#34;} {\u0026#34;appName\u0026#34;:\u0026#34;RedisHub\u0026#34;,\u0026#34;host\u0026#34;:\u0026#34;corerman-WorkStation\u0026#34;,\u0026#34;ip\u0026#34;:\u0026#34;\u0026#34;,\u0026#34;level\u0026#34;:\u0026#34;INFO\u0026#34;,\u0026#34;message\u0026#34;:\u0026#34;heartbeat report info: command parse count : 3674420\u0026#34;,\u0026#34;timestamp\u0026#34;:\u0026#34;2019-09-15T09:44:27.222+0800\u0026#34;} {\u0026#34;appName\u0026#34;:\u0026#34;RedisHub\u0026#34;,\u0026#34;host\u0026#34;:\u0026#34;corerman-WorkStation\u0026#34;,\u0026#34;ip\u0026#34;:\u0026#34;\u0026#34;,\u0026#34;level\u0026#34;:\u0026#34;INFO\u0026#34;,\u0026#34;message\u0026#34;:\u0026#34;heartbeat report info: command parse count : 7971749\u0026#34;,\u0026#34;timestamp\u0026#34;:\u0026#34;2019-09-15T09:46:27.223+0800\u0026#34;} {\u0026#34;appName\u0026#34;:\u0026#34;RedisHub\u0026#34;,\u0026#34;host\u0026#34;:\u0026#34;corerman-WorkStation\u0026#34;,\u0026#34;ip\u0026#34;:\u0026#34;\u0026#34;,\u0026#34;level\u0026#34;:\u0026#34;INFO\u0026#34;,\u0026#34;message\u0026#34;:\u0026#34;heartbeat report info: command parse count : 13502078\u0026#34;,\u0026#34;timestamp\u0026#34;:\u0026#34;2019-09-15T09:48:27.223+0800\u0026#34;} {\u0026#34;appName\u0026#34;:\u0026#34;RedisHub\u0026#34;,\u0026#34;host\u0026#34;:\u0026#34;corerman-WorkStation\u0026#34;,\u0026#34;ip\u0026#34;:\u0026#34;\u0026#34;,\u0026#34;level\u0026#34;:\u0026#34;INFO\u0026#34;,\u0026#34;message\u0026#34;:\u0026#34;heartbeat report info: command parse count : 19082608\u0026#34;,\u0026#34;timestamp\u0026#34;:\u0026#34;2019-09-15T09:50:27.224+0800\u0026#34;} {\u0026#34;appName\u0026#34;:\u0026#34;RedisHub\u0026#34;,\u0026#34;host\u0026#34;:\u0026#34;corerman-WorkStation\u0026#34;,\u0026#34;ip\u0026#34;:\u0026#34;\u0026#34;,\u0026#34;level\u0026#34;:\u0026#34;INFO\u0026#34;,\u0026#34;message\u0026#34;:\u0026#34;heartbeat report info: command parse count : 24676646\u0026#34;,\u0026#34;timestamp\u0026#34;:\u0026#34;2019-09-15T09:52:27.224+0800\u0026#34;} {\u0026#34;appName\u0026#34;:\u0026#34;RedisHub\u0026#34;,\u0026#34;host\u0026#34;:\u0026#34;corerman-WorkStation\u0026#34;,\u0026#34;ip\u0026#34;:\u0026#34;\u0026#34;,\u0026#34;level\u0026#34;:\u0026#34;INFO\u0026#34;,\u0026#34;message\u0026#34;:\u0026#34;heartbeat report info: command parse count : 30279296\u0026#34;,\u0026#34;timestamp\u0026#34;:\u0026#34;2019-09-15T09:54:27.225+0800\u0026#34;} {\u0026#34;appName\u0026#34;:\u0026#34;RedisHub\u0026#34;,\u0026#34;host\u0026#34;:\u0026#34;corerman-WorkStation\u0026#34;,\u0026#34;ip\u0026#34;:\u0026#34;\u0026#34;,\u0026#34;level\u0026#34;:\u0026#34;INFO\u0026#34;,\u0026#34;message\u0026#34;:\u0026#34;heartbeat report info: command parse count : 35869386\u0026#34;,\u0026#34;timestamp\u0026#34;:\u0026#34;2019-09-15T09:56:27.225+0800\u0026#34;} {\u0026#34;appName\u0026#34;:\u0026#34;RedisHub\u0026#34;,\u0026#34;host\u0026#34;:\u0026#34;corerman-WorkStation\u0026#34;,\u0026#34;ip\u0026#34;:\u0026#34;\u0026#34;,\u0026#34;level\u0026#34;:\u0026#34;INFO\u0026#34;,\u0026#34;message\u0026#34;:\u0026#34;heartbeat report info: command parse count : 41462169\u0026#34;,\u0026#34;timestamp\u0026#34;:\u0026#34;2019-09-15T09:58:27.226+0800\u0026#34;} {\u0026#34;appName\u0026#34;:\u0026#34;RedisHub\u0026#34;,\u0026#34;host\u0026#34;:\u0026#34;corerman-WorkStation\u0026#34;,\u0026#34;ip\u0026#34;:\u0026#34;\u0026#34;,\u0026#34;level\u0026#34;:\u0026#34;INFO\u0026#34;,\u0026#34;message\u0026#34;:\u0026#34;heartbeat report info: command parse count : 47037700\u0026#34;,\u0026#34;timestamp\u0026#34;:\u0026#34;2019-09-15T10:00:27.227+0800\u0026#34;} {\u0026#34;appName\u0026#34;:\u0026#34;RedisHub\u0026#34;,\u0026#34;host\u0026#34;:\u0026#34;corerman-WorkStation\u0026#34;,\u0026#34;ip\u0026#34;:\u0026#34;\u0026#34;,\u0026#34;level\u0026#34;:\u0026#34;INFO\u0026#34;,\u0026#34;message\u0026#34;:\u0026#34;heartbeat report info: command parse count : 52639532\u0026#34;,\u0026#34;timestamp\u0026#34;:\u0026#34;2019-09-15T10:02:27.227+0800\u0026#34;} {\u0026#34;appName\u0026#34;:\u0026#34;RedisHub\u0026#34;,\u0026#34;host\u0026#34;:\u0026#34;corerman-WorkStation\u0026#34;,\u0026#34;ip\u0026#34;:\u0026#34;\u0026#34;,\u0026#34;level\u0026#34;:\u0026#34;INFO\u0026#34;,\u0026#34;message\u0026#34;:\u0026#34;heartbeat report info: command parse count : 58224711\u0026#34;,\u0026#34;timestamp\u0026#34;:\u0026#34;2019-09-15T10:04:27.229+0800\u0026#34;} {\u0026#34;appName\u0026#34;:\u0026#34;RedisHub\u0026#34;,\u0026#34;host\u0026#34;:\u0026#34;corerman-WorkStation\u0026#34;,\u0026#34;ip\u0026#34;:\u0026#34;\u0026#34;,\u0026#34;level\u0026#34;:\u0026#34;INFO\u0026#34;,\u0026#34;message\u0026#34;:\u0026#34;heartbeat report info: command parse count : 63814850\u0026#34;,\u0026#34;timestamp\u0026#34;:\u0026#34;2019-09-15T10:06:27.229+0800\u0026#34;} {\u0026#34;appName\u0026#34;:\u0026#34;RedisHub\u0026#34;,\u0026#34;host\u0026#34;:\u0026#34;corerman-WorkStation\u0026#34;,\u0026#34;ip\u0026#34;:\u0026#34;\u0026#34;,\u0026#34;level\u0026#34;:\u0026#34;INFO\u0026#34;,\u0026#34;message\u0026#34;:\u0026#34;heartbeat report info: command parse count : 69385735\u0026#34;,\u0026#34;timestamp\u0026#34;:\u0026#34;2019-09-15T10:08:27.229+0800\u0026#34;} {\u0026#34;appName\u0026#34;:\u0026#34;RedisHub\u0026#34;,\u0026#34;host\u0026#34;:\u0026#34;corerman-WorkStation\u0026#34;,\u0026#34;ip\u0026#34;:\u0026#34;\u0026#34;,\u0026#34;level\u0026#34;:\u0026#34;INFO\u0026#34;,\u0026#34;message\u0026#34;:\u0026#34;heartbeat report info: command parse count : 74981851\u0026#34;,\u0026#34;timestamp\u0026#34;:\u0026#34;2019-09-15T10:10:27.230+0800\u0026#34;} {\u0026#34;appName\u0026#34;:\u0026#34;RedisHub\u0026#34;,\u0026#34;host\u0026#34;:\u0026#34;corerman-WorkStation\u0026#34;,\u0026#34;ip\u0026#34;:\u0026#34;\u0026#34;,\u0026#34;level\u0026#34;:\u0026#34;INFO\u0026#34;,\u0026#34;message\u0026#34;:\u0026#34;heartbeat report info: command parse count : 80565352\u0026#34;,\u0026#34;timestamp\u0026#34;:\u0026#34;2019-09-15T10:12:27.230+0800\u0026#34;} {\u0026#34;appName\u0026#34;:\u0026#34;RedisHub\u0026#34;,\u0026#34;host\u0026#34;:\u0026#34;corerman-WorkStation\u0026#34;,\u0026#34;ip\u0026#34;:\u0026#34;\u0026#34;,\u0026#34;level\u0026#34;:\u0026#34;INFO\u0026#34;,\u0026#34;message\u0026#34;:\u0026#34;heartbeat report info: command parse count : 86114343\u0026#34;,\u0026#34;timestamp\u0026#34;:\u0026#34;2019-09-15T10:14:27.231+0800\u0026#34;} {\u0026#34;appName\u0026#34;:\u0026#34;RedisHub\u0026#34;,\u0026#34;host\u0026#34;:\u0026#34;corerman-WorkStation\u0026#34;,\u0026#34;ip\u0026#34;:\u0026#34;\u0026#34;,\u0026#34;level\u0026#34;:\u0026#34;INFO\u0026#34;,\u0026#34;message\u0026#34;:\u0026#34;heartbeat report info: command parse count : 91721982\u0026#34;,\u0026#34;timestamp\u0026#34;:\u0026#34;2019-09-15T10:16:27.231+0800\u0026#34;} {\u0026#34;appName\u0026#34;:\u0026#34;RedisHub\u0026#34;,\u0026#34;host\u0026#34;:\u0026#34;corerman-WorkStation\u0026#34;,\u0026#34;ip\u0026#34;:\u0026#34;\u0026#34;,\u0026#34;level\u0026#34;:\u0026#34;INFO\u0026#34;,\u0026#34;message\u0026#34;:\u0026#34;heartbeat report info: command parse count : 97338179\u0026#34;,\u0026#34;timestamp\u0026#34;:\u0026#34;2019-09-15T10:18:27.231+0800\u0026#34;} {\u0026#34;appName\u0026#34;:\u0026#34;RedisHub\u0026#34;,\u0026#34;host\u0026#34;:\u0026#34;corerman-WorkStation\u0026#34;,\u0026#34;ip\u0026#34;:\u0026#34;\u0026#34;,\u0026#34;level\u0026#34;:\u0026#34;INFO\u0026#34;,\u0026#34;message\u0026#34;:\u0026#34;heartbeat report info: command parse count : 102913090\u0026#34;,\u0026#34;timestamp\u0026#34;:\u0026#34;2019-09-15T10:20:27.231+0800\u0026#34;} {\u0026#34;appName\u0026#34;:\u0026#34;RedisHub\u0026#34;,\u0026#34;host\u0026#34;:\u0026#34;corerman-WorkStation\u0026#34;,\u0026#34;ip\u0026#34;:\u0026#34;\u0026#34;,\u0026#34;level\u0026#34;:\u0026#34;INFO\u0026#34;,\u0026#34;message\u0026#34;:\u0026#34;heartbeat report info: command parse count : 102913090\u0026#34;,\u0026#34;timestamp\u0026#34;:\u0026#34;2019-09-15T10:22:27.232+0800\u0026#34;} {\u0026#34;appName\u0026#34;:\u0026#34;RedisHub\u0026#34;,\u0026#34;host\u0026#34;:\u0026#34;corerman-WorkStation\u0026#34;,\u0026#34;ip\u0026#34;:\u0026#34;\u0026#34;,\u0026#34;level\u0026#34;:\u0026#34;INFO\u0026#34;,\u0026#34;message\u0026#34;:\u0026#34;heartbeat report info: command parse count : 102913090\u0026#34;,\u0026#34;timestamp\u0026#34;:\u0026#34;2019-09-15T10:24:27.232+0800\u0026#34;} {\u0026#34;appName\u0026#34;:\u0026#34;RedisHub\u0026#34;,\u0026#34;host\u0026#34;:\u0026#34;corerman-WorkStation\u0026#34;,\u0026#34;ip\u0026#34;:\u0026#34;\u0026#34;,\u0026#34;level\u0026#34;:\u0026#34;INFO\u0026#34;,\u0026#34;message\u0026#34;:\u0026#34;heartbeat report info: command parse count : 102913090\u0026#34;,\u0026#34;timestamp\u0026#34;:\u0026#34;2019-09-15T10:26:27.233+0800\u0026#34;} {\u0026#34;appName\u0026#34;:\u0026#34;RedisHub\u0026#34;,\u0026#34;host\u0026#34;:\u0026#34;corerman-WorkStation\u0026#34;,\u0026#34;ip\u0026#34;:\u0026#34;\u0026#34;,\u0026#34;level\u0026#34;:\u0026#34;INFO\u0026#34;,\u0026#34;message\u0026#34;:\u0026#34;heartbeat report info: command parse count : 102913100\u0026#34;,\u0026#34;timestamp\u0026#34;:\u0026#34;2019-09-15T10:28:27.233+0800\u0026#34;} {\u0026#34;appName\u0026#34;:\u0026#34;RedisHub\u0026#34;,\u0026#34;host\u0026#34;:\u0026#34;corerman-WorkStation\u0026#34;,\u0026#34;ip\u0026#34;:\u0026#34;\u0026#34;,\u0026#34;level\u0026#34;:\u0026#34;INFO\u0026#34;,\u0026#34;message\u0026#34;:\u0026#34;heartbeat report info: command parse count : 102913270\u0026#34;,\u0026#34;timestamp\u0026#34;:\u0026#34;2019-09-15T10:30:27.340+0800\u0026#34;} {\u0026#34;appName\u0026#34;:\u0026#34;RedisHub\u0026#34;,\u0026#34;host\u0026#34;:\u0026#34;corerman-WorkStation\u0026#34;,\u0026#34;ip\u0026#34;:\u0026#34;\u0026#34;,\u0026#34;level\u0026#34;:\u0026#34;INFO\u0026#34;,\u0026#34;message\u0026#34;:\u0026#34;heartbeat report info: command parse count : 102913270\u0026#34;,\u0026#34;timestamp\u0026#34;:\u0026#34;2019-09-15T10:32:27.341+0800\u0026#34;} {\u0026#34;appName\u0026#34;:\u0026#34;RedisHub\u0026#34;,\u0026#34;host\u0026#34;:\u0026#34;corerman-WorkStation\u0026#34;,\u0026#34;ip\u0026#34;:\u0026#34;\u0026#34;,\u0026#34;level\u0026#34;:\u0026#34;INFO\u0026#34;,\u0026#34;message\u0026#34;:\u0026#34;heartbeat report info: command parse count : 102913270\u0026#34;,\u0026#34;timestamp\u0026#34;:\u0026#34;2019-09-15T10:34:27.341+0800\u0026#34;} 一、Redis基准压测性能对比 # corerman@corerman-WorkStation:~$ redis-benchmark -p 6379 -t get,set,rpush,lpop,setex,psetex,del -n 200000 -c 50 -q SET: 129785.85 requests per second GET: 128865.98 requests per second RPUSH: 131839.16 requests per second LPOP: 131061.59 requests per second corerman@corerman-WorkStation:~$ redis-benchmark -s /tmp/redis.socks -t get,set,rpush,lpop,setex,psetex,del -n 200000 -c 50 -q SET: 116754.23 requests per second GET: 105932.20 requests per second RPUSH: 116686.12 requests per second LPOP: 105652.41 requests per second 通过上面可以看出，SET、GET、RPUSH、LPOP性能损耗不大\n二. 中间件和标准集群下，phpredis的表现及性能 # phpredis 5.0.2版本 需要在php.ini 中增加 redis.clusters.cache_slots = 1，开启redis集群的slots信息缓存，总而提升性能。\n2.1 SET指令 （OK） # 2.1.1 中间件 # \u0026lt;?php $redis = new Redis(); try{ //connect 是 异常级别 $redis-\u0026gt;connect(\u0026#39;/tmp/redis.socks\u0026#39;); $status = $redis-\u0026gt;set(\u0026#34;test\u0026#34;,\u0026#34;testval\u0026#34;); var_dump($status); }catch (\\Exception $ex){ var_dump($ex-\u0026gt;getMessage()); } 运行结果：bool(true)\n2.1.2 标准集群 # \u0026lt;?php try{ //connect 是 异常级别 $redisCluster = new RedisCluster(NULL, Array(\u0026#34;127.0.0.1:9001\u0026#34;), 1.5, 1.5, true); $status = $redisCluster-\u0026gt;set(\u0026#34;test\u0026#34;,\u0026#34;testval\u0026#34;); var_dump($status); }catch (\\Exception $ex){ var_dump($ex-\u0026gt;getMessage()); } 运行结果：bool(true)\n2.1.3 压测数据对比 # #中间件 corerman@corerman-WorkStation:~$ ab -n 100000 -c 20 http://lab.test.local/redis_agent.php This is ApacheBench, Version 2.3 \u0026lt;$Revision: 1807734 $\u0026gt; Copyright 1996 Adam Twiss, Zeus Technology Ltd, http://www.zeustech.net/ Licensed to The Apache Software Foundation, http://www.apache.org/ Benchmarking lab.test.local (be patient) Completed 10000 requests Completed 20000 requests Completed 30000 requests Completed 40000 requests Completed 50000 requests Completed 60000 requests Completed 70000 requests Completed 80000 requests Completed 90000 requests Completed 100000 requests Finished 100000 requests Server Software: nginx Server Hostname: lab.test.local Server Port: 80 Document Path: /redis_agent.php Document Length: 11 bytes Concurrency Level: 20 Time taken for tests: 6.229 seconds Complete requests: 100000 Failed requests: 0 Total transferred: 19000000 bytes HTML transferred: 1100000 bytes Requests per second: 16054.15 [#/sec] (mean) Time per request: 1.246 [ms] (mean) Time per request: 0.062 [ms] (mean, across all concurrent requests) Transfer rate: 2978.80 [Kbytes/sec] received Connection Times (ms) min mean[+/-sd] median max Connect: 0 0 0.1 0 2 Processing: 0 1 2.9 1 213 Waiting: 0 1 2.9 1 213 Total: 0 1 2.9 1 213 Percentage of the requests served within a certain time (ms) 50% 1 66% 1 75% 1 80% 1 90% 2 95% 2 98% 3 99% 4 100% 213 (longest request) # phpredis直连标准集群 ： 开启slot缓存 corerman@corerman-WorkStation:~$ ab -n 100000 -c 20 http://lab.test.local/redis_cluster.php This is ApacheBench, Version 2.3 \u0026lt;$Revision: 1807734 $\u0026gt; Copyright 1996 Adam Twiss, Zeus Technology Ltd, http://www.zeustech.net/ Licensed to The Apache Software Foundation, http://www.apache.org/ Benchmarking lab.test.local (be patient) Completed 10000 requests Completed 20000 requests Completed 30000 requests Completed 40000 requests Completed 50000 requests Completed 60000 requests Completed 70000 requests Completed 80000 requests Completed 90000 requests Completed 100000 requests Finished 100000 requests Server Software: nginx Server Hostname: lab.test.local Server Port: 80 Document Path: /redis_cluster.php Document Length: 11 bytes Concurrency Level: 20 Time taken for tests: 5.609 seconds Complete requests: 100000 Failed requests: 0 Total transferred: 19000000 bytes HTML transferred: 1100000 bytes Requests per second: 17829.52 [#/sec] (mean) Time per request: 1.122 [ms] (mean) Time per request: 0.056 [ms] (mean, across all concurrent requests) Transfer rate: 3308.21 [Kbytes/sec] received Connection Times (ms) min mean[+/-sd] median max Connect: 0 0 0.1 0 1 Processing: 0 1 2.0 1 213 Waiting: 0 1 2.0 1 212 Total: 0 1 2.0 1 213 Percentage of the requests served within a certain time (ms) 50% 1 66% 1 75% 1 80% 1 90% 2 95% 2 98% 2 99% 3 100% 213 (longest request) # phpredis直连标准集群 ： 未开启slot缓存 corerman@corerman-WorkStation:~$ ab -n 100000 -c 20 http://lab.test.local/redis_cluster.php This is ApacheBench, Version 2.3 \u0026lt;$Revision: 1807734 $\u0026gt; Copyright 1996 Adam Twiss, Zeus Technology Ltd, http://www.zeustech.net/ Licensed to The Apache Software Foundation, http://www.apache.org/ Benchmarking lab.test.local (be patient) Completed 10000 requests Completed 20000 requests Completed 30000 requests Completed 40000 requests Completed 50000 requests Completed 60000 requests Completed 70000 requests Completed 80000 requests Completed 90000 requests Completed 100000 requests Finished 100000 requests Server Software: nginx Server Hostname: lab.test.local Server Port: 80 Document Path: /redis_cluster.php Document Length: 11 bytes Concurrency Level: 20 Time taken for tests: 10.369 seconds Complete requests: 100000 Failed requests: 0 Total transferred: 19000000 bytes HTML transferred: 1100000 bytes Requests per second: 9643.96 [#/sec] (mean) Time per request: 2.074 [ms] (mean) Time per request: 0.104 [ms] (mean, across all concurrent requests) Transfer rate: 1789.41 [Kbytes/sec] received Connection Times (ms) min mean[+/-sd] median max Connect: 0 0 3.2 0 1018 Processing: 1 2 4.1 2 214 Waiting: 1 2 4.1 2 214 Total: 1 2 5.2 2 1021 Percentage of the requests served within a certain time (ms) 50% 2 66% 2 75% 2 80% 2 90% 2 95% 2 98% 3 99% 3 100% 1021 (longest request) 2.2 SETEX指令 （OK） # 2.2.1 中间件 # \u0026lt;?php $redis = new Redis(); try{ //connect 是 异常级别 $redis-\u0026gt;connect(\u0026#39;/tmp/redis.socks\u0026#39;); $status = $redis-\u0026gt;set(\u0026#34;test\u0026#34;,\u0026#34;testval\u0026#34;，5); //内部调用setex var_dump($status); }catch (\\Exception $ex){ var_dump($ex-\u0026gt;getMessage()); } 运行结果：bool(true)\n2.2.2 标准集群 # \u0026lt;?php try{ //connect 是 异常级别 $redis = new RedisCluster(NULL, Array(\u0026#34;127.0.0.1:9001\u0026#34;), 1.5, 1.5, true); $status = $redis-\u0026gt;set(\u0026#34;test\u0026#34;,\u0026#34;testval\u0026#34;，5); //内部调用setex var_dump($status); }catch (\\Exception $ex){ var_dump($ex-\u0026gt;getMessage()); } 运行结果：bool(true)\n2.2.3 压测数据对比 # # 中间件 corerman@corerman-WorkStation:~$ ab -n 100000 -c 20 http://lab.test.local/redis_agent.php This is ApacheBench, Version 2.3 \u0026lt;$Revision: 1807734 $\u0026gt; Copyright 1996 Adam Twiss, Zeus Technology Ltd, http://www.zeustech.net/ Licensed to The Apache Software Foundation, http://www.apache.org/ Benchmarking lab.test.local (be patient) Completed 10000 requests Completed 20000 requests Completed 30000 requests Completed 40000 requests Completed 50000 requests Completed 60000 requests Completed 70000 requests Completed 80000 requests Completed 90000 requests Completed 100000 requests Finished 100000 requests Server Software: nginx Server Hostname: lab.test.local Server Port: 80 Document Path: /redis_agent.php Document Length: 11 bytes Concurrency Level: 20 Time taken for tests: 6.258 seconds Complete requests: 100000 Failed requests: 0 Total transferred: 19000000 bytes HTML transferred: 1100000 bytes Requests per second: 15979.34 [#/sec] (mean) Time per request: 1.252 [ms] (mean) Time per request: 0.063 [ms] (mean, across all concurrent requests) Transfer rate: 2964.92 [Kbytes/sec] received Connection Times (ms) min mean[+/-sd] median max Connect: 0 0 0.1 0 1 Processing: 0 1 2.6 1 211 Waiting: 0 1 2.6 1 211 Total: 0 1 2.6 1 211 Percentage of the requests served within a certain time (ms) 50% 1 66% 1 75% 1 80% 1 90% 2 95% 2 98% 3 99% 3 100% 211 (longest request) # 标准集群 corerman@corerman-WorkStation:~$ ab -n 100000 -c 20 http://lab.test.local/redis_cluster.php This is ApacheBench, Version 2.3 \u0026lt;$Revision: 1807734 $\u0026gt; Copyright 1996 Adam Twiss, Zeus Technology Ltd, http://www.zeustech.net/ Licensed to The Apache Software Foundation, http://www.apache.org/ Benchmarking lab.test.local (be patient) Completed 10000 requests Completed 20000 requests Completed 30000 requests Completed 40000 requests Completed 50000 requests Completed 60000 requests Completed 70000 requests Completed 80000 requests Completed 90000 requests Completed 100000 requests Finished 100000 requests Server Software: nginx Server Hostname: lab.test.local Server Port: 80 Document Path: /redis_cluster.php Document Length: 11 bytes Concurrency Level: 20 Time taken for tests: 5.600 seconds Complete requests: 100000 Failed requests: 0 Total transferred: 19000000 bytes HTML transferred: 1100000 bytes Requests per second: 17858.46 [#/sec] (mean) Time per request: 1.120 [ms] (mean) Time per request: 0.056 [ms] (mean, across all concurrent requests) Transfer rate: 3313.58 [Kbytes/sec] received Connection Times (ms) min mean[+/-sd] median max Connect: 0 0 0.1 0 1 Processing: 0 1 2.0 1 209 Waiting: 0 1 2.0 1 209 Total: 0 1 2.0 1 210 Percentage of the requests served within a certain time (ms) 50% 1 66% 1 75% 1 80% 1 90% 2 95% 2 98% 2 99% 3 100% 210 (longest request) 2.3 PSETEX指令 （OK） # 2.3.1 中间件 # \u0026lt;?php $redis = new Redis(); try{ //connect 是 异常级别 $redis-\u0026gt;connect(\u0026#39;/tmp/redis.socks\u0026#39;); $status = $redis-\u0026gt;set(\u0026#34;test\u0026#34;,\u0026#34;testval\u0026#34;, [\u0026#39;xx\u0026#39;, \u0026#39;px\u0026#39;=\u0026gt;1000]); var_dump($status); }catch (\\Exception $ex){ var_dump($ex-\u0026gt;getMessage()); } 运行结果：bool(true)\n2.3.2 标准集群 # \u0026lt;?php try{ //connect 是 异常级别 $redisCluster = new RedisCluster(NULL, Array(\u0026#34;127.0.0.1:9001\u0026#34;), 1.5, 1.5, true); $status = $redisCluster-\u0026gt;set(\u0026#34;test\u0026#34;,\u0026#34;testval\u0026#34;, [\u0026#39;xx\u0026#39;, \u0026#39;px\u0026#39;=\u0026gt;1000]); var_dump($status); }catch (\\Exception $ex){ var_dump($ex-\u0026gt;getMessage()); } 运行结果：bool(true)\n2.3.3 压测数据对比 # # 中间件 corerman@corerman-WorkStation:~$ ab -n 100000 -c 20 http://lab.test.local/redis_agent.php This is ApacheBench, Version 2.3 \u0026lt;$Revision: 1807734 $\u0026gt; Copyright 1996 Adam Twiss, Zeus Technology Ltd, http://www.zeustech.net/ Licensed to The Apache Software Foundation, http://www.apache.org/ Benchmarking lab.test.local (be patient) Completed 10000 requests Completed 20000 requests Completed 30000 requests Completed 40000 requests Completed 50000 requests Completed 60000 requests Completed 70000 requests Completed 80000 requests Completed 90000 requests Completed 100000 requests Finished 100000 requests Server Software: nginx Server Hostname: lab.test.local Server Port: 80 Document Path: /redis_agent.php Document Length: 11 bytes Concurrency Level: 20 Time taken for tests: 6.265 seconds Complete requests: 100000 Failed requests: 0 Total transferred: 19000000 bytes HTML transferred: 1100000 bytes Requests per second: 15962.77 [#/sec] (mean) Time per request: 1.253 [ms] (mean) Time per request: 0.063 [ms] (mean, across all concurrent requests) Transfer rate: 2961.84 [Kbytes/sec] received Connection Times (ms) min mean[+/-sd] median max Connect: 0 0 0.1 0 1 Processing: 0 1 2.9 1 213 Waiting: 0 1 2.9 1 213 Total: 0 1 2.9 1 213 Percentage of the requests served within a certain time (ms) 50% 1 66% 1 75% 1 80% 1 90% 2 95% 2 98% 3 99% 4 100% 213 (longest request) # 标准集群 corerman@corerman-WorkStation:~$ ab -n 100000 -c 20 http://lab.test.local/redis_cluster.php This is ApacheBench, Version 2.3 \u0026lt;$Revision: 1807734 $\u0026gt; Copyright 1996 Adam Twiss, Zeus Technology Ltd, http://www.zeustech.net/ Licensed to The Apache Software Foundation, http://www.apache.org/ Benchmarking lab.test.local (be patient) Completed 10000 requests Completed 20000 requests Completed 30000 requests Completed 40000 requests Completed 50000 requests Completed 60000 requests Completed 70000 requests Completed 80000 requests Completed 90000 requests Completed 100000 requests Finished 100000 requests Server Software: nginx Server Hostname: lab.test.local Server Port: 80 Document Path: /redis_cluster.php Document Length: 11 bytes Concurrency Level: 20 Time taken for tests: 5.696 seconds Complete requests: 100000 Failed requests: 0 Total transferred: 19000000 bytes HTML transferred: 1100000 bytes Requests per second: 17555.61 [#/sec] (mean) Time per request: 1.139 [ms] (mean) Time per request: 0.057 [ms] (mean, across all concurrent requests) Transfer rate: 3257.39 [Kbytes/sec] received Connection Times (ms) min mean[+/-sd] median max Connect: 0 0 0.1 0 3 Processing: 0 1 1.8 1 214 Waiting: 0 1 1.8 1 214 Total: 0 1 1.8 1 214 Percentage of the requests served within a certain time (ms) 50% 1 66% 1 75% 1 80% 1 90% 2 95% 2 98% 3 99% 4 100% 214 (longest request) 2.4 GET指令 （数据存在：1KB 标准数据） （OK） # 2.4.1 中间件 # \u0026lt;?php $redis = new Redis(); try{ //connect 是 异常级别 $redis-\u0026gt;connect(\u0026#39;/tmp/redis.socks\u0026#39;); $ret = $redis-\u0026gt;get(\u0026#34;test\u0026#34;); var_dump($ret); }catch (\\Exception $ex){ var_dump($ex-\u0026gt;getMessage()); } 能够成功获取到1KB数据。\n2.4.2 标准集群 # \u0026lt;?php try{ //connect 是 异常级别 $redis = new RedisCluster(NULL, Array(\u0026#34;127.0.0.1:9001\u0026#34;), 1.5, 1.5, true); $ret = $redis-\u0026gt;get(\u0026#34;test\u0026#34;); var_dump($ret); }catch (\\Exception $ex){ var_dump($ex-\u0026gt;getMessage()); } 能够成功获取到1KB数据。\n2.4.3 压测数据对比 # # 中间件 corerman@corerman-WorkStation:~$ ab -n 100000 -c 20 http://lab.test.local/redis_agent.php This is ApacheBench, Version 2.3 \u0026lt;$Revision: 1807734 $\u0026gt; Copyright 1996 Adam Twiss, Zeus Technology Ltd, http://www.zeustech.net/ Licensed to The Apache Software Foundation, http://www.apache.org/ Benchmarking lab.test.local (be patient) Completed 10000 requests Completed 20000 requests Completed 30000 requests Completed 40000 requests Completed 50000 requests Completed 60000 requests Completed 70000 requests Completed 80000 requests Completed 90000 requests Completed 100000 requests Finished 100000 requests Server Software: nginx Server Hostname: lab.test.local Server Port: 80 Document Path: /redis_agent.php Document Length: 0 bytes Concurrency Level: 20 Time taken for tests: 6.025 seconds Complete requests: 100000 Failed requests: 0 Total transferred: 17900000 bytes HTML transferred: 0 bytes Requests per second: 16597.96 [#/sec] (mean) Time per request: 1.205 [ms] (mean) Time per request: 0.060 [ms] (mean, across all concurrent requests) Transfer rate: 2901.40 [Kbytes/sec] received Connection Times (ms) min mean[+/-sd] median max Connect: 0 0 0.1 0 2 Processing: 0 1 2.8 1 213 Waiting: 0 1 2.8 1 213 Total: 0 1 2.8 1 214 Percentage of the requests served within a certain time (ms) 50% 1 66% 1 75% 1 80% 1 90% 2 95% 2 98% 3 99% 3 100% 214 (longest request) # 标准集群 corerman@corerman-WorkStation:~$ ab -n 100000 -c 20 http://lab.test.local/redis_cluster.php This is ApacheBench, Version 2.3 \u0026lt;$Revision: 1807734 $\u0026gt; Copyright 1996 Adam Twiss, Zeus Technology Ltd, http://www.zeustech.net/ Licensed to The Apache Software Foundation, http://www.apache.org/ Benchmarking lab.test.local (be patient) Completed 10000 requests Completed 20000 requests Completed 30000 requests Completed 40000 requests Completed 50000 requests Completed 60000 requests Completed 70000 requests Completed 80000 requests Completed 90000 requests Completed 100000 requests Finished 100000 requests Server Software: nginx Server Hostname: lab.test.local Server Port: 80 Document Path: /redis_cluster.php Document Length: 0 bytes Concurrency Level: 20 Time taken for tests: 5.314 seconds Complete requests: 100000 Failed requests: 0 Total transferred: 17900000 bytes HTML transferred: 0 bytes Requests per second: 18818.88 [#/sec] (mean) Time per request: 1.063 [ms] (mean) Time per request: 0.053 [ms] (mean, across all concurrent requests) Transfer rate: 3289.63 [Kbytes/sec] received Connection Times (ms) min mean[+/-sd] median max Connect: 0 0 0.1 0 2 Processing: 0 1 1.8 1 213 Waiting: 0 1 1.8 1 212 Total: 0 1 1.8 1 213 Percentage of the requests served within a certain time (ms) 50% 1 66% 1 75% 1 80% 1 90% 1 95% 2 98% 2 99% 3 100% 213 (longest request) 2.5 GET指令 （数据不存在） （OK） # 2.5.1 中间件 # \u0026lt;?php $redis = new Redis(); try{ //connect 是 异常级别 $redis-\u0026gt;connect(\u0026#39;/tmp/redis.socks\u0026#39;); $ret = $redis-\u0026gt;get(\u0026#34;test\u0026#34;); var_dump($ret); }catch (\\Exception $ex){ var_dump($ex-\u0026gt;getMessage()); } 运行结果：bool(false)\n2.5.2 标准集群 # \u0026lt;?php try{ //connect 是 异常级别 $redis = new RedisCluster(NULL, Array(\u0026#34;127.0.0.1:9001\u0026#34;), 1.5, 1.5, true); $ret = $redis-\u0026gt;get(\u0026#34;test\u0026#34;); var_dump($ret); }catch (\\Exception $ex){ var_dump($ex-\u0026gt;getMessage()); } 运行结果：bool(false)\n2.5.3 压测数据对比 # # 中间件 corerman@corerman-WorkStation:~$ ab -n 100000 -c 20 http://lab.test.local/redis_agent.php This is ApacheBench, Version 2.3 \u0026lt;$Revision: 1807734 $\u0026gt; Copyright 1996 Adam Twiss, Zeus Technology Ltd, http://www.zeustech.net/ Licensed to The Apache Software Foundation, http://www.apache.org/ Benchmarking lab.test.local (be patient) Completed 10000 requests Completed 20000 requests Completed 30000 requests Completed 40000 requests Completed 50000 requests Completed 60000 requests Completed 70000 requests Completed 80000 requests Completed 90000 requests Completed 100000 requests Finished 100000 requests Server Software: nginx Server Hostname: lab.test.local Server Port: 80 Document Path: /redis_agent.php Document Length: 12 bytes Concurrency Level: 20 Time taken for tests: 6.012 seconds Complete requests: 100000 Failed requests: 0 Total transferred: 19100000 bytes HTML transferred: 1200000 bytes Requests per second: 16632.40 [#/sec] (mean) Time per request: 1.202 [ms] (mean) Time per request: 0.060 [ms] (mean, across all concurrent requests) Transfer rate: 3102.33 [Kbytes/sec] received Connection Times (ms) min mean[+/-sd] median max Connect: 0 0 0.1 0 2 Processing: 0 1 2.9 1 213 Waiting: 0 1 2.9 1 213 Total: 0 1 2.9 1 213 Percentage of the requests served within a certain time (ms) 50% 1 66% 1 75% 1 80% 1 90% 2 95% 2 98% 3 99% 3 100% 213 (longest request) # 标准集群 corerman@corerman-WorkStation:~$ ab -n 100000 -c 20 http://lab.test.local/redis_cluster.php This is ApacheBench, Version 2.3 \u0026lt;$Revision: 1807734 $\u0026gt; Copyright 1996 Adam Twiss, Zeus Technology Ltd, http://www.zeustech.net/ Licensed to The Apache Software Foundation, http://www.apache.org/ Benchmarking lab.test.local (be patient) Completed 10000 requests Completed 20000 requests Completed 30000 requests Completed 40000 requests Completed 50000 requests Completed 60000 requests Completed 70000 requests Completed 80000 requests Completed 90000 requests Completed 100000 requests Finished 100000 requests Server Software: nginx Server Hostname: lab.test.local Server Port: 80 Document Path: /redis_cluster.php Document Length: 12 bytes Concurrency Level: 20 Time taken for tests: 5.313 seconds Complete requests: 100000 Failed requests: 0 Total transferred: 19100000 bytes HTML transferred: 1200000 bytes Requests per second: 18822.79 [#/sec] (mean) Time per request: 1.063 [ms] (mean) Time per request: 0.053 [ms] (mean, across all concurrent requests) Transfer rate: 3510.89 [Kbytes/sec] received Connection Times (ms) min mean[+/-sd] median max Connect: 0 0 0.1 0 1 Processing: 0 1 2.0 1 212 Waiting: 0 1 2.0 1 212 Total: 0 1 2.0 1 213 Percentage of the requests served within a certain time (ms) 50% 1 66% 1 75% 1 80% 1 90% 1 95% 2 98% 2 99% 3 100% 213 (longest request) 2.6 RPUSH指令 （异常情况）（OK） # 2.6.1 中间件 # \u0026lt;?php $redis = new Redis(); try{ //connect 是 异常级别 $redis-\u0026gt;connect(\u0026#39;/tmp/redis.socks\u0026#39;); $ret = $redis-\u0026gt;rPush(\u0026#34;test\u0026#34;,\u0026#34;val1\u0026#34;); //由于test 键已经和上面的set冲突，所以会出错 var_dump($ret); }catch (\\Exception $ex){ var_dump($ex-\u0026gt;getMessage()); } 运行结果：bool(false)\n2.6.2 标准集群 # \u0026lt;?php try{ //connect 是 异常级别 $redis = new RedisCluster(NULL, Array(\u0026#34;127.0.0.1:9001\u0026#34;), 1.5, 1.5, true); $ret = $redis-\u0026gt;rPush(\u0026#34;test\u0026#34;,\u0026#34;val1\u0026#34;); var_dump($ret); }catch (\\Exception $ex){ var_dump($ex-\u0026gt;getMessage()); } 运行结果：bool(false)\n2.6.3 压测数据对比 # # 中间件 corerman@corerman-WorkStation:~$ ab -n 100000 -c 20 http://lab.test.local/redis_agent.php This is ApacheBench, Version 2.3 \u0026lt;$Revision: 1807734 $\u0026gt; Copyright 1996 Adam Twiss, Zeus Technology Ltd, http://www.zeustech.net/ Licensed to The Apache Software Foundation, http://www.apache.org/ Benchmarking lab.test.local (be patient) Completed 10000 requests Completed 20000 requests Completed 30000 requests Completed 40000 requests Completed 50000 requests Completed 60000 requests Completed 70000 requests Completed 80000 requests Completed 90000 requests Completed 100000 requests Finished 100000 requests Server Software: nginx Server Hostname: lab.test.local Server Port: 80 Document Path: /redis_agent.php Document Length: 12 bytes Concurrency Level: 20 Time taken for tests: 5.777 seconds Complete requests: 100000 Failed requests: 0 Total transferred: 19100000 bytes HTML transferred: 1200000 bytes Requests per second: 17309.96 [#/sec] (mean) Time per request: 1.155 [ms] (mean) Time per request: 0.058 [ms] (mean, across all concurrent requests) Transfer rate: 3228.71 [Kbytes/sec] received Connection Times (ms) min mean[+/-sd] median max Connect: 0 0 0.1 0 2 Processing: 0 1 2.4 1 213 Waiting: 0 1 2.4 1 213 Total: 0 1 2.4 1 213 Percentage of the requests served within a certain time (ms) 50% 1 66% 1 75% 1 80% 1 90% 2 95% 2 98% 2 99% 3 100% 213 (longest request) # 标准集群 corerman@corerman-WorkStation:~$ ab -n 100000 -c 20 http://lab.test.local/redis_cluster.php This is ApacheBench, Version 2.3 \u0026lt;$Revision: 1807734 $\u0026gt; Copyright 1996 Adam Twiss, Zeus Technology Ltd, http://www.zeustech.net/ Licensed to The Apache Software Foundation, http://www.apache.org/ Benchmarking lab.test.local (be patient) Completed 10000 requests Completed 20000 requests Completed 30000 requests Completed 40000 requests Completed 50000 requests Completed 60000 requests Completed 70000 requests Completed 80000 requests Completed 90000 requests Completed 100000 requests Finished 100000 requests Server Software: nginx Server Hostname: lab.test.local Server Port: 80 Document Path: /redis_cluster.php Document Length: 12 bytes Concurrency Level: 20 Time taken for tests: 5.570 seconds Complete requests: 100000 Failed requests: 0 Total transferred: 19100000 bytes HTML transferred: 1200000 bytes Requests per second: 17952.40 [#/sec] (mean) Time per request: 1.114 [ms] (mean) Time per request: 0.056 [ms] (mean, across all concurrent requests) Transfer rate: 3348.54 [Kbytes/sec] received Connection Times (ms) min mean[+/-sd] median max Connect: 0 0 0.1 0 1 Processing: 0 1 1.9 1 210 Waiting: 0 1 1.9 1 210 Total: 0 1 1.9 1 210 Percentage of the requests served within a certain time (ms) 50% 1 66% 1 75% 1 80% 1 90% 1 95% 2 98% 2 99% 3 100% 210 (longest request) 2.7 RPUSH指令 （成功情况）（OK） # 2.7.1 中间件 # \u0026lt;?php $redis = new Redis(); try{ //connect 是 异常级别 $redis-\u0026gt;connect(\u0026#39;/tmp/redis.socks\u0026#39;); $ret = $redis-\u0026gt;rPush(\u0026#34;pushtest1\u0026#34;,\u0026#34;val1\u0026#34;); var_dump($ret); }catch (\\Exception $ex){ var_dump($ex-\u0026gt;getMessage()); } 运行结果：int(1)\n2.7.2 标准集群 # \u0026lt;?php try{ //connect 是 异常级别 $redis = new RedisCluster(NULL, Array(\u0026#34;127.0.0.1:9001\u0026#34;), 1.5, 1.5, true); $ret = $redis-\u0026gt;rPush(\u0026#34;pushtest2\u0026#34;,\u0026#34;val1\u0026#34;); var_dump($ret); }catch (\\Exception $ex){ var_dump($ex-\u0026gt;getMessage()); } 运行结果：int(1)\n2.7.3 压测数据对比 # # 中间件 压测后计数正常 corerman@corerman-WorkStation:~$ ab -n 100000 -c 20 http://lab.test.local/redis_agent.php This is ApacheBench, Version 2.3 \u0026lt;$Revision: 1807734 $\u0026gt; Copyright 1996 Adam Twiss, Zeus Technology Ltd, http://www.zeustech.net/ Licensed to The Apache Software Foundation, http://www.apache.org/ Benchmarking lab.test.local (be patient) Completed 10000 requests Completed 20000 requests Completed 30000 requests Completed 40000 requests Completed 50000 requests Completed 60000 requests Completed 70000 requests Completed 80000 requests Completed 90000 requests Completed 100000 requests Finished 100000 requests Server Software: nginx Server Hostname: lab.test.local Server Port: 80 Document Path: /redis_agent.php Document Length: 7 bytes Concurrency Level: 20 Time taken for tests: 6.132 seconds Complete requests: 100000 Failed requests: 99992 (Connect: 0, Receive: 0, Length: 99992, Exceptions: 0) Total transferred: 18988900 bytes HTML transferred: 1088900 bytes Requests per second: 16307.69 [#/sec] (mean) Time per request: 1.226 [ms] (mean) Time per request: 0.061 [ms] (mean, across all concurrent requests) Transfer rate: 3024.07 [Kbytes/sec] received Connection Times (ms) min mean[+/-sd] median max Connect: 0 0 0.1 0 1 Processing: 0 1 1.7 1 213 Waiting: 0 1 1.7 1 213 Total: 0 1 1.7 1 213 Percentage of the requests served within a certain time (ms) 50% 1 66% 1 75% 1 80% 1 90% 2 95% 2 98% 3 99% 3 100% 213 (longest request) # 标准集群 压测后计数正常 corerman@corerman-WorkStation:~$ ab -n 100000 -c 20 http://lab.test.local/redis_cluster.php This is ApacheBench, Version 2.3 \u0026lt;$Revision: 1807734 $\u0026gt; Copyright 1996 Adam Twiss, Zeus Technology Ltd, http://www.zeustech.net/ Licensed to The Apache Software Foundation, http://www.apache.org/ Benchmarking lab.test.local (be patient) Completed 10000 requests Completed 20000 requests Completed 30000 requests Completed 40000 requests Completed 50000 requests Completed 60000 requests Completed 70000 requests Completed 80000 requests Completed 90000 requests Completed 100000 requests Finished 100000 requests Server Software: nginx Server Hostname: lab.test.local Server Port: 80 Document Path: /redis_cluster.php Document Length: 7 bytes Concurrency Level: 20 Time taken for tests: 5.558 seconds Complete requests: 100000 Failed requests: 99991 (Connect: 0, Receive: 0, Length: 99991, Exceptions: 0) Total transferred: 18988895 bytes HTML transferred: 1088895 bytes Requests per second: 17992.50 [#/sec] (mean) Time per request: 1.112 [ms] (mean) Time per request: 0.056 [ms] (mean, across all concurrent requests) Transfer rate: 3336.50 [Kbytes/sec] received Connection Times (ms) min mean[+/-sd] median max Connect: 0 0 0.1 0 3 Processing: 0 1 2.3 1 213 Waiting: 0 1 2.3 1 213 Total: 0 1 2.4 1 213 Percentage of the requests served within a certain time (ms) 50% 1 66% 1 75% 1 80% 1 90% 1 95% 2 98% 2 99% 3 100% 213 (longest request) 2.8 LPOP指令（OK） # 2.8.1 中间件 # \u0026lt;?php $redis = new Redis(); try{ //connect 是 异常级别 $redis-\u0026gt;connect(\u0026#39;/tmp/redis.socks\u0026#39;); $ret = $redis-\u0026gt;lPop(\u0026#34;pushtest1\u0026#34;); var_dump($ret); }catch (\\Exception $ex){ var_dump($ex-\u0026gt;getMessage()); } 结果：可以正常消费，并且当没有数据后 返回false\n2.8.2 标准集群 # \u0026lt;?php try{ //connect 是 异常级别 $redis = new RedisCluster(NULL, Array(\u0026#34;127.0.0.1:9001\u0026#34;), 1.5, 1.5, true); $ret = $redis-\u0026gt;lPop(\u0026#34;pushtest2\u0026#34;); var_dump($ret); }catch (\\Exception $ex){ var_dump($ex-\u0026gt;getMessage()); } 结果：可以正常消费，并且当没有数据后 返回false\n2.8.3 压测数据对比 # # 中间件 corerman@corerman-WorkStation:~$ ab -n 100000 -c 20 http://lab.test.local/redis_agent.php This is ApacheBench, Version 2.3 \u0026lt;$Revision: 1807734 $\u0026gt; Copyright 1996 Adam Twiss, Zeus Technology Ltd, http://www.zeustech.net/ Licensed to The Apache Software Foundation, http://www.apache.org/ Benchmarking lab.test.local (be patient) Completed 10000 requests Completed 20000 requests Completed 30000 requests Completed 40000 requests Completed 50000 requests Completed 60000 requests Completed 70000 requests Completed 80000 requests Completed 90000 requests Completed 100000 requests Finished 100000 requests Server Software: nginx Server Hostname: lab.test.local Server Port: 80 Document Path: /redis_agent.php Document Length: 17 bytes Concurrency Level: 20 Time taken for tests: 5.839 seconds Complete requests: 100000 Failed requests: 97496 (Connect: 0, Receive: 0, Length: 97496, Exceptions: 0) Total transferred: 19112520 bytes HTML transferred: 1212520 bytes Requests per second: 17126.52 [#/sec] (mean) Time per request: 1.168 [ms] (mean) Time per request: 0.058 [ms] (mean, across all concurrent requests) Transfer rate: 3196.59 [Kbytes/sec] received Connection Times (ms) min mean[+/-sd] median max Connect: 0 0 0.1 0 1 Processing: 0 1 2.7 1 213 Waiting: 0 1 2.7 1 213 Total: 0 1 2.7 1 213 Percentage of the requests served within a certain time (ms) 50% 1 66% 1 75% 1 80% 1 90% 2 95% 2 98% 3 99% 3 100% 213 (longest request) # 标准集群 corerman@corerman-WorkStation:~$ ab -n 100000 -c 20 http://lab.test.local/redis_cluster.php This is ApacheBench, Version 2.3 \u0026lt;$Revision: 1807734 $\u0026gt; Copyright 1996 Adam Twiss, Zeus Technology Ltd, http://www.zeustech.net/ Licensed to The Apache Software Foundation, http://www.apache.org/ Benchmarking lab.test.local (be patient) Completed 10000 requests Completed 20000 requests Completed 30000 requests Completed 40000 requests Completed 50000 requests Completed 60000 requests Completed 70000 requests Completed 80000 requests Completed 90000 requests Completed 100000 requests Finished 100000 requests Server Software: nginx Server Hostname: lab.test.local Server Port: 80 Document Path: /redis_cluster.php Document Length: 17 bytes Concurrency Level: 20 Time taken for tests: 5.419 seconds Complete requests: 100000 Failed requests: 47803 (Connect: 0, Receive: 0, Length: 47803, Exceptions: 0) Total transferred: 19360985 bytes HTML transferred: 1460985 bytes Requests per second: 18453.22 [#/sec] (mean) Time per request: 1.084 [ms] (mean) Time per request: 0.054 [ms] (mean, across all concurrent requests) Transfer rate: 3488.99 [Kbytes/sec] received Connection Times (ms) min mean[+/-sd] median max Connect: 0 0 0.1 0 1 Processing: 0 1 1.8 1 209 Waiting: 0 1 1.8 1 209 Total: 0 1 1.8 1 209 Percentage of the requests served within a certain time (ms) 50% 1 66% 1 75% 1 80% 1 90% 1 95% 2 98% 2 99% 3 100% 209 (longest request) 2.9 MGET指令（OK） # 2.9.1 中间件 # \u0026lt;?php $redis = new Redis(); try{ //connect 是 异常级别 $redis-\u0026gt;connect(\u0026#39;/tmp/redis.socks\u0026#39;); $ret = $redis-\u0026gt;mget([\u0026#34;test1\u0026#34;,\u0026#34;test2\u0026#34;,\u0026#34;test3\u0026#34;,\u0026#34;test4\u0026#34;,\u0026#34;test5\u0026#34;,\u0026#34;test6\u0026#34;,\u0026#34;test7\u0026#34;,\u0026#34;test8\u0026#34;,\u0026#34;test9\u0026#34;,\u0026#34;test10\u0026#34;,\u0026#34;test11\u0026#34;,\u0026#34;test12\u0026#34;,\u0026#34;test13\u0026#34;,\u0026#34;test14\u0026#34;,\u0026#34;test15\u0026#34;,\u0026#34;test16\u0026#34;,\u0026#34;test17\u0026#34;,\u0026#34;test18\u0026#34;,\u0026#34;test19\u0026#34;,\u0026#34;test20\u0026#34;]); var_dump($ret); }catch (\\Exception $ex){ var_dump($ex-\u0026gt;getMessage()); } 运行结果：\narray(20) { [0]=\u0026gt; string(6) \u0026#34;value1\u0026#34; [1]=\u0026gt; string(6) \u0026#34;value2\u0026#34; [2]=\u0026gt; bool(false) [3]=\u0026gt; bool(false) [4]=\u0026gt; bool(false) [5]=\u0026gt; bool(false) [6]=\u0026gt; bool(false) [7]=\u0026gt; bool(false) [8]=\u0026gt; bool(false) [9]=\u0026gt; bool(false) [10]=\u0026gt; bool(false) [11]=\u0026gt; bool(false) [12]=\u0026gt; bool(false) [13]=\u0026gt; bool(false) [14]=\u0026gt; bool(false) [15]=\u0026gt; bool(false) [16]=\u0026gt; bool(false) [17]=\u0026gt; bool(false) [18]=\u0026gt; bool(false) [19]=\u0026gt; bool(false) } 2.9.2 标准集群 # \u0026lt;?php try{ //connect 是 异常级别 $redis = new RedisCluster(NULL, Array(\u0026#34;127.0.0.1:9001\u0026#34;), 1.5, 1.5, true); $ret = $redis-\u0026gt;mget([\u0026#34;test1\u0026#34;,\u0026#34;test2\u0026#34;,\u0026#34;test3\u0026#34;,\u0026#34;test4\u0026#34;,\u0026#34;test5\u0026#34;,\u0026#34;test6\u0026#34;,\u0026#34;test7\u0026#34;,\u0026#34;test8\u0026#34;,\u0026#34;test9\u0026#34;,\u0026#34;test10\u0026#34;,\u0026#34;test11\u0026#34;,\u0026#34;test12\u0026#34;,\u0026#34;test13\u0026#34;,\u0026#34;test14\u0026#34;,\u0026#34;test15\u0026#34;,\u0026#34;test16\u0026#34;,\u0026#34;test17\u0026#34;,\u0026#34;test18\u0026#34;,\u0026#34;test19\u0026#34;,\u0026#34;test20\u0026#34;]); var_dump($ret); }catch (\\Exception $ex){ var_dump($ex-\u0026gt;getMessage()); } 运行结果：\narray(20) { [0]=\u0026gt; string(6) \u0026#34;value1\u0026#34; [1]=\u0026gt; string(6) \u0026#34;value2\u0026#34; [2]=\u0026gt; bool(false) [3]=\u0026gt; bool(false) [4]=\u0026gt; bool(false) [5]=\u0026gt; bool(false) [6]=\u0026gt; bool(false) [7]=\u0026gt; bool(false) [8]=\u0026gt; bool(false) [9]=\u0026gt; bool(false) [10]=\u0026gt; bool(false) [11]=\u0026gt; bool(false) [12]=\u0026gt; bool(false) [13]=\u0026gt; bool(false) [14]=\u0026gt; bool(false) [15]=\u0026gt; bool(false) [16]=\u0026gt; bool(false) [17]=\u0026gt; bool(false) [18]=\u0026gt; bool(false) [19]=\u0026gt; bool(false) } 2.9.3 压测数据对比 # # 中间件 corerman@corerman-WorkStation:~$ ab -n 100000 -c 20 http://lab.test.local/redis_agent.php This is ApacheBench, Version 2.3 \u0026lt;$Revision: 1807734 $\u0026gt; Copyright 1996 Adam Twiss, Zeus Technology Ltd, http://www.zeustech.net/ Licensed to The Apache Software Foundation, http://www.apache.org/ Benchmarking lab.test.local (be patient) Completed 10000 requests Completed 20000 requests Completed 30000 requests Completed 40000 requests Completed 50000 requests Completed 60000 requests Completed 70000 requests Completed 80000 requests Completed 90000 requests Completed 100000 requests Finished 100000 requests Server Software: nginx Server Hostname: lab.test.local Server Port: 80 Document Path: /redis_agent.php Document Length: 478 bytes Concurrency Level: 20 Time taken for tests: 8.120 seconds Complete requests: 100000 Failed requests: 0 Total transferred: 65700000 bytes HTML transferred: 47800000 bytes Requests per second: 12315.93 [#/sec] (mean) Time per request: 1.624 [ms] (mean) Time per request: 0.081 [ms] (mean, across all concurrent requests) Transfer rate: 7901.92 [Kbytes/sec] received Connection Times (ms) min mean[+/-sd] median max Connect: 0 0 0.1 0 1 Processing: 0 1 2.5 1 214 Waiting: 0 1 2.5 1 214 Total: 0 2 2.5 1 215 Percentage of the requests served within a certain time (ms) 50% 1 66% 2 75% 2 80% 2 90% 2 95% 3 98% 3 99% 4 100% 215 (longest request) # 标准集群 corerman@corerman-WorkStation:~$ ab -n 100000 -c 20 http://lab.test.local/redis_cluster.php This is ApacheBench, Version 2.3 \u0026lt;$Revision: 1807734 $\u0026gt; Copyright 1996 Adam Twiss, Zeus Technology Ltd, http://www.zeustech.net/ Licensed to The Apache Software Foundation, http://www.apache.org/ Benchmarking lab.test.local (be patient) Completed 10000 requests Completed 20000 requests Completed 30000 requests Completed 40000 requests Completed 50000 requests Completed 60000 requests Completed 70000 requests Completed 80000 requests Completed 90000 requests Completed 100000 requests Finished 100000 requests Server Software: nginx Server Hostname: lab.test.local Server Port: 80 Document Path: /redis_cluster.php Document Length: 478 bytes Concurrency Level: 20 Time taken for tests: 13.117 seconds Complete requests: 100000 Failed requests: 0 Total transferred: 65700000 bytes HTML transferred: 47800000 bytes Requests per second: 7623.54 [#/sec] (mean) Time per request: 2.623 [ms] (mean) Time per request: 0.131 [ms] (mean, across all concurrent requests) Transfer rate: 4891.28 [Kbytes/sec] received Connection Times (ms) min mean[+/-sd] median max Connect: 0 0 0.0 0 1 Processing: 1 3 2.4 2 213 Waiting: 1 3 2.4 2 213 Total: 1 3 2.4 2 213 Percentage of the requests served within a certain time (ms) 50% 2 66% 3 75% 3 80% 3 90% 4 95% 4 98% 5 99% 5 100% 213 (longest request) 2.10 DEL指令（OK） # 2.10.1 中间件 # \u0026lt;?php $redis = new Redis(); try{ //connect 是 异常级别 $redis-\u0026gt;connect(\u0026#39;/tmp/redis.socks\u0026#39;); $ret = $redis-\u0026gt;mset([\u0026#34;test1\u0026#34;=\u0026gt;\u0026#39;value1\u0026#39;,\u0026#34;test2\u0026#34;=\u0026gt;\u0026#39;value2\u0026#39;]); var_dump($ret); $ret = $redis-\u0026gt;del(\u0026#34;test1\u0026#34;,\u0026#34;test2\u0026#34;,\u0026#34;test3\u0026#34;); var_dump($ret); }catch (\\Exception $ex){ var_dump($ex-\u0026gt;getMessage()); } 运行结果：bool(true) int(2)\n2.10.2 标准集群 # \u0026lt;?php try{ //connect 是 异常级别 $redis = new RedisCluster(NULL, Array(\u0026#34;127.0.0.1:9001\u0026#34;), 1.5, 1.5, true); $ret = $redis-\u0026gt;mset([\u0026#34;test1\u0026#34;=\u0026gt;\u0026#39;value1\u0026#39;,\u0026#34;test2\u0026#34;=\u0026gt;\u0026#39;value2\u0026#39;]); var_dump($ret); $ret = $redis-\u0026gt;del(\u0026#34;test1\u0026#34;,\u0026#34;test2\u0026#34;,\u0026#34;test3\u0026#34;); var_dump($ret); }catch (\\Exception $ex){ var_dump($ex-\u0026gt;getMessage()); } 运行结果：bool(true) int(2)\n2.10.3 压测数据对比 # # 中间件 corerman@corerman-WorkStation:~$ ab -n 100000 -c 20 http://lab.test.local/redis_agent.php This is ApacheBench, Version 2.3 \u0026lt;$Revision: 1807734 $\u0026gt; Copyright 1996 Adam Twiss, Zeus Technology Ltd, http://www.zeustech.net/ Licensed to The Apache Software Foundation, http://www.apache.org/ Benchmarking lab.test.local (be patient) Completed 10000 requests Completed 20000 requests Completed 30000 requests Completed 40000 requests Completed 50000 requests Completed 60000 requests Completed 70000 requests Completed 80000 requests Completed 90000 requests Completed 100000 requests Finished 100000 requests Server Software: nginx Server Hostname: lab.test.local Server Port: 80 Document Path: /redis_agent.php Document Length: 7 bytes Concurrency Level: 20 Time taken for tests: 7.240 seconds Complete requests: 100000 Failed requests: 0 Total transferred: 18600000 bytes HTML transferred: 700000 bytes Requests per second: 13811.28 [#/sec] (mean) Time per request: 1.448 [ms] (mean) Time per request: 0.072 [ms] (mean, across all concurrent requests) Transfer rate: 2508.69 [Kbytes/sec] received Connection Times (ms) min mean[+/-sd] median max Connect: 0 0 0.1 0 1 Processing: 0 1 2.6 1 215 Waiting: 0 1 2.6 1 215 Total: 0 1 2.6 1 215 Percentage of the requests served within a certain time (ms) 50% 1 66% 1 75% 2 80% 2 90% 2 95% 2 98% 3 99% 4 100% 215 (longest request) # 标准集群 corerman@corerman-WorkStation:~$ ab -n 100000 -c 20 http://lab.test.local/redis_cluster.php This is ApacheBench, Version 2.3 \u0026lt;$Revision: 1807734 $\u0026gt; Copyright 1996 Adam Twiss, Zeus Technology Ltd, http://www.zeustech.net/ Licensed to The Apache Software Foundation, http://www.apache.org/ Benchmarking lab.test.local (be patient) Completed 10000 requests Completed 20000 requests Completed 30000 requests Completed 40000 requests Completed 50000 requests Completed 60000 requests Completed 70000 requests Completed 80000 requests Completed 90000 requests Completed 100000 requests Finished 100000 requests Server Software: nginx Server Hostname: lab.test.local Server Port: 80 Document Path: /redis_cluster.php Document Length: 7 bytes Concurrency Level: 20 Time taken for tests: 6.447 seconds Complete requests: 100000 Failed requests: 0 Total transferred: 18600000 bytes HTML transferred: 700000 bytes Requests per second: 15511.04 [#/sec] (mean) Time per request: 1.289 [ms] (mean) Time per request: 0.064 [ms] (mean, across all concurrent requests) Transfer rate: 2817.44 [Kbytes/sec] received Connection Times (ms) min mean[+/-sd] median max Connect: 0 0 0.1 0 1 Processing: 0 1 3.1 1 216 Waiting: 0 1 3.1 1 216 Total: 0 1 3.1 1 216 Percentage of the requests served within a certain time (ms) 50% 1 66% 1 75% 1 80% 1 90% 2 95% 2 98% 3 99% 4 100% 216 (longest request) RedisHub 与 phpredis集群客户端指令效果对比 # 一. set指令 （保持一致） # 正常：true 节点损坏：报异常 clusterDown：返回异常，clusterdown异常 二、mset （保持一致） # 正常 ：true 节点损坏：报异常 clusterDown：返回异常，clusterdown异常 三、get （保持一致） # 正常：数据 节点损坏：报异常 clusterDown：返回异常，clusterdown异常 四、mget （节点损坏时有区别，redishub更合理） # 正常：返回数据 ，无数据时为false 节点损坏： phpredis全部不返回，redishub针对存活的数据节点返回数据，不存活的节点返回nil及false clusterDown：返回异常，clusterdown异常 五、DEL # 正常：返回删除数据量\n节点损坏：phpredis报异常、redishub针对存活的数据节点进行数据删除，并统计数量返回，redishub不报异常\nclusterDown：返回异常，clusterdown异常\n六.rpush指令 （保持一致） # 正常 返回：统计量\n节点损坏：报异常\nclusterDown：返回异常，clusterdown异常\n七.lpop指令 （保持一致） # 正常 返回：统计量 节点损坏：报异常 clusterDown：返回异常，clusterdown异常 "},{"id":17,"href":"/icorer_docs/doccenter/pulseflow/pulgin_designed/2.2/","title":"2.2 数据结构","section":"PulseFlow插件端","content":" 二. 数据结构 # 思来想去，要把这个扩展目前的功能阐述完全，首先我们来描述一下相关数据结构。\n数据结构是扩展运行的基石，如何构造简单的数据结构，既能完整记录相关数据，又能够减少数据查询次数和提高数据进程间传输的便利性。\n2.1 数据结构要求 # 在设计扩展的数据结构时，我们需要保障以下几点。\n数据结构足够简单，便于代码阅读。\n数据结构具有较高效能，最多容忍O(n)复杂度。\n数据结构要便于传输，由于牵扯到IPC通信，所以这个部分特别重要。\n在这基础上，我们设计了三类数据结构，包括：进程全局变量、SVIPC_Func_Struct 和 Function_Prof_Struct 。\n2.2 进程全局变量 # 由于目前我们的进程模型是PHP-FPM，每一个PHP-FPM进程拥有一份独立的全局变量区域，全局变量主要围绕以下几个方面来设计。\nINI配置文件加载变量\n全局数据结构数据\n数据1主要在PHP的 MI生命期阶段进行加载INI配置文件选项，数据2主要是为了完成插件功能而开辟的全局变量。\n2.2.1 扩展配置参数 # 变量名 INI文件配置对应名称 默认值 含义 enabled PulseFlow.enabled false 是否启用插件？ disable_trace_functions PulseFlow.disable_trace_functions 空字符串 禁止跟踪的函数名列表（逗号分割） disable_trace_class PulseFlow.disable_trace_class 空字符串 禁止跟踪的类名列表（逗号分割） svipc_name PulseFlow.svipc_name /PulseFlow_sv_ipc System V IPC 所需要的文件路径名 svipc_gj_id PulseFlow.svipc_pj_id 1000 System V IPC 所需要的项目ID max_package_size PulseFlow.max_package_size 0 组件内部允许的最大消息队列发包大小，超过这个大小进行分包发送 log_dir PulseFlow.log_dir 空字符串 Plugin Log Dir ( 如果此参数不为空，则开启插件日志记录，目前只会记录必要日志信息 ) sampling_rate PulseFlow.sampling_rate 100 采样率，默认是1/100，根据每次请求进行采样隔离 上面所列的参数并不是都需要一一设置，需要对若干参数进行相关解释：\nenabled：这个参数负责控制插件的可用开关，除了【 在php.ini文件中进行设置】 之外， 还可以【 **通过 pulseflow_enable 和*pulseflow_disable 函数进行设置 **】， 还可以【 在url参数中附属get参数 “pulseflowswitch=on” 或 “pulseflowswitch=off”进行选择开关 】。\nsvipc_name：这个参数不是必须设置的参数，如果不设置就必须保障默认值的文件路径在操作系统中存在，并且php-fpm有权限访问。（这个参数代表文件路径，请保障文件存储在不易卸载的位置，tmp、dev目录不推荐）\nsvipc_gj_id：这个参数不是必须进行设置的参数，这个参数和 svipc_name 是一对的，都必须保障和 后端程序配置相同。\nmax_package_size：这个参数用来设置消息队列的最大值，当监控数据的消息体大于此值时进入发送流程。因为为了支持更大的消息队列，需要调整内核参数，~~sysctl -p命令对于不同系别的Linux系统支持力度不同，centos可以不重启加载内核参数，对于其他系统，~~如果出现了sysctl -p 命令无法修改成功内核队列单条信息大小情况时，可以设置这个参数来达到在当前内核环境下发送信息。（这个参数非常重要，请结合内核进行理解） max_package_size参数所牵连的内核消息队列的坑，可以参考文章：https://blog.icorer.com/index.php/archives/334/\n2.3 Function_Prof_Struct 结构体 # 这个结构体针对每一个不同的函数，我们这里定义的不同函数，是指函数名和类名均不同的函数。结构体如下：\ntypedef struct Function_Prof_Struct { char className[CLASS_NAME_MAX_SIZE]; //类名 char functionName[FUNC_NAME_MAX_SIZE]; //函数名 unsigned int memoryUse; //内存消耗 unsigned int cpuTimeUse; //CPU时间消耗 unsigned int refcount; //调用次数 unsigned long funcNameHash; //函数名哈希值 unsigned long classNameHash; //类名哈希值 } Function_Prof_Data; 通过结构体，我们发现我们定义了两个hash字段，这两个哈希采用的是 BKDRHash 字符串，通过这两个字段，我们可以大大提高后期的字符串查询效率。\n2.4 SVIPC_Func_Struct 结构体 # 这个结构体，可以理解为一堆函数小结构体的上层结构体，也是进程间IPC通信所用的公用结构体。结构体如下：\ntypedef struct SVIPC_Func_Struct { long message_type; //System V 消息队列的消息类型字段 char opts[OPTS_STR_MAX_SIZE]; //消息体的附属参数 int size; //函数的数量 Function_Prof_Data Function_Prof_List[FUNCTION_PROF_LIST_SIZE]; //Function_Prof_Struct 结构体数组 } SVIPC_Func_Prof_Message; 特别说明：为了提高组件的控制动态化，我们提供了一个opts附属参数，这个参数通过函数 “pulseflow_set_options” 进行设置，使用样例：pulseflow_set_options(['service'=\u0026gt;'cloudapi']);,这个参数会传入后端程序，后端程序可以根据这个参数进行动态变化，只更新后台程序即可完成一定程度的组件变化。\n2.5 SVIPC_Func_Struct 和 Function_Prof_Struct的关系 # 通过上面的存储结构，我们就可以跟踪每个函数的执行状况。\n2.6 (借力)全局变量的存储区域 # 拒绝反复分配与初始化：我们把 SVIPC_Func_Struct 的空间分配在静态区域，并且设置在MI阶段进行分配与初始化，这样可以保障在后面成千上万的php请求过程中，不需要进程空间分配与初始化。\n拒绝内存泄露：分配在静态资源区还能拒绝内存泄露。\n拒绝序列化与反序列化：IPC通信，序列化操作的性能损耗不容小视，由于拒绝了动态分配，所以拒绝了深度拷贝，拒绝了深度拷贝，就能够更简单的进行IPC传输，由于IPC通信双方共用同一个结构体，所以拒绝了序列化和反序列化过程。\n"},{"id":18,"href":"/icorer_docs/doccenter/ak-2019/designs/1.1/","title":"框架层次设计","section":"系统设计","content":" 一. 框架内部分层关系 # 基于目前的AK-2019框架代码: https://git.icorer.com/APLID/AK-2019\n系统框架在设计上分为4层,相关层次结构从下向上如下图:\n二. 框架各个层次的作用 # TP5.1 层: 引入进来的TP框架,采用其中的ORM和路由部分 AK-Frame层: 这一层是我们重力设计的一部分,这部分主要用来存储内核代码,和业务层完全分开,通过类或者包对外提供服务. APPS层: 这一层是业务代码层,里面每一个文件夹代表一组业务,由于这部分和AK-FRAME已经隔离,所以这里可以存储一组业务,也可以存储多组业务. APPS-FRAME: 这一层介于APPS层和AK-FRAME层,继承自AK-FRAME层,服务于APPS层,这一层主要是预防业务层代码需要定制化AK-FRAME内核. "},{"id":19,"href":"/icorer_docs/doccenter/ak-2019/designs/1.2/","title":"1.2 AK-FRAME设计-Request Handle设计","section":"系统设计","content":"\n"},{"id":20,"href":"/icorer_docs/doccenter/logdarts/designs/1.2/","title":"1.2 代码流程分析","section":"风险分析","content":" 三. 代码流程分析 # 组件模块从代码执行流程上来看，主要包括：\n对象实例化\n数据包组装\n保存数据结构\n发送数据包\n3.1 对象实例化（已审查） # 组件采用单对象实例设计，主要的判断逻辑如下：\n相关模型代码如下：\npublic static function getLoger() { if (!isset(self::$Loger)) { self::$Loger = new self(); } return self::$Loger; } 3.2 数据包组装（构造 $logPacker）（已审查） # 这里的数据包组装并不是直接组装成最终的字符串，而是组装为数据结构体，结构包括metrics_name、typeInfo、指标量这三部分，相关模型代码如下：\npublic static function encode_count_metrics($metrics_name,$serviceName,$labelType=[],$siteName,$countNum=1,$biz_parameter=\u0026#39;\u0026#39;){ $ret = array(); $ret[]=$metrics_name; $part2 = \u0026#39;type=\u0026#39;.implode(\u0026#39;.\u0026#39;,$labelType).\u0026#39;\u0026amp;service=\u0026#39;.$serviceName.\u0026#39;\u0026amp;site=\u0026#39;.$siteName; if (!empty($biz_parameter)){ $part2.=\u0026#39;\u0026amp;biz_parameter=\u0026#39;.$biz_parameter; } $ret[]=$part2; $ret[]=$countNum; return $ret; } 3.3 保存数据结构 （消费 $logPacker）（已审查） # 这个是关键的一步，它的作用在于把数据包结构数据进行再一次结构化，变为真正可用的全局数据结构，总体结构如下图：\n相关代码模型如下：\nprivate function save_count_metrics_log($logPacker) { $log = implode(\u0026#39;|\u0026#39;, $logPacker) . \u0026#34;\\n\u0026#34;; $log_size = strlen($log); switch (self::$PACKER_SAVE_TYPE) { case \u0026#39;STATIC_VAR\u0026#39;: self::$count_metrics_logs[\u0026#39;LOGS_DATA\u0026#39;][\u0026#39;log_str\u0026#39;][] = $log; self::$count_metrics_logs[\u0026#39;LOGS_DATA\u0026#39;][\u0026#39;log_struct\u0026#39;][] = $logPacker; self::$count_metrics_logs[\u0026#39;LOGS_DATA\u0026#39;][\u0026#39;log_length\u0026#39;][] = $log_size; self::$count_metrics_logs[\u0026#39;TOTAL_COUNT\u0026#39;]++; self::$count_metrics_logs[\u0026#39;TOTAL_SIZE\u0026#39;] += $log_size; break; case \u0026#39;SHM\u0026#39;: break; case \u0026#39;APCU\u0026#39;: break; } } 3.4 发送数据包 （通过UDP协议）（已审查） # 数据包采用两种模式进行发送，一种是SIMPLE模式，这种模式是对每一条数据包均进行发送，第二种是GROUP模式，顾名思义就是数据量达到了一定限制后再统一发送，组件默认采用GROUP模式进行发送。\n组件在保存数据结构后会自动出发数据包发送流程，GROUP模式下只有当数据总量达到配置中设置的数据包最大值时才会激发UDP发送过程，残余的数据会在类析构函数中进行发送。\nGROUP发送模式下相关的发送流程如下图所示：\nGROUP发送相关的模型代码如下：\nif (self::$count_metrics_logs[\u0026#39;TOTAL_SIZE\u0026#39;] \u0026gt;= self::$PACKER_MAX_SIZE) { $udpPakData = \u0026#39;\u0026#39;; try { foreach (self::$count_metrics_logs[\u0026#39;LOGS_DATA\u0026#39;][\u0026#39;log_str\u0026#39;] as $key =\u0026gt; $val) { $udpPakData .= $val; $log_size = self::$count_metrics_logs[\u0026#39;LOGS_DATA\u0026#39;][\u0026#39;log_length\u0026#39;][$key]; //垃圾清理 unset(self::$count_metrics_logs[\u0026#39;LOGS_DATA\u0026#39;][\u0026#39;log_str\u0026#39;][$key]); unset(self::$count_metrics_logs[\u0026#39;LOGS_DATA\u0026#39;][\u0026#39;log_length\u0026#39;][$key]); unset(self::$count_metrics_logs[\u0026#39;LOGS_DATA\u0026#39;][\u0026#39;log_struct\u0026#39;][$key]); self::$count_metrics_logs[\u0026#39;TOTAL_COUNT\u0026#39;]--; self::$count_metrics_logs[\u0026#39;TOTAL_SIZE\u0026#39;] -= $log_size; } self::sendUdpPackage(self::$IP, self::$PORT, $udpPakData); //发送UDP return 0; } catch (\\Exception $e) { return $e-\u0026gt;getCode(); //这里返回错误码，而不是继续向上返回异常。 } } "},{"id":21,"href":"/icorer_docs/doccenter/pulseflow/overviews/1.2/","title":"1.2 使用文档","section":"PulseFlow概览","content":" PulseFLow组件 使用文档 # 这篇文档主要进行组件使用方面的介绍。\n一. PHP.INI 文件配置参数 # 变量名 INI文件配置对应名称 默认值 含义 enabled PulseFlow.enabled false 是否启用插件？ disable_trace_functions PulseFlow.disable_trace_functions 空字符串 禁止跟踪的函数名列表（逗号分割） disable_trace_class PulseFlow.disable_trace_class 空字符串 禁止跟踪的类名列表（逗号分割） svipc_name PulseFlow.svipc_name /PulseFlow_sv_ipc System V IPC 所需要的文件路径名 svipc_gj_id PulseFlow.svipc_pj_id 1000 System V IPC 所需要的项目ID max_package_size PulseFlow.max_package_size 0 组件内部允许的最大消息队列发包大小，超过这个大小进行分包发送 log_dir PulseFlow.log_dir 空字符串 Plugin Log Dir ( 如果此参数不为空，则开启插件日志记录，目前只会记录必要日志信息 ) sampling_rate PulseFlow.sampling_rate 100 采样率，默认是1/100，根据每次请求进行采样隔离 上面所列的参数并不是都需要一一设置，需要对若干参数进行相关解释：\nenabled：这个参数负责控制插件的可用开关，除了【 在php.ini文件中进行设置】 之外， 还可以【 **通过 pulseflow_enable 和*pulseflow_disable 函数进行设置 **】， 还可以【 在url参数中附属get参数 “pulseflowswitch=on” 或 “pulseflowswitch=off”进行选择开关 】。\nsvipc_name：这个参数不是必须设置的参数，如果不设置就必须保障默认值的文件路径在操作系统中存在，并且php-fpm有权限访问。（这个参数代表文件路径，请保障文件存储在不易卸载的位置，tmp、dev目录不推荐）\nsvipc_gj_id：这个参数不是必须进行设置的参数，这个参数和 svipc_name 是一对的，都必须保障和 后端程序配置相同。\nmax_package_size：这个参数用来设置消息队列的最大值，当监控数据的消息体大于此值时进入发送流程。因为为了支持更大的消息队列，需要调整内核参数，~~sysctl -p命令对于不同系别的Linux系统支持力度不同，centos可以不重启加载内核参数，对于其他系统，~~如果出现了sysctl -p 命令无法修改成功内核队列单条信息大小情况时，可以设置这个参数来达到在当前内核环境下发送信息。（这个参数非常重要，请结合内核进行理解） max_package_size参数所牵连的内核消息队列的坑，可以参考文章：https://blog.icorer.com/index.php/archives/334/\n二. 组件函数介绍 # PulseFlow组件对PHP脚本提供了若干个函数，分别包括： 对于扩展函数的使用，一定要先判断函数是否存在后再进行调用。\n函数名 函数介绍 函数使用样例 附属介绍 pulseflow_enable 启用插件 pulseflow_enable() 插件默认是关闭状态，可以通过INI文件配置PulseFlow.enabled参数进行开启，也可以在PHP代码中使用这个函数进行开启 pulseflow_disable 关闭插件 pulseflow_disable() 可以在PHP代码中通过这个函数进行插件功能的禁用 pulseflow_set_options 设置插件附属选项 pulseflow_set_options([\u0026lsquo;services\u0026rsquo;=\u0026gt;\u0026lsquo;API2017\u0026rsquo;]); 可以在PHP代码中通过这个函数进行附属信息的设置 pulseflow_output_trace_list 输出跟踪信息到页面 pulseflow_output_trace_list(); 这个参数 只会在URL参数 pulseflow_switch值为on的情况下起效果 pulseflow_set_options 这个函数很重要，通过PHP脚本使用这个函数，插件会把函数中的数组进行序列化传到后台程序和下游服务中，这样可以实现动态化参数。(JAVA 天眼下游服务必需service参数，可以通过传入数组进行动态添加)\n二. 组件 URL 参数介绍 # PulseFlow组件除了提供 php.ini 参数、组件函数之外，还提供了URL Get参数配置。\nGET参数名 参数介绍 参数使用样例 附属介绍 pulseflow_switch=on 强制启用插件 http://127.0.0.1/debug.php?pulseflow_switch=on 通过这个参数可以强制开启插件跟踪功能 pulseflow_switch=off 强制关闭插件 http://127.0.0.1/debug.php?pulseflow_switch=off 通过这个参数可以强制关闭插件跟踪功能 pulseflow_web_display_switch=on 输出性能跟踪信息到网页 http://127.0.0.1/debug.php?pulseflow_switch=on\u0026amp;pulseflow_web_display_switch=on 这个参数 只会在 pulseflow_switch参数为on的情况下起效果 "},{"id":22,"href":"/icorer_docs/doccenter/redishub/designs/1.2/","title":"1.2配置解析器","section":"系统设计","content":" 1.2 配置解析器设计 # Agent配置器, 主要负责解析来自网络 或者 文件系统中的配置文件,目前提供配置文件解析模块,配置解析器设计主要包括以下部分:\n配置信息元素结构. 配置解析器相关解析函数. 配置解析器对外API接口服务,允许动态更新配置. 组成结构图如下: 1.2.1 配置信息元素 # 随着系统功能的不断丰富,系统的配置项目也会越来越多,目前配置解析器主要解析的数据对象包括:\n网络配置项 : 针对中间件网络监听进行配置。 redis集群配置项：针对Redis集群进行配置。 日志配置项：目前提供kafka或日志输出，kafka支持公司标准日志。 1.2.2 配置样例 # #RedisHub YAML config file #RedisHub Net Config net: listen_uri: unix:/var/run/redis.sock #Unix Domain Socket的监听路径：PHP推荐使⽤这种模式 # listen_uri: tcp:10.100.183.180:16379 #TCP的监控IP及端⼝ #RedisHub cluster Config cluster: start_nodes:node1,node2,node3 #Redis集群的节点，这⾥可以根据线上实际情况进⾏配置，多个只是为了保障⾼可⽤ conn_timeout: 200 #Redis节点的TCP连接超时时间 （单位：毫秒） conn_read_timeout: 50 #Redis节点的TCP读取超时时间 （单位：毫秒） conn_write_timeout: 50 #Redis节点的TCP写⼊超时时间 （单位：毫秒） conn_alive_timeout: 60 #Redis节点的TCP最⼤空闲时间 （单位：秒） conn_pool_size: 200 #针对每⼀个Redis集群节点的TCP连接池最⼤值 （单位：个） #RedisHub api config api: http_listen_address: #RedisHub log config # log 相关配置 log: # 日否开启日志 enable: true # 日志输出位置，支持std(终端) kafka # 注：std仅在调试时使用 output: \u0026#34;kafka\u0026#34; # kafka server的地址 需要修改到指定环境的kafka kafka_address: [\u0026#34;10.166.7.139:9092\u0026#34;, \u0026#34;10.166.7.139:9093\u0026#34;, \u0026#34;10.166.7.139:9094\u0026#34;] kafka_info_topic: \u0026#34;ltlog-info\u0026#34; kafka_error_topic: \u0026#34;ltlog-error\u0026#34; # 日志输出级别控制, 可省略, 默认输出到 error 级别 # 高级别的可以输出低级别的日志， 级别 trace \u0026gt; debug \u0026gt; error \u0026gt; warning \u0026gt; info # 例如 level = error时，不可输出trace和debug级别的日志 level: \u0026#34;debug\u0026#34; # 日志中是否报告函数调用信息,可省略 默认为false report_call: false # 机器ip，可为空，默认自动查找 ip: \u0026#34;\u0026#34; # 机器hostname，可为空，默认自动查找 hostname: \u0026#34;\u0026#34; # app_name 默认为 RedisHub app_name: \u0026#34;RedisHub\u0026#34; # 周期上报redis执行信息 （单位：秒） heartbeat_report_second: 120 "},{"id":23,"href":"/icorer_docs/doccenter/redistun/designs/1.2/","title":"1.2配置解析器","section":"系统设计","content":" 1.2 配置解析器设计 # Agent配置器, 主要负责解析来自网络 或者 文件系统中的配置文件,目前提供配置文件解析模块,配置解析器设计主要包括以下部分:\n配置信息元素结构. 配置解析器相关解析函数. 配置解析器对外API接口服务,允许动态更新配置. 组成结构图如下: 1.2.1 配置信息元素 # 随着系统功能的不断丰富,系统的配置项目也会越来越多,目前配置解析器主要解析的数据对象包括:\n系统通用配置 : 对系统的通用配置进行解析 网络组配置 : 对通信组件中需要使用的redis集群组进行配置 1.2.2 配置样例 # local_unix_common_uri: /home/corerman/DATA/ICODE/GoLang/RedisTunel-go/bin/unix/ api_http_listen_uri: 127.0.0.1:10000 redis_group_list: - server_name: redis-pool1 group_id : 1 is_enable: true local_unix_name: redis1 master_server : 127.0.0.1:6379 master_conn_pool_size:10,20 master_conn_idle_time_out: 200 slave_server : 127.0.0.1:6380,127.0.0.1:6381,127.0.0.1:6382,127.0.0.1:6383 slave_conn_pool_size:30,40 slave_conn_idle_time_out: 200 - server_name: redis-pool2 group_id : 2 is_enable: true local_unix_name: redis2 master_server : 127.0.1.1:6379 master_conn_pool_size:10,20 master_conn_idle_time_out: 200 slave_server : 127.0.1.1:6380,127.0.1.1:6381,127.0.1.1:6382,127.0.1.1:6383 slave_conn_pool_size:30,40 slave_conn_idle_time_out: 200 上面的配置文件中,配置了两个redis group,每个group中包含主从关系,用来读写分离,也针对每个主从的网络连接配置了相关的连接池配置.\n1.2 解析器工作流程 # 配置解析器有两个加载部分,第一部分在程序初始化阶段,但是这种情况无法做到后期动态更新配置,所以配置解析器还会对外提供api接口,用于更新内部配置 , 相关流程结构图如下:\n"},{"id":24,"href":"/icorer_docs/doccenter/pulseflow/pulgin_designed/2.3/","title":"2.3 功能流程","section":"PulseFlow插件端","content":"\n"},{"id":25,"href":"/icorer_docs/doccenter/ak-2019/designs/1.3/","title":"1.3 AK-FRAME设计-Request Handle设计阐述","section":"系统设计","content":"Request Handle 顾名思义 ,它的主要职责用来承载用户API请求,基于这个包将会衍生出框架的控制器基础类，也可以让当前类成为控制器基础类，控制器基础类将被每个实体业务控制器继承,所以它处在AK-FRAME层面.\n所以在AK-FRAME层面,我们有request目录用来存储request相关的类实现文件,配置文件,相关工具包文件.\n一. 工作流程组成部分 # 1.1 Request-Handle 模块设计图 # Request-Handle 模块主要包括 请求合法性检测、请求数据体分析、权限校验等模块组成，相关具体的模块设计图如下所示：\n二. 相关组件介绍 # 2.1 Request-Handle组件类 # 为了把Request模块统一打包对外服务，所以这里我们需要把Request-Handle组件抽象为一个RequestHandle类，这个类主要包含一些相关模块方法，可以被外部类引用，在请求校验阶段做出贡献。\n2.2 请求合法性检测 # 对于网络请求来源复杂，我们首先不能让请求轻易进入消耗计算机资源的环节，所以这部分很关键，但是这部分具有很强的不确定性。因为随着计算机技术的发展，爬虫技术等模拟技术，黑客攻击的升级，这部分可能面临着修改的可能性，因此这部分除了进行基础的请求过滤外，还需要留下相关的扩展函数，便于后期进行调整。\n请求合法性检测在实现层是RequestHandle类的一个函数，函数名为checkRequest，这个函数主要完成两部分工作。\n路由放行：调用RequestHandle类子函数isRouteIgnore，这个部分主要检查当前请求的控制器和方法是不是在路由忽略列表，如果在列表内，则放过这个请求，这个应用场景主要针对一些权限初始化接口，比如用户登录、获取token 接口。\n请求参数校验：调用RequestHandle类子函数checkHeader，这个部分主要对于header头部参数里的一些约定条件进行检测，目前主要包括的参数包括JWT令牌数据、请求来源from参数，这两个检测过程均为调用RequestHandle内部函数。\n2.2.1 JWT组件包 # JWT 是通用令牌协议，基于JWT可以做用户安全校验、同时开源社区提供了相关的代码包，可以帮助系统框架快速构建JWT令牌模块。\n但是，在安装了JWT包后，我们不能直接使用开源社区的裸包，我们需要在AK-FRAME封装JWT子模块，子模块主要提供生成JWT和解析JWT的代码包，JWT封装层注意封装的用户单元信息不要采用uid，要采用用户名，便于后期做分布式系统，基于用户名的JWT，可以在各个系统之间可以做到统一登录。\n校验JWT模块，这个是JWT包中的一个方法，名称为checkJWT，这个函数在RequestHandle类子函数checkHeader中被调用，主要对header头部传输进来的JWT数据做数据段的检验，包括JWT长度，和相关数据段拆分，如果JWT验证成功，则要把拆分后的数据体组成数组返回上一级，便于上一级函数把数据加载进控制器基础类相关属性。\n2.2.2 请求参数匹配函数（filterRequestParames方法） # 需要在 RequestHandle类中实现出请求参数匹配函数，这个是一个扩展单元，目前可以在函数内部仅仅做header部分的from参数判断，比如参数值可以为app，web，wechat，如果不在列表，则返回false，由上级接收到返回值后决定是否放行请求，在以后可能会对更多的请求参数进行过滤，这个函数将起到过滤效果。\n2.3 请求数据体分析（getRequestData方法） # 如果上面的流程已经顺利通过，那么这个请求在安全程度上已经是合法的了，那么将进行非常重要的两部分操作。\n这个方法将调用ak-frame中的request目录下的requestData工具类，\n请求数据体抽取：对于request 请求体的相关参数进行抽取，这部分是requestData工具类的实现，这个工具类基于TP5.1的request部分做了一层封装，提供一些基础方法，比如findGetDataByKey,findPostDataByKey等，这层封装既可以满足已经定制化请求数据，还可以降级对于TP框架的耦合度。\n检查路由权限：这部分流程则需要检查当前请求所处的路由是够属于前面部分解析的JWT所对应的用户拥有的权限，首先会取出控制器基础类中的用户名，然后去缓存中查询是否有对应的用户权限，如果没有则调用权限包中的权限分析方法对于JWT解析出的用户名进行权限获取，如果已经存在则把缓存权限取出来，这两条线路最终都需要对于当前路由和用户权限列表中进行搜索，如果找到则放行，否则就拒绝访问。\n"},{"id":26,"href":"/icorer_docs/doccenter/logdarts/designs/1.3/","title":"1.3 异常监控分析","section":"风险分析","content":"组件也包含异常监控部分，但是为了减少对于业务代码的影响，在异常监控部分进行了改造：\n组件内部通过异常机制进行错误跟踪。 组件和外部调用之间通过错误码进行状态反馈。 组件内部的异常产生主要集中于 初始化配置 和 UDP发送两大部分，目前对这两部分进行了调整。\n4.1初始化配置 （已审查） # 初始化配置主要作用是分析配置文件，根据配置文件内容初始化相关的环境参数，配置过程在一个PHP生命期内只会进行一次，这部分代码已经调整为错误码返回，相关的模型代码样例如下：\nif (!is_array(self::$EXCEPTION_LIST) || empty(self::$EXCEPTION_LIST[\u0026#39;CLIENT_CONFIG\u0026#39;])) { // throw new \\Exception(\u0026#39;Exception List File is Lose\u0026#39;, 1000); //原来采用抛出异常 return FILE_NOT_FOUND_ERR; //现在采用返回错误码 } else { self::$CLIENT_EXCEPTION_LIST = self::$EXCEPTION_LIST[\u0026#39;CLIENT_CONFIG\u0026#39;]; } 这种调整可以有效降低组件代码和业务系统的耦合性。\n4.2 UDP发送（已审查） # UDP发送函数内部仍然采用异常机制进行上报异常，但是在组件内部调用UDP发送函数时，如果抓取到异常，会向外层反馈异常错误码，而不是继续抛出异常。\n#总结 以上两个部分的代码逻辑已经完全审核。\n"},{"id":27,"href":"/icorer_docs/doccenter/redishub/designs/1.3/","title":"1.3通信组件","section":"系统设计","content":" 1.3 通信组件设计 # 通信组件目前不包括协议解析部分,这里的通信组件就是纯粹的网络通信层设计.\n1.3.1 通信组件组成部分 # 目前网络通信层分为两部分:\n本地UNIX监听组,用于高速的IPC通信 每个UNIX监听组所对应一组远端redis服务器,分别对于主从进行连接池连接. 1.3.1 通信组件链路结构 # RedisHub很重要的是网络代理部分,在网络代理方面由三部分组成.\n第一部分是对远程redis集群的连接池. 第二部分是对本地众多php-fpm客户端的UNIX请求连接管理. 第三部分是对这三端之间redis通信协议进行兼容. "},{"id":28,"href":"/icorer_docs/doccenter/redistun/designs/1.3/","title":"1.3通信组件","section":"系统设计","content":" 1.3 通信组件设计 # 通信组件目前不包括协议解析部分,这里的通信组件就是纯粹的网络通信层设计.\n1.3.1 通信组件组成部分 # 目前网络通信层分为两部分:\n本地UNIX监听组,用于高速的IPC通信 每个UNIX监听组所对应一组远端redis服务器,分别对于主从进行连接池连接. 1.3.1 通信组件链路结构 # Redis-Tunel很重要的是网络代理部分,在网络代理方面由三部分组成.\n第一部分是对远程redis-server的连接池. 第二部分是对本地众多php-fpm客户端的UNIX请求连接管理. 第三部分是对这三端之间redis通信协议进行兼容. "},{"id":29,"href":"/icorer_docs/doccenter/redishub/designs/1.4/","title":"1.4 协议解析器与拦截器","section":"系统设计","content":" 1.4 协议解析器与拦截器 # 作为网络中间件,我们需要针对网络数据包进行读取之外,还需要对数据包进行解析工作,基于redis协议做了解析之后,我们还需要在解析器的基础上做拦截器,针对不同的redis做不同的处理流程.\n1.4.1 协议解析器设计 # 协议解析器,是一个单独的模块,它主要针对网络数据包进行redis协议的解析工作,虽然redis协议具有统一的数据格式,但是还需要对每种协议命令做兼容操作.\n1.4.2 协议解析器构成成分 # redis协议解析器 : 主要用来解析redis协议 (decoder) redis协议编码器 : 主要用来组装redis协议 (encoder) 1.4.3 解析器 和 拦截器 的工作流程 配合 # 这两个重要组件的功能流程配合如下:\n[PHP-FPM请求] \u0026ndash;\u0026gt;** [RedisHub中间件]** \u0026ndash;\u0026gt; (读取数据包) \u0026ndash;\u0026gt; (解析数据包协议) \u0026ndash;\u0026gt; (对指定命令进行拦截操作) \u0026mdash;\u0026gt; (转发下游redis服务) \u0026ndash;\u0026gt; [下游redis集群] \u0026ndash;\u0026gt; (处理命令并响应) \u0026ndash;\u0026gt; [RedisHub中间件] \u0026mdash;\u0026gt; (响应请求) \u0026mdash;\u0026gt;** [PHP-FPM]**\n"},{"id":30,"href":"/icorer_docs/doccenter/redistun/designs/1.4/","title":"1.4 协议解析器与拦截器","section":"系统设计","content":" 1.4 协议解析器与拦截器 # 作为网络中间件,我们需要针对网络数据包进行读取之外,还需要对数据包进行解析工作,基于redis协议做了解析之后,我们还需要在解析器的基础上做拦截器,针对不同的redis做不同的处理流程.\n1.4.1 协议解析器设计 # 协议解析器,是一个单独的模块,它主要针对网络数据包进行redis协议的解析工作,虽然redis协议具有统一的数据格式,但是还需要对每种协议命令做兼容操作.\n1.4.2 协议解析器构成成分 # redis协议解析器 : 主要用来解析redis协议 (decoder) redis协议编码器 : 主要用来组装redis协议 (encoder) 1.4.3 解析器 和 拦截器 的工作流程 配合 # 这两个重要组件的功能流程配合如下:\n[PHP-FPM请求] \u0026ndash;\u0026gt;** [RedisTunel中间件]** \u0026ndash;\u0026gt; (读取数据包) \u0026ndash;\u0026gt; (解析数据包协议) \u0026ndash;\u0026gt; (对指定命令进行拦截操作) \u0026mdash;\u0026gt; (转发下游redis服务) \u0026ndash;\u0026gt; [下游redis服务] \u0026ndash;\u0026gt; (处理命令并响应) \u0026ndash;\u0026gt; [RedisTunel中间件] \u0026mdash;\u0026gt; (响应请求) \u0026mdash;\u0026gt;** [PHP-FPM]**\n"},{"id":31,"href":"/icorer_docs/doccenter/ak-2019/designs/1.4/","title":"1.4 权限设计-最小操作与功能单元","section":"系统设计","content":"在设计统一权限系统之前,我们需要思考第一个问题,在系统权限层次上,到底哪些部分是实体,哪些部分是虚体? 比如你去公司上班,公司具有门禁系统,你需要刷卡入门,假设你需要穿过5道门,想一下在这些动作中,是如何归并你的权限范围的.\n在这些门禁中,都相当于一个操作,每个操作都有不同的标识符,你拥有的标识符越多,你就拥有越多的权限. 现在思考一下目前操作系统中比较流行的RBAC或者基于用户权限这种比较流行的权限系统,都是在不断的给用户赋予标识符,所以我们的新权限系统中首先需要思考第一个问题,我们系统中最小的操作实体是什么?\n一. 最小操作单元 # 最小操作单元,顾名思义就是系统最小能够对外提供服务的功能元素,我们是API后台系统,所以针对新版系统,最小操作单元就是一个个API,这是系统的最小控制力度.\n最小操作单元在数据表存储为一张单表,单表必须存在下面相关字段:\nid : 序号 name : 最小操作单元名称(必须英文,以后应对分布式) name_comment : (name英文所对应的中文) module : API的module部分 controller : API的控制器名称 method : API的方法名称 comment : 描述 二. 最小功能单元 # 最小操作单元是孤零零的API,这是系统的最小实体,但是这个力度太小,所以不能成为养老服务库中的功能单元,所以我们还需要在最小操作单元的基础上聚合成一个个最小功能单元,最小功能单元组装成服务库.\n系统功能单元，就是最小操作单元的聚合体，在数据存储结构上也是一张单表,单表必须存在下面相关字段:\nid : 序号 name : 功能名称 (必须英文,以后应对分布式) name_comment: (name英文所对应的中文) ids : 最小操作单元的id集合(逗号分割) ids_name : ids所对应的最小操作单元英文名称列表(逗号分割,以后应对分布式) comment : 功能单元描述. 三. 两者间关系 # 下图描述最小功能单元与最小操作单元间关系.\n下面以老人管理功能为例。\n"},{"id":32,"href":"/icorer_docs/doccenter/redishub/designs/1.5/","title":"1.5 NetHandle组件","section":"系统设计","content":" NetHandle # 这是一个库,方便构建高性能TCP服务端应用程序,站在Go语言的巨人肩膀上\n项目地址: uriModule/NetHandle\n一. 特点 # 高性能,低资源消耗 非常简单易用的开发接口 支持众多协议,TCP,UDP,UNIX 二. 安装 # go get -u moduleUri/NetHandle\n三. 性能测试: # 3.1 50*10000 (50线程 X 10000请求) # 3.2 50*20000 (50线程 X 20000请求) # 3.3 100*10000 (100线程 X 10000请求) # 四. 样例代码: # 使用这个库的时候,只需要自定义简单的回调函数,即可构造出性能强悍的网络监听.\npackage main import ( \u0026#34;fmt\u0026#34; \u0026#34;moduleUri/NetHandle\u0026#34; \u0026#34;log\u0026#34; \u0026#34;sync\u0026#34; ) var addrTcp = \u0026#34;127.0.0.1:10000\u0026#34; func main() { log.SetFlags(log.Lshortfile | log.LstdFlags) var mu sync.RWMutex count := 0 go log.Printf(\u0026#34;started server at %s\u0026#34;, addrTcp) err := NetHandle.ListenAndServe(\u0026#34;tcp\u0026#34;, addrTcp, func(conn NetHandle.Conn) { requestData := make([]byte, 512) _, err := conn.NetConn().Read(requestData) if err != nil { conn.Close() return } mu.Lock() count++ mu.Unlock() countCurrent := 0 mu.RLock() countCurrent = count mu.RUnlock() replyData := fmt.Sprintf(\u0026#34;%d\\r\\n\u0026#34;, countCurrent) conn.NetConn().Write(append([]byte(replyData))) }, func(conn NetHandle.Conn) bool { // use this function to accept or deny the connection. log.Printf(\u0026#34;accept: %s\u0026#34;, conn.RemoteAddr()) return true }, func(conn NetHandle.Conn, err error) { // this is called when the connection has been closed log.Printf(\u0026#34;closed: %s, err: %v\u0026#34;, conn.RemoteAddr(), err) }, ) if err != nil { log.Fatal(err) } } "},{"id":33,"href":"/icorer_docs/doccenter/redistun/designs/1.5/","title":"1.5 NetHandle组件","section":"系统设计","content":" NetHandle # 这是一个库,方便构建高性能TCP服务端应用程序,站在Go语言的巨人肩膀上\n项目地址: uriModule/NetHandle\n一. 特点 # 高性能,低资源消耗 非常简单易用的开发接口 支持众多协议,TCP,UDP,UNIX 二. 安装 # go get -u moduleUri/NetHandle\n三. 性能测试: # 3.1 50*10000 (50线程 X 10000请求) # 3.2 50*20000 (50线程 X 20000请求) # 3.3 100*10000 (100线程 X 10000请求) # 四. 样例代码: # 使用这个库的时候,只需要自定义简单的回调函数,即可构造出性能强悍的网络监听.\npackage main import ( \u0026#34;fmt\u0026#34; \u0026#34;moduleUri/NetHandle\u0026#34; \u0026#34;log\u0026#34; \u0026#34;sync\u0026#34; ) var addrTcp = \u0026#34;127.0.0.1:10000\u0026#34; func main() { log.SetFlags(log.Lshortfile | log.LstdFlags) var mu sync.RWMutex count := 0 go log.Printf(\u0026#34;started server at %s\u0026#34;, addrTcp) err := NetHandle.ListenAndServe(\u0026#34;tcp\u0026#34;, addrTcp, func(conn NetHandle.Conn) { requestData := make([]byte, 512) _, err := conn.NetConn().Read(requestData) if err != nil { conn.Close() return } mu.Lock() count++ mu.Unlock() countCurrent := 0 mu.RLock() countCurrent = count mu.RUnlock() replyData := fmt.Sprintf(\u0026#34;%d\\r\\n\u0026#34;, countCurrent) conn.NetConn().Write(append([]byte(replyData))) }, func(conn NetHandle.Conn) bool { // use this function to accept or deny the connection. log.Printf(\u0026#34;accept: %s\u0026#34;, conn.RemoteAddr()) return true }, func(conn NetHandle.Conn, err error) { // this is called when the connection has been closed log.Printf(\u0026#34;closed: %s, err: %v\u0026#34;, conn.RemoteAddr(), err) }, ) if err != nil { log.Fatal(err) } } "},{"id":34,"href":"/icorer_docs/doccenter/ak-2019/designs/1.5/","title":"1.5 权限设计-系统结构设计","section":"系统设计","content":" 系统结构设计 # 一. 系统总体结构图 # 二. 系统 # 目标：构建一个千变万化的系统结构。 首先系统和目录是虚拟的，可以随意构造。通过选取功能库中的功能，来建立不同的系统。\n系统在数据表存储为一张单表,单表必须存在下面相关字段:\nid : 序号 name : 系统名称 comment : 描述 三. 目录(功能) # 功能菜单不在是之前的三级权限，功能可以停止在任意目录级别, 根据type进行类别判断。当type为func时，此目录为功能层。\n目录（功能），在数据存储结构上也是一张单表,单表必须存在下面相关字段:\nid : 序号 system_id : 系统id name: 目录名称 par_id : 上级目录id type : 目录类别 （dir-目录、func-功能） comment : 功能单元描述. 四. 系统结构构建流程 # 下图描述系统结构的关联： "},{"id":35,"href":"/icorer_docs/doccenter/redistun/designs/1.6/","title":"1.6 哈希分操器组件","section":"系统设计","content":" 背景描述: # 哈希分槽器,顾名思义,它的主要工作就是根据redis协议中的key值进行哈希计算,并选择相关的存储节点,在不同的节点上完成redis数据的读写操作.\n通过上面的描述,我们可以看出,哈希分槽器主要的设计部分包括如下:\n数据分槽器 : 基于一致性哈希算法,负责key值的落槽工作,每个槽对应一个redis group 单元. 哈希结构及算法 : 需要减少节点添加删除造成的缓存失效问题,所以采用一致性哈希算法. 一. 数据分槽器(Slots) # 在RedTun设计下, 数据分槽器属于Neter的一部分,主要是面向网络组进行服务,数据分槽器前后沟通了一致性哈希算法,服务器group节点,redis客户端请求这三方,是用户的请求可以通过一致性哈希算法准确落到指定的redis group内,响应的group负责读写分离.\n1.1 用户数据分槽流程 # 1.2 分槽器实现 # 为了兼容线上环境,分槽器目前的一致性哈希算法实现高度参考predis的hashring,采用crc32 IEEE作为hash的值计算算法,采用uint32作为hash环的大小.\n1.3 算法兼容性测试 # 为了保障RedTun的一致性哈希算法 和 线上环境predis的一致性哈希算法一致,避免缓存大量失效的情况,目前我们针对这两个算法实现做了单元测试:\n测试总量: **8529820次 ** 随机 key 的哈希生成与结果匹配.\n测试异常: 0次\n总共进行了800多万次测试,两个语言的算法实现没有出现差异结果,说明RedTun内部的一致性哈希算法已经和线上高度一致,不会造成失效问题.\n1.4 一致性哈希的相关数据结构优化 # 1.4.1 哈希环的hash key选择 # 一致性哈希中,每个key的稳定性决定了哈希环上节点位置的稳定性,所以,在RedTun中,对于hash key的选择没有粗略的选择 IP:PORT , 而是在用户配置区间为每个GROUP提供了一个名字叫做\u0026quot;hash_ring_key\u0026quot; , 根据这个字段内的数据进行哈希环的构造.\n二 . 哈希结构及算法 # 现在我们需要设计一个哈希结构,这个哈希结构能够把各个redis group节点映射上来,并且这个哈希结构具有较高的稳定性,当添加或者删除相关的group节点时,不会造成哈希映射的大规模失效.在上述的需求下,我们选择了一致性哈希这个算法.\n2.1 一致性哈希相关解释 # 关于一致性哈希的描述,各处都有比较完善的文章,下面主要摘抄部分来阐述一致性哈希的关键点.\n其实，⼀致性哈希算法也是使⽤取模的⽅法，只是，刚才描述的取模法是对服务器的数量进⾏取模，⽽⼀致性哈希算法是对2^32取模.⾸先，我们把⼆的三⼗⼆次⽅想象成⼀个圆，就像钟表⼀样，钟表的圆可以理解成由60个点组成的圆，⽽此处我们把这个圆想象成由2^32个点组成的圆，⽰意图如下:\n圆环的正上⽅的点代表0，0点右侧的第⼀个点代表1，以此类推，2、3、4、5、6……直到2^32-1,也就是说0点左侧的第⼀个点代表2^32-1,我们把这个由2的32次⽅个点组成的圆环称为hash环,假设我们有3台缓存服务器，服务器A、服务器B、服务器C，那么这三台服务器肯定有⾃⼰的IP地址，我们使⽤它们各⾃的IP地址进⾏哈希计算，使⽤哈希后的结果对2^32取模，可以使⽤如下公式⽰意。 hash（服务器A的IP地址） % 2^32\n通过上述公式算出的结果⼀定是⼀个0到2^32-1之间的⼀个整数，我们就⽤算出的这个整数，代表服务器A，既然这个整数肯定处于0到2^32-1之间，那么，上图中的有⼀个点与这个整数对应，⽽我们刚才已经说明，使⽤这个整数代表服务器A，那么，服务器A就可以映射到这个环上，⽤下图⽰意.\n同理，服务器B与服务器C也可以通过相同的⽅法映射到上图中的hash环中\nhash（服务器B的IP地址） % 2^32\nhash（服务器C的IP地址） % 2^32\n通过上述⽅法，可以将服务器B与服务器C映射到上图中的hash环上，⽰意图如下\n假设，我们需要使⽤缓存服务器缓存图⽚，⽽且我们仍然使⽤图⽚的名称作为找到图⽚的key，那么我们使⽤如下公式可以将图⽚映射到上图中的hash环上。\nhash（图⽚名称） % 2^32\n映射后的⽰意图如下，下图中的橘⻩⾊圆形表⽰图⽚\n好了，现在服务器与图⽚都被映射到了hash环上，那么上图中的这个图⽚到底应该被缓存到哪⼀台服务器上呢？上图中的图⽚将会被缓存到服务器A上，为什么呢？ 位置开始，沿顺时针⽅向遇到的第⼀个服务器就是A服务器，所以，上图中的图⽚将会被缓存到服务器A上，如下图所⽰。\n⼀致性哈希算法就是通过这种⽅法，判断⼀个对象应该被缓存到哪台服务器上的，将缓存服务器与被缓存对象都映射到hash环上以后，从被缓存对象的位置出⽅向遇到的第⼀个服务器，就是当前对象将要缓存于的服务器，由于被缓存对象与服务器hash后的值是固定的，所以，在服务器不变的情况下，⼀张图⽚必定会被缓存服务器上，那么，当下次想要访问这张图⽚时，只要再次使⽤相同的算法进⾏计算，即可算出这个图⽚被缓存在哪个服务器上，直接去对应的服务器查找对应的图⽚即刚才的⽰例只使⽤了⼀张图⽚进⾏演⽰，假设有四张图⽚需要缓存，⽰意图如下:\n1号、2号图⽚将会被缓存到服务器A上，3号图⽚将会被缓存到服务器B上，4号图⽚将会被缓存到服务器C上。\n"},{"id":36,"href":"/icorer_docs/doccenter/ak-2019/designs/1.6/","title":"1.6 权限设计-基于Plan的权限方案设计","section":"系统设计","content":" 基于Plan的权限方案设计 # 一. Plan的结构组成 # 权限Plan是基于构造出来的系统结构，基于系统模板，构造出一个个不同的权限Plan，具体的Plan构造方式如下。\n二. Plan数据结构设计 # 为了有结构的保存用户Plan权限，我们需要一张单独的数据表，这张数据表主要包括以下几个字段：\nid : 序号 plan_name: paln名称 plan_json : 基于系统目录结构构造的Plan json，用于web端或其他来展示。 ids : 操作单元的ids，用来判断用户权限。 数据结构样例解析如下: # 为了方便前端展示，我们把plan的数据结构分为两种模式存储，json的格式大致为 {\u0026ldquo;系统\u0026rdquo;:{\u0026ldquo;一级目录1\u0026rdquo;:{\u0026ldquo;二级目录1\u0026rdquo;:[\u0026ldquo;功能1\u0026rdquo;]},\u0026ldquo;一级目录2\u0026rdquo;:{\u0026ldquo;二级目录2\u0026rdquo;:[\u0026ldquo;功能2\u0026rdquo;]}}}\n为了方便api对于权限进行判断，我们对plan所拥有的api权限，使用操作单元的ids进行存储，这层可用来对于用户权限快速查询.\n这部分功能单元部分 还需要把下属的操作单元ids包括进来，把权限力度降到最低。\n三. Plan相关功能包 # 上面阐述了Plan相关的数据结构设计，在相关的数据结构基础上，还需要一个Plan权限操作包，操作包中包含下面方法：\n校验路由权限： module ， controller ， method 是否属于用户plan范围内\n获取指定Plan的数据结构：数组结构\n存储Plan数据结构\n3.1 权限校验功能 # 这部分需要检查当前请求的路由是否属于用户拥有的权限，首先应该去缓存中获取用户的权限信息，如果没有，则需要进行权限获取。取得用户权限之后，需要对于当前的路由和用户的权限进行比对，如果成功，则放行，否则将无权访问。\n"},{"id":37,"href":"/icorer_docs/doccenter/redishub/designs/1.6/","title":"1.6 集群 MSET 指令支持","section":"系统设计","content":" 集群 MSET 指令支持 # "},{"id":38,"href":"/icorer_docs/doccenter/redishub/designs/1.7/","title":"1.7 集群 MGET 指令支持","section":"系统设计","content":" 1.7 集群 MGET 指令支持 # 业务系统为了提高多个key的数据获取吞吐，经常会采用mget指令，这个指令在单实例模式的redis场景下能够完美支持，但是redis标准集群不支持跨槽位执行mget指令。\n但是mget针对业务环境是大量使用的，所以中间件必须完成mget指令在集群中的命令支持。\n1.7.1 指令转换 # 由于Redis不支持跨槽位执行mget指令，因此我们可以变相思维，总体的指令转换如下：\n针对MGET指令的keys进行拆分。 对keys进行hash计算 =\u0026gt; 选择key所对应的node 。 针对node组上的指令进行并发 pipline命令发送。 聚合各个并发线程的指令结果，把远端redis集群内部的数据返回给业务调用方。 1.7.2 MGET指令设计图 # 针对MGET的具体工作情况，我这边绘制了一个图，说明MGET的具体工作原理，红色线路代表一次完整的MGET执行周期。 从上面的图形可以看出，中间件接受到MGET请求后，会把指令中的KYES进行hash计算、并结合node信息选择数据存储的node，针对每个node进行进行pipeline 指令流水吞吐、保障单node下的吞吐高性能，针对不同的node进行并发执行，通过并发技术提高MGET在集群环境下的整体响应速度。\n"},{"id":39,"href":"/icorer_docs/doccenter/redishub/designs/1.8/","title":"1.9 Redis集群状态更新","section":"系统设计","content":" 1.9 Redis集群状态更新 # RedisHub中间件除了要沟通客户端 与 服务端 这两方，还需要及时获取Redis集群的状态信息，并把状态信息转换或更新必要的内存数据结构，内存数据结构最终会被中间件用来承载redis请求。\n1.9.1 状态信息来源 # 集群状态信息的来源主要包括：\n被动方式：集群内部指令执行周期内的MOVE、ASK信号 主动方式：集群 CLUSTER SLOTS 指令 1.9.2 集群槽位状态信息更新 # 关于集群槽位的信息更新，我们主要包括以下两方面策略：\n为了具备更好的性能，我们采用chan 共享内存监听 采用读写锁，提高关键内存共享区的读写安全性及性能 针对更新操作做了秒级限流操作，保障中间件的稳定性。 核心源码分析 如下：\nfunc (cluster *Cluster) handleUpdate() { for { //获取chan列表的更新信号 msg := \u0026lt;-cluster.updateList // TODO: control update frequency by updateTime and movedTime? cluster.rwLock.RLock() clusterLastUpdateTime := cluster.updateTime cluster.rwLock.RUnlock() //如果集群的上一次更新时间 加上窗口值（1s） 小于 此次集群更新指令产生的时间: 证明集群更新频率过高，控制频率。 if clusterLastUpdateTime.Add(1 * time.Second).Before(msg.movedTime) { //针对集群进行状态更新 err := cluster.Update(msg.node) if err != nil { log.Printf(\u0026#34;handleUpdate: %v\\n\u0026#34;, err) go KafkaLoger.Errorf(\u0026#34;redistun handleUpdate wrong. err: %s\u0026#34;, err.Error()) } } } } 1.9.2 指令MOVE 、ASK 信号跟踪 # 如果客户端在请求redis集群的过程中、redis集群出现集群槽位重新分配，会对于请求产生MOVE、ASK信号，为了让中间件支持数据的无缝迁移，我们针对MOVE、ASK进行了特殊处理。\n核心源码分析 如下：\n// 检查回复类型 resp := checkReply(reply) switch (resp) { case kRespOK, kRespError: return reply, nil case kRespMove: //此处在高并发+slots循环多次集中迁移时，会出现数据的多级别MOVE，对于多级别MOVE 要进行到底，一般频率为20万次中出现10次 //所以采用循环进行多级MOVE处理 for { //尝试第一次MOVE，并对结果进行判断，如果reply类型不再是MOVE类型，则证明摆脱多级MOVE，则把结果返回出去 //由于结果可能会发生变化，因此再进行判断 reply, err = cluster.handleMove(node, reply.(redisError).Error(), cmd, args) respType := checkReply(reply) //如果reply类型不是MOVE类型，则 准备跳出循环、对结果进行判断，选择条件返回 if respType != kRespMove { switch (respType) { case kRespOK, kRespError: return reply, nil case kRespAsk: return cluster.handleAsk(node, reply.(redisError).Error(), cmd, args) case kRespConnTimeout: return cluster.handleConnTimeout(node, cmd, args) case kRespClusterDown: //如果redis集群宕机，则返回宕机错误 //选取可用的节点 更新集群状态信息 cluster.UpdateSlotsInfoByRandomNode(node) return reply, Cluster_Down_Error } //此处return为了跳出多级MOVE的for循环 return reply, err } } //return cluster.handleMove(node, reply.(redisError).Error(), cmd, args) case kRespAsk: return cluster.handleAsk(node, reply.(redisError).Error(), cmd, args) case kRespConnTimeout: return cluster.handleConnTimeout(node, cmd, args) case kRespClusterDown: //如果redis集群宕机，则返回宕机错误 //选取可用的节点 更新集群状态信息 cluster.UpdateSlotsInfoByRandomNode(node) return reply, Cluster_Down_Error } "},{"id":40,"href":"/icorer_docs/doccenter/redishub/designs/1.9/","title":"1.8 TCP连接池","section":"系统设计","content":" 1.8 TCP连接池 # 1.8.1 连接池是什么 # 我们常见的池很多，比如内存池，线程池，对象池，连接池等。顾名思义，池子干的事情都是一样的，把一类相同的事物放到一个池里面，已备不时之需，好比我们的蓄水池一样，把平日多余的水储蓄起来，一方面防止洪水到来时候对下游造成洪涝灾害，另一方面还可以合理灌溉资源利用，比如还可以水力发电。同样连接池是把已经已经建立好的连接放入一个池子，当请求到来可以直接拿来使用，这样就即解决了频繁的创建关闭连接带来的开销，也保护了后端服务，防止同时有大量连接涌入，造成危害。\n1.8.2 连接池的种类 # 其实也就是连接池的使用场景\n可以是一个独立部署的服务，通过套接字提供代理服务。例如我们的常用的dbproxy。\n可以是一个服务内部进程间共享的连接池，这种相对更加轻量，可以理解为项目级别，只对内提供服务。\n进程内的连接池，更加轻量，当前进程内的线程或者协程可以使用。\nRedisHub 实现的连接池就是 进程内的连接池，使用连接池有以下好处：\n减少客户端使用连接时，创建和销毁连接的时间和系统资源开销，这里涉及到TCP的三次握手也四次挥手，还有TCP的慢启动预热。 避免极端情况大量连接直接涌入后端服务，对整个系统服务造成危害。 但同时也有一些缺点，比如空闲状态下也要维护一定数量的连接，占用客户端和服务端的资源，这里可以根据实际需求动态调配连接数，达到效率和资源利用的平衡。哪有一点资源不占用，还想系统高效稳定的事情，建个水坝还得占片地，护坝人间断性的职守呢。\n1.8.3 TCP连接池初始化方式 # TCP连接池的最终目标就是对程序体内部需要使用的TCP连接进行池化管理，连接不够使用时自动扩容、连接过剩的时候能够自动回收，所以 我们首先需要考虑TCP连接池的初始化方式。连接池的初始化方式主要包括如下两种：\n当请求到来的时候，尝试从连接池中获取连接对象，如果连接池为空，创建连接对象，请求结束的时候，归还至连接池.\n进程启动的时候，创建固定数量的连接对象，当请求到来的时候，尝试从连接池中获取连接对象，如果连接池为空，继续等待或者服务降级; 不为空的话正常服务，请求结束的时候，归还至连接池.\nRedisHub 中间件的TCP连接池初始化方式选择第一种。针对第二种连接池的实现方案，可以查阅本人另外一个项目RedisTun。\n1.8.4 连接池源码分析 - 获取一个可用链接 # func (node *redisNode) getConn() (*redisConn, error) { //需要针对当前的redis-node的tcp连接池进行内存操作，在并发场景下，首先先上锁。 node.mutex.Lock() //如果当前node已经进入不可用状态。 if node.closed { node.mutex.Unlock() return nil, fmt.Errorf(\u0026#34;getConn: connection has been closed\u0026#34;) } //从TCP连接池中清理陈旧的TCP连接，这里面使用了LIST数据结构，可以把陈旧连接进行归并、一并处理。 //如果连接远程node节点时候设置了TCP连接存活时间 则 进行检验。 if node.aliveTime \u0026gt; 0 { for { //从list中选择一个元素，如果conns列表为空 则跳出检查 elem := node.conns.Back() if elem == nil { break } //成功获取到一条TCP连接，进行生命期时间校验 conn := elem.Value.(*redisConn) //如果当前获取的TCP连接是在合法生命周期内部的，立刻退出，但是这个元素还在list中，下次获取仍然能够获取到 if conn.t.Add(node.aliveTime).After(time.Now()) { break } //运行到这里，代表TCP连接生命期超时，删除此元素 node.conns.Remove(elem) } } //经过前面的操作，前面目的在于清理超时TCP连接 if node.conns.Len() \u0026lt;= 0 { //没有TCP连接可用，所以需要新建连接，立刻需要释放锁 node.mutex.Unlock() c, err := net.DialTimeout(\u0026#34;tcp\u0026#34;, node.address, node.connTimeout) if err != nil { return nil, err } //var writerMemory bytes.Buffer //创建新的redis连接内存对象 conn := \u0026amp;redisConn{ c: c, br: bufio.NewReader(c), bw: bufio.NewWriter(c), readTimeout: node.readTimeout, writeTimeout: node.writeTimeout, //writerMemory: \u0026amp;writerMemory, } //设置内存缓冲区 //conn.bwm = RedSHandle.NewWriterHandle(conn.writerMemory) //conn.readerParser = RedisFastParser.NewParserHandle(conn.c) return conn, nil } //获取到一条已经存在的存活TCP连接，这条TCP的生命周期也在合法时间内，所以： // 1.取出元素 // 2.删除元素在list中的位置 // 3.立刻解锁 elem := node.conns.Back() node.conns.Remove(elem) node.mutex.Unlock() //重置内存缓冲区 //elem.Value.(*redisConn).writerMemory.Reset() return elem.Value.(*redisConn), nil } 1.8.5 连接池源码分析 - 放回可用连接进入池 # func (node *redisNode) releaseConn(conn *redisConn) { //需要针对当前的redis-node的tcp连接池进行内存操作，在并发场景下，首先先上锁。 node.mutex.Lock() defer node.mutex.Unlock() //连接仍然有待处理的回复，只需将其关闭即可，避免可能的TCP粘包连接。 if conn.pending \u0026gt; 0 || node.closed { conn.shutdown() return } //如果连接池的当前长度已经超过池的最高界限，或者node没有开启tcp存活时间选项。 if node.conns.Len() \u0026gt;= node.keepAlive || node.aliveTime \u0026lt;= 0 { conn.shutdown() return } //更新当前conn的时间，并放入LIST数据结构 conn.t = time.Now() node.conns.PushFront(conn) //重置内存缓冲区 //conn.writerMemory.Reset() } "},{"id":41,"href":"/icorer_docs/doccenter/redistun/","title":"RedisTun","section":"项目总览","content":"RedisTunel 是为了解决PHP-FPM和Redis服务器之间的短连接问题,是为了更好地解耦业务代码与后端redis服务器集群之间的关系而设计的网络通信中间件，目的在于提高PHP请求远程Redis服务器的性能及稳定性,并在业务代码无感知的情况下提供数据分槽,指令组合,数据压缩等通信插件包,丰富redis的操作.\n一. 总体设计 # Redis-Tunel在组件设计上分为以下几部分:\nAgent配置解析器和更新器 通信组件: 包括UNIX本地监听组 和 远端Redis服务器连接池 协议分析器: 主要包括协议编码器,解码器 协议拦截器: 主要对某些redis命令进行拦截,调用协议插件组进行功能扩展. 协议插件组: 为协议分析器添加一系列插件,对通信进行优化和功能扩展. 容灾器: 为Agent运行提供必要的安全保障,主要包括进程资源监控,迭代更新监控. 具体的组件总体架构如下图: 二. 网络代理设计 # Redis-Tunel很重要的是网络代理部分,在网络代理方面由三部分组成.\n第一部分是对远程redis-server的连接池. 第二部分是对本地众多php-fpm客户端的UNIX请求连接管理. 第三部分是对这三端之间redis通信协议进行兼容. Go基础版本组件设计目前已经完成功能如下：\n配置解析器。 Unix domain server 组。 Tcp pool （目前包含自动扩容，连接隔离）。 Unix domain server 与 Tcp pool 的网络解耦。 借助redcon库进行redis协议解析和php-fpm客户端连接控制。 兼容set,get,mset,mget命令。 "},{"id":42,"href":"/icorer_docs/doccenter/redishub/designs/1.10/","title":"1.10 RESP协议解析","section":"系统设计","content":" 1.10 RESP协议解析 # 1.10.1 RESP协议介绍 # Redis 协议在以下三个目标之间进行折中：\n易于实现 可以高效地被计算机分析（parse） 可以很容易地被人类读懂 1.10.2 请求 # Redis 服务器接受命令以及命令的参数。\n服务器会在接到命令之后，对命令进行处理，并将命令的回复传送回客户端。\n1.10.3 回复 # Redis 命令会返回多种不同类型的回复。\n通过检查服务器发回数据的第一个字节， 可以确定这个回复是什么类型：\n状态回复（status reply）的第一个字节是 \u0026ldquo;+\u0026rdquo;\n错误回复（error reply）的第一个字节是 \u0026ldquo;-\u0026rdquo;\n整数回复（integer reply）的第一个字节是 \u0026ldquo;:\u0026rdquo;\n批量回复（bulk reply）的第一个字节是 \u0026ldquo;$\u0026rdquo;\n多条批量回复（multi bulk reply）的第一个字节是 \u0026ldquo;*\u0026rdquo;\n1.10.4 状态回复 # 一个状态回复（或者单行回复，single line reply）是一段以 \u0026ldquo;+\u0026rdquo; 开始、 \u0026ldquo;\\r\\n\u0026rdquo; 结尾的单行字符串。\n以下是一个状态回复的例子：\n+OK\n客户端库应该返回 \u0026ldquo;+\u0026rdquo; 号之后的所有内容。 比如在在上面的这个例子中， 客户端就应该返回字符串 \u0026ldquo;OK\u0026rdquo; 。\n状态回复通常由那些不需要返回数据的命令返回，这种回复不是二进制安全的，它也不能包含新行。\n状态回复的额外开销非常少，只需要三个字节（开头的 \u0026ldquo;+\u0026rdquo; 和结尾的 CRLF）。\n1.10.5 错误回复 # 错误回复和状态回复非常相似， 它们之间的唯一区别是， 错误回复的第一个字节是 \u0026ldquo;-\u0026rdquo; ， 而状态回复的第一个字节是 \u0026quot;+\u0026quot; 。\n错误回复只在某些地方出现问题时发送： 比如说， 当用户对不正确的数据类型执行命令， 或者执行一个不存在的命令， 等等。\n一个客户端库应该在收到错误回复时产生一个异常。\n以下是两个错误回复的例子：\n-ERR unknown command \u0026lsquo;foobar\u0026rsquo; -WRONGTYPE Operation against a key holding the wrong kind of value\n在 \u0026quot;-\u0026quot; 之后，直到遇到第一个空格或新行为止，这中间的内容表示所返回错误的类型。\nERR 是一个通用错误，而 WRONGTYPE 则是一个更特定的错误。 一个客户端实现可以为不同类型的错误产生不同类型的异常， 或者提供一种通用的方式， 让调用者可以通过提供字符串形式的错误名来捕捉（trap）不同的错误。\n不过这些特性用得并不多， 所以并不是特别重要， 一个受限的（limited）客户端可以通过简单地返回一个逻辑假（false）来表示一个通用的错误条件。\n1.10.6 整数回复 # 整数回复就是一个以 \u0026quot;:\u0026quot; 开头， CRLF 结尾的字符串表示的整数。\n比如说， \u0026quot;:0\\r\\n\u0026quot; 和 \u0026quot;:1000\\r\\n\u0026quot; 都是整数回复。\n1.10.7 RESP协议解析- 源码分析 # 这里首先感谢Codis 和 Redigo 这两大开源项目， 这里只进行概括性源码解析。\nfunc (d *Decoder) decodeResp() (*Resp, error) { b, err := d.br.ReadByte() //从缓冲区读取1byte，这个是RESP首特征byte if err != nil { return nil, errors.Trace(err) } r := \u0026amp;Resp{} r.Type = RespType(b) switch r.Type { default: //如果不在可控范围，则代表请求不是RESP协议 return nil, errors.Errorf(\u0026#34;bad resp type %s\u0026#34;, r.Type) case TypeString, TypeError, TypeInt: //如果是字符串、错误、整形响应 r.Value, err = d.decodeTextBytes() case TypeBulkBytes: //如果是Bulk类型 r.Value, err = d.decodeBulkBytes() case TypeArray: //如果数据是数组类型 r.Array, err = d.decodeArray() } return r, err } //解析非二进制安全的字符串、错误、整形响应，必须按照\\r\\n分割。 func (d *Decoder) decodeTextBytes() ([]byte, error) { b, err := d.br.ReadBytes(\u0026#39;\\n\u0026#39;) if err != nil { return nil, errors.Trace(err) } if n := len(b) - 2; n \u0026lt; 0 || b[n] != \u0026#39;\\r\u0026#39; { return nil, errors.Trace(ErrBadCRLFEnd) } else { return b[:n], nil } } //解析数组类型响应。 func (d *Decoder) decodeArray() ([]*Resp, error) { //解析数组长度 n, err := d.decodeInt() if err != nil { return nil, err } switch { case n \u0026lt; -1: return nil, errors.Trace(ErrBadArrayLen) case n \u0026gt; MaxArrayLen: return nil, errors.Trace(ErrBadArrayLenTooLong) case n == -1: return nil, nil } //根据数组长度创建RESP数组 array := make([]*Resp, n) for i := range array { //针对每个数组元素进行解析，此处类似递归调用，但是，借助go的栈逃逸、堆区内存分配，可以避免循环栈消耗。 r, err := d.decodeResp() if err != nil { return nil, err } array[i] = r } return array, nil } "},{"id":43,"href":"/icorer_docs/doccenter/pulseflow/overviews/","title":"PulseFlow概览","section":"PulseFlow","content":" 一. 背景描述 # 随着公司PHP项目体的不断增大，随着不同工程师的功能迭代，如何有效获取PHP项目的执行性能，对于系统整体模块显得异常重要，PulseFlow是一个公司团队内部自研地性能跟踪扩展，它可以在程序员无感知的情况下有效跟踪每一个函数的执行效率，主要分析CPU时间消耗、内存大小消耗，执行次数这三个指标，下面我们将从 PHP生命期 到 组件设计 到 性能优化这三个方面来进行阐述组件。\n二 . 插件和 PHP生命期 # PHP生命周期通常包括 MI（模块初始化）、RI（请求初始化）、RS（请求终止）、MS（模块终止） 这四个步骤，这四个部分使我们能够进行功能渗透的生命期子过程。在MI阶段会包含INI配置文件的解析，在RI阶段会针对每一个CGI请求进行请求初始化操作，在RS阶段会针对每一个请求的关闭进行相关功能拦截。并不是每一次执行PHP均要经历这四个阶段，在CLI模式下，会完整经历这四个阶段，在PHP-FPM这种类CGI模式下，为了提高请求性能，并不会经历过全部阶段，它会着重经历RI、RS阶段。\n了解了PHP的生命期轮廓后，我们绘制了下图阐述大概执行流程所属的生命期阶段。\n三. 插件和ZEND引擎 # 在上述的PHP生命周期阶段内，我们可以在不同的阶段分块插件的功能，其次，我们还需要和ZEND引擎打交道，因为ZEND引擎是真正的执行者，我们目前需要托管他们的 zend_execute_ex 内核函数，这个内核函数就是C语言的函数指针，这个内核函数顾名思义就是PHP的内核执行函数。\n为了阐述方便，我们使用一个执行流程图，来看一下插件该如何拦截ZEND引擎的执行流程。 三. 开始造轮子 # 3.1 插件流程分析 # 首先，我们需要构建插件的执行流程，及各个部分的信息传送关系，我们目前把插件分为两部分，一部分是PHP扩展，用于在PHP生命周期内来进行性能拦截，这部分信息通常存储于 系统进程堆区 或者 系统进程静态区域，第二部分是后台数据转发程序，它负责从信息通道里读取PHP扩展写入的信息，并转发给相应的下一级程序，相关流程图如下。 3.2 环境选择（系统组件选择） # 这一步我们选择相应的环境，或者称之为系统组件选择，我们在选择相应组件时根据插件各个执行周期来进行选择。\n3.2.1 PHP引擎环境 （PHP7+） # 首先PHP引擎我们选择7.0以上，因为 PHP7 与 PHP5 的内核数据结构差距甚大，目前针对PHP7，后面会移植代码覆盖PHP5版本。\n3.2.2 插件语言 （C） # 虽然现在编写PHP扩展可以使用Go语言、zephir语言、但是为了和原PHP内核及Linux操作系统进行最好性能交互，我们选择C语言进行研发。\n3.2.3 信息队列（System V 消息队列） # 在3.1中，我们提及了一个很重要的组件，并用红色进行了标记，PHP扩展和后台信息转发程序 如何 沟通？哪一条路最快？\n为了选择这条信息通路，我们做了大量实验，覆盖面积包括TCP、unix domain socket、zeromq、nanomsg、共享内存、posix 内核消息队列、system V 内核消息队列，目前最快的是共享内存，其次是system V 和 posix 内核队列。\n共享内存虽然是最快的，但是我们目前针对的模型是 多写、多读，为了不对PHP-FPM 内存 和 对系统内存能够更好更有力管理，在第一版中我们将采用system V内核队列，但是我们也已经开放了 共享内存版本的分支 和 给予epoll模型的 posix 内核队列 代码分支，这两个代码分值中均写好模型代码，在后面阶段将会一步步融入主线版本。\n为什么选择 system V 队列？ 首先system V内核队列在 Linux Kernel 2.6 版本均为内置系统库，特别是redhat系列：包括centos，性能更为优秀，作为系统内置库，自然拥有更好的内核支持、更好的编译条件。\n3.2.3 后台程序（C） # 在对后台程序进行设计时，我们仔细分析了不同语言在进行系统调用的性能差距，我们使用Go语言 进行了 相关测试，发现 同样的系统环境下，Go语言对于系统调用的效率严重滞后于C，于是我们使用C语言进行后台程序设计，旨在达到最高性能的内核消息队列消费能力。\n3.3 编码优化 # 在编码期间，我们参考了facebook 的 xhprof 插件 和 tideways 的 XHProf插件，看完相关源码后，我们着重从三个方面进行编码优化：\n调整数据结构存储位置，避免堆区分配，避免内存泄露。\n设计简洁化数据结构，及 简洁化执行流程。\n使用 BKDRHash 字符串哈希算法，提高字符串查询速度。\n拒绝一切 序列化 和 反序列化，提高程序间沟通性能。\n3.3.1 数据存储区域选择 、 简化数据结构 及 拒绝序列化 # 在编写插件的过程中，我们最初采用 PHP-FPM 源码模型，在堆区构造 双数组 数据结构，能够达到时间复杂度为O(n)的查询速度，O(1)的元素定位速度，但是由于分配在堆区，在后期和内核沟通过程中，需要进行大量的拷贝 和 序列化工作，性能损耗巨大，相关数据结构如下图。\n这种结构优于 目前 市场上 的 性能监控插件 数据结构，因为 类 和 函数 的 信息是分离的，而不是简单的通过 链表，这样可以达到类 和 函数 o(n)效率，可以保障 o(1)的 类和 函数转换性能。\n但是这种强依赖关系，在 进行 数据发送阶段 产生大量的深度拷贝 和 序列化工作， 序列化工作是致命的。\n于是 我们设计了第二版数据结构，数据结构如下图\n其次，基于此数据结构，可以无需深度拷贝即可和 Linux内核进行沟通，无需序列化和反序列化即可和 C 后端程序进行沟通， 此思路从protobuf 和 easyjson 借鉴并实现。\n基于静态数据区域，避免内存泄露问题。\n3.3.2 借力 PHP-FPM 模式 # 新的数据结构，由于全部位于静态资源区，各个PHP-FPM在 MI 阶段加载并初始化，通常一个PHP-FPM只会加载一次MI阶段，所以此次消耗在后面的RI至MS阶段均是不损耗的。可以把资源加载的负担转移。\n3.3.3 使用 BKDRHash 字符串哈希算法 # 我们在数据结构元中 添加了 类名 和 函数名的哈希字段，通过BKDRHash进行字符串哈希计算，利用哈希计算后的值，可以快速 定位数据元素，并优化程序的执行流程，避免多次hash计算，降低hash计算压力。\n3.3.4 拒绝序列化 和 反序列化操作 # 由于我们借助内核消息队列进行消息沟通，所以php扩展 和 后端程序体 数据沟通也会有巨大成本，我们着力解决发送端问题，我们初始化时把数据分配到静态资源区，借助新的数据结构，可以无需深度拷贝即可和 Linux内核进行沟通，无需序列化和反序列化即可和 C 后端程序进行沟通， 此思路从protobuf 和 easyjson 借鉴并实现。\n四 . 测试轮子 # 下面将进行基准测试，不带有任何业务代码的测试 ( i7 - 8核 ， 16GB ， Ubuntu16.04 ， PHP 7.2.8 ，Nginx 1.14.0 )。\n总共进行了三轮测试。　吞吐量损耗范围在（1.48％　至 1.78%）\n##4.1 第一轮 测试 吞吐量损失 ： （17454-17130）/17454 = 1.85 %\n4.1.1 无扩展： # 4.1.2 有扩展: # ##4.2 第二轮 测试 吞吐量损失:(17274-16966)/17274 = 1.78%\n4.2.1 无扩展： # 4.2.2 有扩展： # ##4.3 去除了不必要的函数,缩小so体积 吞吐量损失 (17427-17168)/17427 = 1.48 %\n4.3.1 无扩展： # 4.3.2 有扩展： # "},{"id":44,"href":"/icorer_docs/doccenter/redishub/designs/","title":"系统设计","section":"RedisHub","content":" 一. 总体设计 # RedisHub在组件设计上分为以下几部分:\nAgent配置解析器：负责对于配置文件进行解析（后续增加统一配置中心的支持） 通信组件: 包括UNIX本地监听组 和 远端Redis集群TCP长连接及连接池。 协议分析器: 提供稳定的Redis协议解析及组装功能组件。 协议拦截器: 主要对某些Redis命令进行拦截,调用协议插件组进行功能扩展. 协议插件组: 为协议分析器添加一系列插件,对通信进行优化和功能扩展，例如集群的mset、mget、del操作。 容灾器: 为Agent运行提供必要的安全保障,主要包括进程资源监控,迭代更新监控. 具体的组件总体架构如下图: "},{"id":45,"href":"/icorer_docs/doccenter/redistun/designs/","title":"系统设计","section":"RedisTun","content":" 一. 总体设计 # RedisHub在组件设计上分为以下几部分:\nAgent配置解析器：负责对于配置文件进行解析（后续增加统一配置中心的支持） 通信组件: 包括UNIX本地监听组 和 远端Redis集群TCP长连接及连接池。 协议分析器: 提供稳定的Redis协议解析及组装功能组件。 协议拦截器: 主要对某些Redis命令进行拦截,调用协议插件组进行功能扩展. 协议插件组: 为协议分析器添加一系列插件,对通信进行优化和功能扩展，例如集群的mset、mget、del操作。 容灾器: 为Agent运行提供必要的安全保障,主要包括进程资源监控,迭代更新监控. 具体的组件总体架构如下图: "},{"id":46,"href":"/icorer_docs/doccenter/logdarts/designs/","title":"风险分析","section":"LogDarts组件风险评估","content":"LogDarts组件是一个日志记录组件，为了不影响系统的功能稳定性，我们需要对代码的设计及实现部分进行风险分析。\n一. 组件风险领域 # 组件基于PHP进行开发，下面从这几个方面进行分析。\n数据结构 （已审查）\n代码流程 （已审查）\n异常监控 （已审查）\n总结 # 以上三部分的代码逻辑、代码异常机制已经经过完全审核。详情可以查看每个部分的子报告。\n"},{"id":47,"href":"/icorer_docs/doccenter/ak-2019/","title":"AK-2019","section":"项目总览","content":" 系统设计概述 # AK-2019是全新的系统运行框架, 此页主要阐述项目相关的参与人员 及 相关互相之间的配合关系.\nAK-2019提供的新框架,目前主要围绕以下三部分进行设计:\n前后端分离设计 全新的API抽象 更加灵活的权限系统 一.前后端分离设计 # 在这一版系统中,将去除后端的模块渲染部分,采用前后端分离模式,通过接口对外提供统一服务,一方面可以降低后端研发人员的工作量,也可以提高系统的统一性,通过api库对外进行服务,前端对象包括web,微信平台,手机app.\n二. 全新的API抽象层 # 系统基于TP5.1将重构api层,规范api层的输入,输出和处理过程,及必要的系统运行库,主要包括下面四部分:\n标准request请求 灵活权限 标准输出 框架组件库 三.更加灵活的权限系统 # 权限设计对于新版系统很重要,本次设计将对权限部分进行彻底解耦,通过对于最小权限单元的抽象,通过功能库内模块的相互组合达到功能的动态组合和用户权限的动态化,复合化.\n工期计划 # 计划于年前完成前后端框架设计,前端需要完成基础框架构建,后端需完成API层的重构,后端能够对外进行服务.\n项目人员 # 下面对于框架项目人员进行相关分配:\n前后端框架设计(设计层):\nAPI框架负责(工作流程实现层-框架流程):\nAPI框架模块实现(功能模块实现-后端):\n前端负责(功能模块实现层-前端):\n工作配合模式 # 在工作层次上,分为设计层 , 功能模块实现层,框架流程实现层.\n设计层: 负责总体设计,框架相关模块的设计工作,针对整体或者模块推出相应的描述文档或者线下会议描述,负责设计系统相关模块和相关流程 及 详细的阐述工作.\n功能模块实现层: 负责针对设计层所设计出的相关模块组件进行实现工作,实现过程中如果发现设计不符合业务情况,则直接和设计层进行反馈.\n框架流程实现层: 熟悉基础框架代码,熟悉各个功能模块,负责在框架代码中把相关模块衔接起来,实现框架的控制流程,主要包括(输入,输出,权限模块的流程结合)\n"},{"id":48,"href":"/icorer_docs/doccenter/","title":"项目总览","section":"工匠之芯-文档中心","content":" 项目总览 # RedisHub PulseFlow "},{"id":49,"href":"/icorer_docs/doccenter/logdarts/","title":"LogDarts组件风险评估","section":"项目总览","content":" 背景介绍 # 日志对于任何一个需要稳定运行的系统都弥足珍贵，如何构造一个高性能的统一日志平台，首先需要解决的是“记录”，如何用最快、性能损耗最小的方式来记录日志？ UDP是一个不错的选择：首先UDP通道的带宽需求小，能达到很好的实时性；其次UDP不需要维持连接，在网络传输中的动作少。\n有人会说，UDP是不稳定传输、使用时数据风险大。对于这点，我们需要考量具体使用环境，在我们的日志系统中，每台机器都会运行一个LogAgent，你可以把它想像成数据接受转发者，LogAgent接受本地客户端发来的UDP数据包、并把数据包通过稳定传输协议传输到统一日志中心，而且随着网络不断发展，网络状况也在逐渐改善。\nCDN服务商Akamai（NASDAQ: AKAM）报告从2008年到2015年7年时间，各个国家网络平均速率由1.5Mbps提升为5.1Mbps，网速提升近4倍。网络环境变好，网络传输的延迟、稳定性也随之改善，UDP的丢包率低于5%，如果再使用应用层重传，能够完全确保传输的可靠性。\nLogDarts 开源项目就是建立在上述的使用环境下，它可以帮助使用PHP开发的系统快速集成UDP日志客户端功能。\n项目地址： LogDarts-noComposer 、LogDarts\n项目组件 # LogDarts 开源项目包含CONF、EXP、PACKER 和 LOGER 四个组件。\nCONF组件 # 顾名思义，它是配置组件，主要负责UDP客户端的配置文件、配置文件目前包括UDP配置、数据打包配置、数据发送配置。\n数据打包配置里 ‘MAX_SIZE’ 参数代表UDP数据包最大长度、默认值为1400 (此参数根据IP数据包设置，如果是本地loop网卡，可以设置65000) 数据打包配置里 ‘SAVE_TYPE’ 参数代表数据保存模式，默认值为‘STATIC_VAR’，后期还会支持 SHM 和 APCU 数据发送配置里 ‘MODE’ 参数代表数据发送模式，有 ‘SIMPLE’ 和 ‘GROUP’ 两种，前者代表每次都发送，后者代表分组发送，后者可以有效降低UDP请求次数。 EXP组件 # EXP组件主要包装项目中可能出现的异常。\nPACKER组件 # 此组件负责组装数据包字符串、目前主要记录两类数据，相应的数据格式如下：\n计数型： php_biz_count_metrics|type=payorder\u0026amp;service=shein\u0026amp;site=iosus|1\n瞬时型： php_biz_gauae_metrics|type=order.payorder\u0026amp;service=shein\u0026amp;site=shein\u0026amp;biz_parameter=facebook7|2.15\nLOGER组件 # LOGER是最重要的组件，主要SDK提供者，帮助用户记录日志和发送日志\n使用方法 # 使用流程 # 加载 loader.php ==\u0026gt; 获取Loger对象 ==\u0026gt; 使用count方法进行发送计数日志 （使用set方法发送瞬时日志）。\n样例代码 # \u0026lt;?php require_once __DIR__ .\u0026#34;/../src/loader.php\u0026#34;; $loger = Loger::getLoger(); $ret = $loger-\u0026gt;count(\u0026#39;shein\u0026#39;,[\u0026#39;order\u0026#39;,\u0026#39;payorder\u0026#39;],\u0026#39;iosus1\u0026#39;); $ret = $loger-\u0026gt;set(\u0026#39;shein\u0026#39;,[\u0026#39;order\u0026#39;,\u0026#39;payorder\u0026#39;],\u0026#39;shein\u0026#39;,2.15,\u0026#39;facebook7\u0026#39;); ?\u0026gt; 性能测试 # 对组件利用xhprof 进行性能跟踪，具体情况如下图。组件所消耗的CPU时间还是很小的，一个执行流程能够控制在400微秒以下。 "},{"id":50,"href":"/icorer_docs/doccenter/pulseflow/pulgin_designed/","title":"PulseFlow插件端","section":"PulseFlow","content":" 一. 组件概述 # PulseFLow插件端主要完成下面两个方面的功能。 # 1.1 拦截PHP执行过程 （保障高效） # PulseFlow的第一个部分是PHP扩展，这个PHP扩展的主要功能是拦截PHP脚本在执行过程中的运行信息。目前拦截的信息包括：\n函数名及类名\n函数执行耗时\n函数执行的内存损耗\n函数执行的次数统计\n上述的四个指标均指在一个PHP生命周期内。\n在拦截执行信息的过程中，为了保障高效率，我们先后调整了两次数据结构，最终在简易的数据结构基础上，借助全局变量的威力，去除了序列化和反序列化过程，大大提高了信息采集的效率。\n1.2 发送拦截的性能信息（保障高效稳定） # 在 1.1 节中，我们介绍了扩展拦截了一系列的运行信息，但是还需要发送出去这个环节，如何既快速又稳定地和信息接收端通信，我们测试了以下方案。\nSystem V Message Queue\nPosix Message Queue\nUnix Domain Socket\nZero MQ\nNanoMsg\nShared Memory\n我们在详尽测试了上述六种方案后，为了保证稳定性、系统搭建的简易性，我们选择了既安全又快速的System V Message Queue。\n这是一种 Linux 内核消息队列，速度仅次于共享内存通信，虽然没有共享内存速度快，但是具有很好的安全性 和 队列性，毕竟是线上产品，所以我们在1.0版本中采用此方案。（但是我们保留了共享内存代码分支，后期共享内存版本稳定后再另行推出。）\n"},{"id":51,"href":"/icorer_docs/doccenter/redishub/system_access/","title":"系统接入","section":"RedisHub","content":" Tutorials # "},{"id":52,"href":"/icorer_docs/doccenter/redistun/system_access/","title":"系统接入","section":"RedisTun","content":" Tutorials # "}]