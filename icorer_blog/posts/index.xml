<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Posts on 笔迹-工匠之芯</title><link>https://icorer.com/icorer_blog/posts/</link><description>Recent content in Posts on 笔迹-工匠之芯</description><generator>Hugo -- gohugo.io</generator><language>zh-cn</language><lastBuildDate>Tue, 14 Jun 2022 12:55:18 +0800</lastBuildDate><atom:link href="https://icorer.com/icorer_blog/posts/index.xml" rel="self" type="application/rss+xml"/><item><title>2022 Wanxiang Blockchain Spring Hackathon - IceFireDB Won The First Prize</title><link>https://icorer.com/icorer_blog/posts/icefiredb2022wanxiang/</link><pubDate>Tue, 14 Jun 2022 12:55:18 +0800</pubDate><guid>https://icorer.com/icorer_blog/posts/icefiredb2022wanxiang/</guid><description>2022 Wanxiang Blockchain Spring Hackathon Wrapped up on June 12th,We are very lucky and grateful to Protocol Labs for giving us this honor. In addition to joy, we are more moved. Our efforts and innovation are recognized. Next, we will work harder to incubate our projects.
2022 Wanxiang Blockchain Spring Hackathon, an immensely successful hackathon packed with over 20 teams of passionate builders and developers wrapped up yesterday, under the theme of “Metaverse: A Shared Future on Blockchain”.</description></item><item><title>Gorilla：一个快速、可伸缩的内存时间序列数据库</title><link>https://icorer.com/icorer_blog/posts/gorilladb/</link><pubDate>Fri, 01 Apr 2022 17:26:18 +0800</pubDate><guid>https://icorer.com/icorer_blog/posts/gorilladb/</guid><description>摘要大规模互联网服务旨在出现意外故障时保持高可用性和高响应性。提供这种服务通常需要在大量系统上每秒钟监测和分析数千万次测量，一个特别有效的解决方案是在时间序列数据库(TSDB)中存储和查询这种测量。TSDB设计中的一个关键挑战是如何在效率、可伸缩性和可靠性之间取得平衡。在本文中，我们介绍Gorilla系统，脸书的内存TSDB。我们的见解是，监控系统的用户不太重视单个数据点，而是更重视综合分析，对于快速检测和诊断持续问题的根本原因而言，最新数据点比旧数据点更有价值。Gorilla优化了写入和读取的高可用性，即使在出现故障时也是如此，代价是可能会在写入路径上丢弃少量数据。为了提高查询效率，我们积极利用压缩技术，如增量时间戳和异或浮点值，将Gorilla的存储空间减少了10倍。这使我们能够将Gorilla的数据存储在内存中，与传统数据库(HBase)支持的时间序列数据相比，查询延迟减少了73倍，查询吞吐量提高了14倍。这种性能改进带来了新的监控和调试工具，比如时序关联搜索和更密集的可视化工具。Gorilla还可以优雅地处理从单个节点到整个区域的故障，几乎没有运营开销。
一、介绍大规模互联网服务即使在出现意外故障的情况下也能保持高可用性和对用户的响应。随着这些服务发展到支持全球客户，它们已经从运行在数百台机器上的几个系统扩展到服务数以千计的个人用户系统运行在数千台机器上，通常跨越多个地理复制的数据中心。
运行这些大规模服务的一个重要要求是准确监控底层系统的健康和性能，并在出现问题时快速识别和诊断问题。脸书使用时间序列数据库(TSDB)存储系统测量数据点，并在顶部提供快速查询功能。接下来，我们将指定监控和操作脸书需要满足的一些约束，然后描述Gorilla，这是我们新的内存TSDB，可以存储数千万个数据点(例如，CPU 负载、错误率、延迟等)。)并在几毫秒内响应对此数据的查询。
写占主导地位。我们对 TSDB 的主要要求是它应该始终可用于写入。由于我们有数百个公开数据项的系统，写入速率可能很容易超过每秒数千万个数据点。相比之下，读取速率通常要低几个数量级，因为它主要来自于观察“重要”时间序列数据的自动化系统、可视化系统或为希望诊断观察到问题的人类操作员提供仪表板。
状态转换。我们希望识别新软件发布中出现的问题、配置更改的意外副作用、网络中断以及导致重大状态转换的其他问题。因此，我们希望我们的TSDB支持短时间窗口内的细粒度聚合。在几十秒钟内显示状态转换的能力特别有价值，因为它允许自动化在问题变得广泛传播之前快速修复问题。
高可用性。即使网络分区或其他故障导致不同数据中心之间的连接断开，在任何给定数据中心内运行的系统都应该能够将数据写入本地TSDB机器，并且能够按需检索这些数据。
容错。我们希望将所有写入复制到多个区域，这样我们就可以在任何给定的数据中心或地理区域因灾难而丢失时幸存下来。
Gorilla是脸书的新TSDB，满足了这些限制。Gorilla用作进入监控系统的最新数据的直写缓存。我们的目标是确保大多数查询在几十毫秒内运行。Gorilla 的设计理念是，监控系统的用户不太重视单个数据点，而是更重视综合分析。此外，这些系统不存储任何用户数据，因此传统的 ACID保证不是TSDB的核心要求。 但是，高比例的写入必须始终成功，即使面临可能导致整个数据中心无法访问的灾难。此外，最近的数据点比旧的数据点具有更高的价值，因为直觉上，对于运营工程师来说，知道特定系统或服务现在是否被破坏比知道它是否在一个小时前被破坏更有价值，Gorilla 进行了优化，即使在出现故障的情况下也能保持高度的读写可用性，代价是可能会丢失少量数据写入路径。
高数据插入率、总数据量、实时聚合和可靠性要求带来了挑战。我们依次解决了这些问题。为了解决第一个要求，我们分析了 TSDB 操作数据存储(ODS),这是一个在脸书广泛使用的老的监控系统。我们注意到，对ODS的所有查询中，至少有85%是针对过去26小时内收集的数据。进一步的分析使我们能够确定，如果我们能够用内存中的数据库替换基于磁盘的数据库，我们可能能够为我们的用户提供最好的服务。此外，通过将这个内存中的数据库视为持久的基于磁盘的存储的缓存，我们可以实现具有基于磁盘的数据库的持久性的内存中系统的插入速度。
截至2015年春天，脸书的监控系统生成了超过20亿个独特的时间序列计数器，每秒钟增加约1200万个数据点。这代表每天超过1万亿个点。在每点16字节的情况下，产生的16TBRAM对于实际部署来说太耗费资源了。我们通过重新利用现有的基于XOR的浮点压缩方案来解决这一问题，使其以流的方式工作，从而允许我们将时间序列压缩到平均每点1.37字节，大小减少了12倍。
我们通过在不同的数据中心区域运行多个Gorilla实例并向每个实例传输数据流来满足可靠性要求，而不试图保证一致性。读取查询指向最近的可用Gorilla实例。请注意，这种设计利用了我们的观察，即在不影响数据聚合的情况下，单个数据点可能会丢失，除非Gorilla实例之间存在显著差异。Gorilla目前正在脸书的生产中运行，工程师们每天将其用于实时灭火和调试，并与Hive[27]和Scuba[3]等其他监控和分析系统结合使用，以检测和诊断问题。
二、背景和要求2.1 操作数据存储脸书的大型基础设施由分布在多个数据中心的数百个系统组成，如果没有能够跟踪其运行状况和性能的监控系统，运营和管理这些基础设施将会非常困难。业务数据储存库是脸书监测系统的一个重要部分。ODS由一个时间序列数据库(TSDB)、一个查询服务以及一个探测和警报系统组成。ODS的TSDB 构建在 HBase存储系统之上，如[26]中所述。图1显示了ODS组织方式的高级视图。来自运行在脸书主机上的服务的时间序列数据由ODS写入服务收集并写入 HBase。
ODS时间序列数据有两个消费者。第一个消费者是依赖制图系统的工程师，该系统从ODS生成图形和其他时间序列数据的直观表示，用于交互式分析。第二个消费者是我们的自动警报系统，该系统从 ODS读取计数器，将它们与健康、性能和诊断指标的预设阈值进行比较，并向oncall工程师和自动补救系统发出警报。
2.1.1 监控系统读取性能问题2013 年初，脸书的监控团队意识到其HBase时序存储系统无法扩展处理未来的读取负载。虽然交互式图表的平均读取延迟是可以接受的，但是P90的查询时间增加到了几秒钟，阻碍了我们的自动化。此外，用户正在自我审查他们的用户年龄，因为即使是几千个时间序列的中等规模查询的交互式分析也需要几十秒钟才能执行。在稀疏数据集上执行的较大查询会超时，因为HBase数据存储被调整为优先写入。虽然我们基于HBase的TSDB效率低下，但我们很快就对存储系统进行了大规模更换，因为 ODS的HBase存储拥有大约2PB 的数据[5]。脸书的数据仓库解决方案Hive也不合适，因为它的查询延迟比ODS 高几个数量级，而查询延迟和效率是我们主要关心的问题[27]。
接下来，我们将注意力转向内存缓存。ODS已经使用了一个简单的通读缓存，但它主要是针对多个仪表板共享相同时间序列的图表系统。一个特别困难的场景是当仪表板查询最近的数据点，在缓存中错过，然后发出请求直接发送到 HBase 数据存储。我们还考虑了基于独立Memcache[20]的直写缓存，但拒绝了它，因为向现有时间序列添加新数据需要一个读/写周期，从而导致Memcache服务器的流量非常高。我们需要更有效的解决方案。
2.2 Gorilla要求考虑到这些因素，我们确定了新服务的以下要求:
由一个字符串键标识的20亿个唯一的时间序列。 每分钟增加7亿个数据点(时间戳和值)。 存储数据26小时。 峰值时每秒超过40,000次查询。 读取在不到一毫秒的时间内成功。 支持15秒粒度的时间序列(每个时间序列每分钟 4 个点)。 两个内存中、不在同一位置的副本(用于灾难恢复容量)。 即使单个服务器崩溃，也始终提供读取服务。 能够快速扫描所有内存中的数据。 支持每年至少2倍的增长。 在第3节与其他 TSDB 系统进行简单比较后，我们在第4节详细介绍Gorilla的实现，首先在第4.1 节讨论其新的时间戳和数据值压缩方案。然后，我们将在第 4.4 节中描述Gorilla如何在单节点故障和区域性灾难的情况下保持高可用性。我们将在第5节描述Gorilla如何启用新工具。最后，我们在第6节描述了我们开发和部署Gorilla的经验。
三、与 TSDB 系统的比较有许多出版物详细介绍了数据挖掘技术，以有效地搜索、分类和聚类大量的时间序列数据[8,23,24]。这些系统展示了检查时间序列数据的许多用途，从聚类和分类[8,23]到异常检测[10,16] 到索引时间序列[9,12,24]。然而，很少有例子详细说明能够实时收集和存储大量时间序列数据的系统。Gorilla的设计侧重于对生产系统进行可靠的实时监控，与其他TSDB相比非常突出。Gorilla占据了一个有趣的设计空间，在面对优先于任何旧数据可用性的故障时，可用于读取和写入。
由于 Gorilla 从一开始就被设计为将所有数据存储在内存中，因此它的内存结构也不同于现有TSDB。但是，如果将Gorilla视为另一个磁盘上TSDB之前的时间序列数据内存存储的中间存储，那么Gorilla 可以用作任何 TSDB 的直写缓存(相对简单的修改)。Gorilla对摄取速度和水平扩展的关注与现有解决方案相似。
3.1 OpenTSDBOpenTSDB基于HBase[28]，非常接近我们用于长期数据的ODS HBase存储层。这两个系统依赖于相似的表结构，并且在优化和水平可伸缩性方面得出了相似的结论[26,28]。然而，我们发现支持构建高级监控工具所需的查询量需要比基于磁盘的存储所能支持的更快的查询。
与OpenTSDB不同，ODS HBase层确实为较旧的数据进行时间累积聚合以节省空间**。这导致较旧的存档数据与ODS中较新的数据相比具有较低的时间粒度**，而OpenTSDB将永远保留全分辨率数据。我们发现，更便宜的长时间查询和空间节省是值得的精度损失。</description></item><item><title>保护您的服务网格：十三项清单</title><link>https://icorer.com/icorer_blog/posts/13-item_checklist_for_securing_your_service_mesh/</link><pubDate>Thu, 17 Feb 2022 14:57:18 +0800</pubDate><guid>https://icorer.com/icorer_blog/posts/13-item_checklist_for_securing_your_service_mesh/</guid><description>世界各地的组织都在急于对其应用程序进行现代化改造，以便在云中 Kubernetes 编排的容器中运行。在此现代化过程中，这些公司必须计划保护其应用程序连接。当应用程序被重新平台化并重新构建为分布式微服务时，会出现新的连接模式，这些模式通常会促使构建一个或多个服务网格。
强大的服务网格可以处理南北连接（从边缘进入基于 Kubernetes 的应用程序）和东西连接（同一集群上的服务之间或不同集群之间）。但是，这些流量模式中的每一个都需要全面的安全性.
实现服务网格安全性的最佳方法是采用零信任模型，这意味着每个连接，无论其来源如何，都必须经过验证和保护。为了帮助您评估服务网格技术并实施零信任安全，我们提供了 13 个必备功能，以确保您的应用程序连接安全。这是清单：
传输层安全性（TLS 和 mTLS）提供端到端加密，以保护任何端点对之间的动态数据。它可能是最基本的组件，但令人惊讶的是，并非所有服务网格都完全支持双向 TLS。 内置 Web 应用程序防火墙 (WAF)可屏蔽入站流量以发现威胁并阻止攻击侵入您的周边。对于任何向 Internet 公开以接收传入用户和应用程序连接请求的边缘网关来说，这都是必不可少的。 数据丢失防护 (DLP)监控数据泄露或泄露，以防止数据丢失和数据泄露。如果您的应用程序以某种方式受到损害，您不希望数据泄露您的边界。 Kubernetes的机密管理集成，后者管理密码、安全令牌和加密密钥等敏感凭证。您会担心这些信息仍然被硬编码到应用程序中或以纯文本形式存储的频率。 证书管理从集中式平台控制和执行 SSL 证书以验证连接。证书轮换可能是一个痛苦的管理步骤，应该优雅地加以考虑。这应该可以扩展以支持外部权限，这意味着它将与您已经使用的企业身份和访问管理解决方案一起使用。 授权，例如使用开放策略代理 (OPA)，它将服务 API 策略定义为代码。授权是身份验证的另一面，一旦您验证了他们的身份，谁就可以访问哪些资源。 联合信任域可以安全地跨环境对用户和应用程序进行身份验证，从而在任何地方始终如一地扩展身份验证策略。如果没有这个，您将花费大量精力来尝试保持各种角色的更新和同步——并且可能会犯一些错误。 联合的基于角色的访问控制 (RBAC) 和委派向用户授予与其职责相符的权限，并且再次在任何地方始终如一地应用此权限。这些控制可以应用于管理服务网格的运营商的不同级别，也可以应用于构建在网格中运行的应用程序的开发人员。 多租户和隔离使服务网格中的用户和应用程序可以安全地共享资源。拥有 RBAC 后，您可以安全地定义谁可以接触什么，并为不同的角色有效地创建隔离的工作空间。Istio 的授权策略也可用于防止不需要的流量到达您的应用程序。 漏洞扫描和出版物发现、解决和警告系统中的任何弱点。安全性与其最薄弱的环节一样好，因此检查防御中的任何漏洞很重要。 多集群访问可观察性为整个系统的所有活动提供完整的日志聚合和可审计性。这对于事件后的实时监控和取证都很有用。对于分布式应用程序，有必要获得全局视图。许多人使用 Prometheus 和 Grafana 等开源工具来实现可观察性。 联邦信息处理标准 (FIP) 140-2意味着您的服务网格技术已经过验证，符合美国政府规定的特定严格安全标准。有许多政府法规和行业最佳实践，但 FIPS 是确定安全基准的一种常用方法。 集群中继的安全拉取模型在整个系统中安全地共享配置。这是非常微妙的，但是您要确保任何配置更改都在请求时分发到边缘，并且仅在请求时分发。 虽然严格来说不是服务网格的安全特性，但一个额外的考虑因素是企业支持的可用性和用于响应的定义服务级别协议 (SLA)。</description></item><item><title>使用区块链将零信任架构扩展到端点：最先进的审查</title><link>https://icorer.com/icorer_blog/posts/blockchain_with_zerotrust/</link><pubDate>Tue, 15 Feb 2022 23:50:18 +0800</pubDate><guid>https://icorer.com/icorer_blog/posts/blockchain_with_zerotrust/</guid><description>摘要为了防御当今无边界网络中的横向移动，零信任架构(ZTA)的采用势头越来越猛。有了全面的 ZTA 实施，对手不太可能从受损的端点开始通过网络传播。然而，已经经过身份验证和授权的受损端点会话可以被用来执行有限的(尽管是恶意的)活动，最终使端点成为 ZTA 的致命弱点。为了有效地检测此类攻击，已经开发了具有基于攻击场景的方法的分布式协同入侵检测系统。尽管如此，高级持续威胁(APTs)已经证明了它们绕过这种方法的能力，并且成功率很高。因此，对手可以不被发现地通过或潜在地改变检测记录机制，以实现隐蔽的存在。最近，区块链技术在网络安全领域展示了可靠的使用案例。在本文中，受基于 ZTA 和区块链的入侵检测和防御的融合的推动，我们研究了如何将 ZTA 扩展到端点。也就是说，我们对 ZTA 模型、以端点为重点的真实体系结构以及基于区块链的入侵检测系统进行了最先进的审查。我们讨论了区块链的不变性增强检测过程的潜力，并确定了开放的挑战以及潜在的解决方案和未来的方向。
一、介绍随着云计算的革命，大多数企业的资源和数据不再存储在内部。此外，最近的新冠肺炎疫情事件极大地改变了工作模式，因为大多数员工和企业不得不转向在家工作。在家工作(和远程工作)会给组织带来新的严重安全风险，因为许多“未经培训”的员工使用自己的设备连接到工作信息技术(IT)系统。云计算和远程工作是企业必须扩大其数字安全范围并适应当代趋势的例子。
在传统的基于外围的安全模型中，组织在外围的资源和资产被认为是良性的和可信的。边界通常由安全措施保护，如防火墙或入侵检测系统。这种模式在云计算和远程工作领域似乎不太有效，针对远程工作员工的几次网络攻击(例如[1-5])就表明了这一点。
信任是传统的基于边界的安全模型所依赖的基本原则。员工或合作者的设备和组织资产(即端点)通常在默认情况下是可信的，而不管其状况如何。如果攻击者能够控制这些端点中的任何一个，那么边界就会受到威胁，并且通过横向移动有可能实现对信息和数据的进一步访问。
防火墙、防病毒技术、入侵检测和防御系统(IDS/IPS)和网络应用防火墙(WAFs)，换句话说，大石墙和装甲前门，已经不足以保证现代 IT 和运营技术(OT)环境的安全[6]。基于外围的安全是多家公司采用的主要概念，尤其是当他们的数据驻留在内部数据中心时。建立在内部和外部差异基础上的传统防御模式正在过时[7]，而与此同时，威胁格局也在急剧演变[8]，最终导致基于外围的安全架构的衰落。
为了应对当今复杂的网络基础设施和当前不断发展的威胁形势，需要一种新的安全架构。ZTA 通过建立无边界的基于数字身份的边界脱颖而出，在这个边界中，数据处于安全架构的中心，破坏思维主导着威胁模型， 引领着访问控制环境、运营、托管环境、端点和互连基础架构。ZTA 提倡一种新的安全架构，默认情况下，任何设备、系统、用户或应用程序都不应该基于其在网络中的位置而受到固有的信任。相反，不管在什么地方，信任总是要赢得和验证的。然而，这并不一定意味着在ZTA 的情况下信任被消除，而是应该最小化，直到通过ZTA 信条和核心组成部分证明不是这样。
使用传统的基于边界的防御，如果坚定的攻击者能够在端点上建立经过身份验证和授权的立足点，他们仍然可以绕过 ZTA 安全健康检查。例如，操作系统内核中的潜在恶意软件可以篡改在 ZTA 环境中进行的安全检查。这最终导致绕过在 ZTA 实施的基本控制，这将允许攻击者除了横向移动之外，还执行一些以用户和设备为中心的恶意活动。因此，需要一种有效的入侵检测方法来解决端点的漏洞，这可以被视为 ZTAs 的致命弱点。
在本文中，我们旨在研究如何利用区块链的不变性增强入侵检测过程的潜力，将 ZTA 扩展到端点，以消除上述问题。为此，我们首先回顾零信任的核心原则、能力和要求。其次，我们对现有的现实世界零信任实现进行分类，并讨论它们的优缺点。第三，我们探索了区块链在开发和改进分布式协作入侵检测系统(DCIDSs)方面的潜力，该系统可以缓解ZTA 的致命弱点(即端点的脆弱性)。最后，我们讨论了开放的问题和挑战，并强调了ZTA和基于区块链的分布式入侵检测系统的潜在解决方案和研究方向。
据我们所知，这是第一个利用区块链技术成功将ZTA扩展到端点的工作。表1给出了本文中使用的主要缩写及其定义。
二、零信任（ZT）在本节中，我们简要介绍了“零信任”和 ZTA 的历史，并讨论了零信任的核心原则、核心能力、模型和现有方法，包括现实世界的实现。
2.1 零信任架构的历史2004 年的杰里科论坛提出了去周边化的想法(当时是激进的)[3]，随后发展成为更广泛的零信任概念。早在2010 年，J. Kindervag [15]就创造了“零信任”一词；然而，在此之前，网络安全领域就存在零信任概念。美国国防部和国防信息系统局(DISA)提出了一项名为“黑核”的安全战略，并于 2007 年发表[16]。Black core讨论了从基于外围的安全架构向强调保护单个交易的安全架构的过渡。
云和移动计算的广泛采用极大地促进了 ZTAs 的发展，例如，作为其中的一部分，基于身份的架构等方法慢慢获得了关注和更广泛的接受。谷歌以“BeyondCorp”的名义发布了一系列关于如何实现零信任架构的六个文档[17-22]。BeyondCorp项目倡导去边界化的概念，认为基于边界的安全控制已经不够，安全应该扩展到用户和设备。由于这个项目，谷歌放弃了传统的基于虚拟专用网络(VPNs)的远程工作方式，并设法提供了一个合理的保证，即所有公司用户都可以通过不安全和不受管理的网络访问谷歌的网络。
2.2 从传统的周边架构到ZTA作为一种理念，“零信任”假设对用户、设备、工作负载和网络流量的信任不应被隐含地授予[15]，其结果是所有实体都必须被明确地验证、认证、授权和持续监控。零信任的核心目标之一是，一旦对手成功危及用户的设备，甚至简单地窃取他们的凭据，就会严重抑制对手横向移动的能力。因此，需要相应地塑造和准备信息技术基础设施。
传统的基于外围的安全架构会创建多个信任区域[2]。并非所有区域都遵守相同的规则或相同的信任级别。事实上，如果相关组件没有明确允许，用户甚至可能无法进入下一个区域。这被称为纵深防御，正如史密斯[23]所讨论的，并在图1中描述，或者称为城堡和护城河方法[24]。请注意，在到达大型机之前，不同的区域(互联网、非军事区、可信和特权)受到各种基于外围的控制的保护，例如本地代理、虚拟专用网网关、多个防火墙和应用程序服务。在这个例子(即图1)中，大型机是一个核心银行系统，负责所有交易，因此它被完全隔离在一个特权区域中。
与传统的安全架构不同，零信任要求从内到外进行思考、构建和保护。基于谷歌[19] [20]、Jericho[3]和Kindervag[15] [25]的上述工作，有一个直接和重要的观察， 即在ZTA，一旦网络位置依赖性变得无关紧要，虚拟专用网技术就可以被消除。简而言之，虚拟专用网允许远程工作的用户(在图1中用“远程员工”表示)通过安全的加密通道连接到办公室(在图1中用“可信”表示)。但是，应该通过其他方式保护端点，因为虚拟专用网加密只处理“远程员工”和“可信”区域之间的隧道。当“远程员工”通过身份验证并成功建立隧道时，他/她会收到“可信”区域的远程网络中的一个 IP 地址。在该隧道上， 从“远程员工”到“可信”区域的流量被解封并路由，因此导致“官方”后门。此外，被称为“虚拟专用网网关”的单一入口点充当体系结构和网络的单一故障点或扼杀点。因此，如果我们开始认为网络位置无关紧要，同时应用一组适当的控制，那么如果没有进一步的依赖关系 (例如，具有传统协议的应用程序)，就可以消除虚拟专用网络。也就是说，身份验证和授权以及策略实施应该立即向网络边缘和端点靠拢。
为了反映上面的论点，我们绘制了图 2，显示了对 ZTA的引用。为了简化起见，在图中，我们只包括核心组件，例如，本地代理(LB)、远程员工、移动设备、不可信客户端和许多需要保护的服务。与基于边界的架构相比，如图 1 所示，没有区域，安全性是由内而外构建的。此外，既没有 VPN 网关，也没有防火墙来过滤网络流量， 最重要的是没有单一的入口网关。我们注意到；但是，控制平面上的策略执行点。这种 ZTA 参考不会像基于外围的架构那样产生任何瓶颈。</description></item><item><title>自主网络安全-保障未来颠覆性技术</title><link>https://icorer.com/icorer_blog/posts/autonomous_network_security_securing_future_disruptive_technologies/</link><pubDate>Fri, 28 Jan 2022 21:07:07 +0800</pubDate><guid>https://icorer.com/icorer_blog/posts/autonomous_network_security_securing_future_disruptive_technologies/</guid><description>From：2021 年 IEEE ⽹络安全与弹性国际会议 (CSR)
概述这篇论文讲述自主网络安全知识的系统化。诸如物联网、人工智能和自治系统等颠覆性技术正变得越来越普通，而且通常很少或者根本没有网络安全保护，这种缺乏安全性导致的网络攻击面不断扩大。自主计算计划旨在通过使复杂计算系统自我管理来解决管理复杂计算系统的复杂性。自主系统包含应对网络攻击的属性，例如新技术的自我保护和自我修复。有许多关于自主网络安全的研究项目，采用不同的方法和目标技术，其中许多具有破坏性。本文回顾了自主计算，分析了自主网络安全的研究，并提供研究知识的系统化，本文最后确定自主网络安全方面的差距，以供未来研究。
一、介绍随着恶意⾏为者变得善于发现和利⽤⽹络和计算机系统中的缺陷[1]，对计算机系统的攻击数量随着复杂程度和严重程度的增加⽽增加。新的颠覆性技术不断被引⼊并连接到企业⽹络和互联⽹，这些技术限制了有些甚⾄没有内置的⽹络安全。其中包括⽹络物理系统/物联⽹ (CPS/IoT)、⼈⼯智能(AI) 和⾃治系统等技术。计算系统通常会在事后添加⽹络安全，⽽不是从⼀开始就设计，尤其是新的颠覆性技术，尤其是匆忙推向市场的技术。
系统需要能够以⾃我管理的⽅式对攻击和固有的弱点做出反应，⽆论是单独还是与其他系统⼀起。将安全性本地嵌⼊到软件和硬件系统中将使它们能够对攻击做出反应，并单独保护和治愈⾃⼰，并且作为⼀个群体。从本质上讲，这是⽹络安全的⾃主⽅法。
伯纳尔等⼈[2]在2019 年确定了⽹络安全⽅⾯的⼀些研究挑战，并将“软件化和虚拟化CPS/IoT系统和移动⽹络中的⾃主安全编排和执⾏”列为第⼆名，仅次于“可互操作和可扩展的安全管理异构⽣态系统”。 他们指出，需要新的⾃主和上下⽂感知安全协调器，它们可以快速、动态地编排和实施适当的防御机制。
本⽂的⽬的是调查⾃主⽹络安全研究中的空⽩，并将这些知识系统化以探索未来的研究。该论⽂基于对⾃主⽹络安全⽂献的调查和⽅法分类。这提供了对未来研究可以帮助推动⾃主⽹络安全向前发展以保护未来颠覆性技术的洞察⼒。本⽂的其余部分结构如下：第⼆部分提供了⾃主计算(AC) 的背景以及如何将⽹络安全设想为⾃主系统的⼀部分。第三部分描述了⾃主⽹络安全的过去和当前研究。⼀些研究侧重于特定应⽤领域的⾃主⽹络安全，⽽其他研究则提供可⽤于⼀系列应⽤的⾃主⽹络安全框架。第四节提供了研究分类和分类知识库的系统化，第五节讨论了基于知识系统化的⽹络安全研究的差距，第六节提供了结论性意⻅。
二、背景Kephart 和 Chess 在 2003 年的⾃主愿景论⽂[3]中将⾃主计算定义为“根据管理员的⾼级⽬标，可以⾃我管理的计算系统”。使⽤“⾃主计算”⼀词是因为⾃主神经系统管理⾝体功能，调整这些功能以满⾜⾝体需求，并为更⾼层次的认知活动释放有意识的活动。⽹络安全也是如此，它应该在维护服务的同时，根据当前的⽹络情况⾃动 调整和调整系统资源。Kephart 和 Chess 概述了⾃主系统应 具备的四个要素：
⾃我配置 ⾃我修复 ⾃我优化 ⾃我保护，也称为Self CHOP 提出了⼀个参考架构来实现能够适应不断变化的环境的Self CHOP 属性（图 1）。
Monitor、Analyze、Plan、Execute 和 Knowledge 组件统称为 MAPEK 架构。⾃主计算系统并未被设想为单⼀的独⽴系统，⽽是交互的、⾃我管理的系统，它们共同⼯作以实现其⽬标（图2）。
Self CHOP属性在[3]中定义为：
⾃配置：系统通过动态调整其资源来⾃动配置和重新配置⾃⾝的能⼒ ⾃我修复：系统从常规和意外事件中⾃动检测、诊断和修复硬件和软件的能⼒ ⾃我优化：系统和⼦组件监控其部件以检测性能下降同时不断寻求⾃我改进的能⼒ ⾃我保护：系统针对故障和恶意对系统的攻击能力能够⾃动检测和防御 自主安全CHOP属性可以为系统提供⽹络安全⽀持，以保护⾃⾝并从⽹络攻击中恢复。Kephart 将⾃我保护属性描述为保护系统免受⾃我修复属性⽆法纠正的恶意攻击或级联故障。其他Self CHOP属性也⽀持⾃保护属性，⾃修复属性在系统受到攻击后通过更新和脱落受损组件来修复系统，⾃配置属性帮助系统在禁⽤受损⼦系统后重新配置⾃⾝，⾃优化属性可以帮助系统通过攻击运⾏，然后重新配置后重新优化。
⾃主⽹络安全建⽴在⾃主视觉和参考架构的基础上，以开发⾃我管理能⼒，利⽤Self CHOP特性检测⽹络攻击并从⽹络攻击中恢复 [4]。⾃主⽹络安全不仅使⽤⾃主计算的Self CHOP特性，⽽且还互连⾃主元素，以提供⾃主元素之间的信息通信和共享，以共同应对攻击并从攻击中恢复。
三、自主网络安全方法以下是对一系列领域实施自主网络安全的方法的调查，这些领域包括智能汽车、网络物理系统/物联网、工业控制系统、关键基础设施、自组织计算、高性能计算、云计算、企业计算和其他。一些方法集中在架构上，另一些集中在被保护的领域或底层技术上。以下描述了调查的不同方法。它们按照是否使用 MAPEK 参考体系结构、非MAPEK体系结构、实现特定的自主特性、是提供自主开发支持的框架还是自主安全开发工具来分组。
3.1 MAPEK方法3.1.1 认知和自主网络安全Maymir Ducharme等人[5]在2015年描述了使用上下文分析和自主元素的分层网络，该网络从分层结构中的不同抽象层次提供系统元素的不同视图。具有更高级视图的自治元素将具有企业任务级上下文。更高级别的自治元素将根据公司功能的关键程度对这些功能进行优先排序，以便在紧急情况或网络攻击时维持运营。与安全相关的元素，如防火墙，将在层次结构中较低的抽象级别表示。
3.1.2 零信任Eidle等在2017年提出利用autonomic网络安全实现网络零信任[6]。作者开发了一个网络安全测试平台，实现了基于观察、定向、决定、行动(OODA)模型的零信任网络的各个方面，该模型与 MAPEK 参考架构相似，平台观察网络用于监控和分析攻击特征的身份验证日志。他们集成了来自多个网络设备的威胁响应，以简化威胁的检测和缓解危害。
3.1.3 自主车辆网络Le Lann在 2018年描述了未来智能汽车网络如何具有自主组织和自愈特性[7]。车辆网络可以构成由一组车辆组成的系统系统。每辆车都将是一个自主元件，与附近的其他车辆相连。车辆将被动态地连接在一起，形成“队列”，它们像车队一样一起行进，并提供群体安全。车辆可以根据车辆需求动态添加和删除。出于安全目的，加入群组需要身份验证。
3.1.4 使用大数据的分布式计算中的自主入侵响应Vierira等人在2018年使用了自主计算和大数据分析的组合来检测和响应网络攻击[8]。作者为自主入侵响应系统提供了一个参考架构，并开发了一个概念验证实现。作者将其入侵响应参考体系结构建立在 MAPEK 参考体系结构的基础上，网络流量系统日志是通过监控 MAPEK子组件收集的。</description></item><item><title>系统调用级二进制兼容的Unikernel虚拟机</title><link>https://icorer.com/icorer_blog/posts/system_call_level_binary_compatible_unikernel_virtual_machine/</link><pubDate>Mon, 24 Jan 2022 19:00:18 +0800</pubDate><guid>https://icorer.com/icorer_blog/posts/system_call_level_binary_compatible_unikernel_virtual_machine/</guid><description>一、背景Unikernel 是最小的单一用途虚拟机，目前在研究领域非常受欢迎，但是目前想把已有的应用程序移植到当前的unikernel环境是很困难的。HermiTux是第一个提供与Linux应用程序的系统调用级二进制兼容的unikernel，它由一个管理程序和一个模拟负载及运行时Linux ABI的轻量级内核层组成。HermiTux将应用程序开发人员从移植软件的负担中解脱出来，同时通过硬件辅助虚拟化隔离、快速启动时间和低磁盘/内存占⽤、安全性等提供单核优势。通过二进制分析重写技术及共享库替换，可以快速实现系统调用和内核模块化。
论文中展示了HermiTux的独立架构特色，在x86-64和ARM aarch64 ISA架构上展示了一个原型，针对各种云以及边缘/嵌入式部署，也展示了HermiTux对⼀系列原⽣C/C++/Fortran/Python Linux 应⽤程序的兼容性。HermiTux与其他unikernel相比，也提供了相似程度的轻量级，并且在许多情况下与Linux性能相似，它在内存和计算密集型场景下性能开销平均损失3%，其I/O性能是可以接受的。
二、HermiTux对于Linux程序兼容性的思路Unikernels在学术领域变得很流行，它以虚拟化LibOS模型为基础，这种模型也带来了很多好处，主要包括：提高安全性、性能改进、隔离性提升、降低成本等。这样的优势也增加了很多应用场景：云和边缘部署的微服务/基于Saas和Faas的软件、服务器应用程序、NFV、IOT、HPC等。尽管unikernel被视为容器领域具有吸引力的替代品，但unikernels仍然在行业中很难获得显著的牵引力，并且它们的采用率相当缓慢，主要原因是将遗留/现有的应用程序移植到unikernel模型很困难，有时候甚至是不可能的。
在大型程序中，移植复杂的代码库很困难，这是由于诸如不兼容/缺少库/函数、复杂的构建过程、缺乏开发工具（调试器/分析器）、不受支持的语言等因素存在。移植到unikernel环境，也需要程序员具备这方面的专业知识，巨大的移植负担是阻碍广泛采用unikernels最大的障碍之一。
HermiTux提出了一个新型的unikernel模型，他为常规Linux应用程序提供二进制兼容性，同时保留了unikernel的优势，它允许开发工作集中在unikernel这层。HermiTux原型是HermitCore unikernel的扩展，它能够运行原生的Linux可执行文件作为unikernel。通过提供这种基础设施，HermiTux将应用程序员的移植工作转变为unikernel层开发人员的支持工作，在这个模型下不仅可以让原生Linux应用程序透明地获得unikernel的好处，而且还可以运行以前不可移植的应用程序。使用HermiTux将遗留应用程序作为unikernel移植和运行是不存在的，HermiTux支持静态和动态链接的可执行文件、兼容多种语言（C/C++/Fortran/Python等）、编译器（GCC和LLVM）、全面优化（-O3）和剥离/混淆的二进制文件。它支持多线程和对称多处理器（SMP）、检查点/重启和迁移。
大多数现有的unikernel不提供任何类型的二进制兼容性，一些系统通过在C库级别进行接口适配来提供二进制兼容性，其作用类似于动态链接库。这可以防止它们通过系统调用来支持何种需要操作系统服务的应用程序，而无需通过C库。为了保障最大化的兼容性，HermiTux没有采用通用做法，在系统调用级别实现了所有应用程序和编译库使用的标准化接口。
三、HermiTux的挑战HermiTux应对的第一个挑战是如何提供系统调用级别的二进制兼容性？，因此HermiTux根据Linux应用程序二进制接口ABI设置执行环境并在运行时模拟OS接口。基于自定义管理程序的ELF加载程序用于在单个空间虚拟机中与最小内核一起运行Linux二进制文件。程序运行的系统调用被重定向到unikernel提供的实现。
HermiTux应对的第二个挑战是如何在**提供二进制兼容性的同时保持unikernel的好处？**有些是自然具备的好处（小磁盘/内存占用、虚拟化强制隔离），而另一些（快速的系统调用、内核模块化）在假设无法访问源代码时会带来技术挑战。为了实现这些好处，HermiTux对于静态可执行文件使用了二进制重写与分析技术，并在运行时用一个可识别的unikernel的C库替代动态链接库的可执行文件。最后HermiTux针对低磁盘/内存占用和攻击面进行了优化，与现有的unikernel一样低或更低。
由于unikernel应用案例广泛，HermiTux当前目的是兼容服务器和嵌入式虚拟化场景，因此主要支持Intel x86-64和 ARM aarch64 (ARM64) 指令集架构 (ISA) 开发。HermiTux的设计基本原则是独立于架构，但是它的实现以及我们用来恢复unikernel的二进制重写/分析技术是ISA特定的。
总体来说，HermiTux做了以下出色工作：
一种新的unikernel模型，旨在执行本机Linux可执行程序，同时保持经典的unikernel优势。 提供可以在x86-64 和 aarch64 架构上的两个原型实现。 四、关键概念阐述4.1 Unikernelsunikernel是一个应用程序，它使用必要的库和一个精简OS层静态编译成一个二进制文件，能够作为虚拟机在管理程序上执行。Unikernel符合以下条件：
单一目的：一个unikernel只包含一个应用程序 单一地址空间：由于单一目的原则，所以unikernel不需要内存保护，因此应用程序和内核共享一个地址空间，所有代码都以最高权限级别执行。 这样的模型提供了显著的好处，在安全性方面提供了unikernel之间的强隔离，虚拟机管理程序让它成为云部署的良好候选者。此外unikernel仅包含运行给定应用程序所需的必要软件。结合非常小的内核尺寸，和常规VM相比，这导致应用程序攻击面显著减少。一些unikernel也是用提供内存安全保障的语言编写的。关于性能方面，unikernel系统调用很快，因为它们是常见的函数调用，特权级别之间没有代价昂贵的用户态与内核态切换。上下文切换也很快，因为没有页表切换或TLB刷新。除了由于小内核导致代码库减少之外，unikernel OS层通常是模块化的，可以将它们配置为仅包含给定应用程序的必要功能。
所有这些好处让unikernels的应用程序域非常丰富。他们非常适合运行大多数需要高度隔离的云应用程序和需要高性能、低操作系统开销的计算密集型作业的数据中心。unikernel减少的资源使用使它们特别适合嵌入式虚拟化，随着边缘计算和物联网等范式的出现，这个领域的重要性日益增加。由于unikernels的应用领域包括服务器和嵌入式机器，因此论文主要针对intel x86-64和 aarch64架构进行模型构建。
4.2将现有应用程序移植到Unikernel移植现有软件作为unikernel运行是很困难的，特别在某些情况下无法移植程序到unikernel环境，因为所有的程序都需要重新编译与链接。一个给定的unikernel支持一组有限的内核特性和软件库，如果不支持应用程序所需的函数、库或者特定版本的库，则该程序需要进行调整。在许多情况下，缺少函数/库意味着应用程序根本无法移植，此外unikernel使用复杂的构建基础架构，将一些遗留的应用程序（大型的Makefile、autotools、cmake）移植到unikernel工具链会很麻烦，更改编译器或者构建选项也是如此。
在如此大的移植成本上，所以unikernel发展缓慢是有原因的，一种解决方案是让unikernel为常规可执行文件提供二进制兼容性，同时仍保持经典 unikernel 的优势，例如⼩代码库/占⽤空间、快速启动时间、模块化等。这种新模型允许 unikernel 开发⼈员致⼒于推⼴unikernel 层以⽀持最⼤应⽤程序的数量，并减轻应⽤程序开 发⼈员的任何移植⼯作。这种⽅法还应该⽀持调试器等开发⼯具。在这种情况下，HermiTux 允许将 Linux ⼆进制⽂件作为unikernel 运⾏，同时保持上述优势。
4.3 轻量级虚拟化设计空间轻量级虚拟化设计空间包含unikernel、面向安全的LibOS、例如Graphene，以及带有软件和硬件强化技术的容器。HermiTux不需要应用程序移植工作，并且和其他二进制兼容的系统方案不同，不同点主要包括：
作为unikernel HermiTux运行硬件强制（扩展页表）虚拟机，这是一种从根本上比软件强制隔离（容器/软件LibOS）更强的隔离机制。当前在VM中运行容器以确保安全的趋势（clear containers）加强容器隔离的努力（gVisor）都表明了这一点，这通常用作支持unikernel与容器的安全依据。 HermiTux使更广泛的应用程序能够透明地无需任何移植工作即可获得unikernel的好处，无需修改代码以及维护单独分支的潜在复杂性。鉴于unikernel提供的安全性和减少占用空间的特性，这在当今的计算机系统环境中非常有价值，软件和硬件漏洞经常成为新闻，并且数据中心架构师正在寻求增加整合和减少资源/能源消耗的方法。二进制兼容允许HermiTux成为专有软件（其源代码不可用）作为unikernel运行的唯一方法。最后，HermiTux允许软件获得VM的传统优势，例如检查点/重启/迁移，而无需大量磁盘/内存占用的相关开销。 4.4 系统调用级二进制兼容两个现有的unikernel已经生成和应用程序的二进制兼容，OSv和Lupin Linux。需要注意的是，两者都提供二进制兼容性标准C库（libc）级别，unikernel包含一个动态加载程序，它在运行时捕获对libc函数的调用，例如printf、fopen并将它重定向到内核。
这种接口方法意味着假设所有系统调用都是通过libc进行的，当考虑到各种各样的现代应用程序二进制文件时，这并不成立。我们分析了整个Debian10 x86-64存储库 (主要，贡献 和 ⾮免费） 并统计了553个ELF可执⾏⽂件，包括⾄少⼀次调⽤系统调⽤指令：这些代表不通过libc 执⾏系统调⽤程序，因此 libc 级别的⼆进制兼容unikernel 不⽀持这些程序。这种有限的libc级兼容性组织了这些系统运行相对较大范围的应用程序，这些应用程序将从座位unikernel的执行中受益匪浅。举几个例子，大量的云服务是用Go语言编写的，Go是一种无须标准C库即可执行大多数系统调用的语言。此外，由于在系统调用层面缺乏兼容性，OSv不支持最流行的HPC共享内存编程框架OpenMP，最后libc接口排除了对静态二进制文件的支持。
HermiTux代表了一种尝试，通过增加一个更加标准和一致使用的接口（系统调用级别）上进行接口来进一步推动unikernel的兼容性程度。</description></item></channel></rss>