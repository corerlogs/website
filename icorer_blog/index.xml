<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>笔迹-工匠之芯</title><link>https://icorer.com/icorer_blog/</link><description>Recent content on 笔迹-工匠之芯</description><generator>Hugo -- gohugo.io</generator><language>zh-cn</language><lastBuildDate>Mon, 12 Dec 2022 11:55:18 +0800</lastBuildDate><atom:link href="https://icorer.com/icorer_blog/index.xml" rel="self" type="application/rss+xml"/><item><title>Self-Sovereign Identity：什么是自我主权身份？</title><link>https://icorer.com/icorer_blog/posts/web3/what-is-self-sovereign-identity/</link><pubDate>Mon, 12 Dec 2022 11:55:18 +0800</pubDate><guid>https://icorer.com/icorer_blog/posts/web3/what-is-self-sovereign-identity/</guid><description>如今，我们日常生活的许多方面都依赖数字服务，从在线购物到所谓的 Web2.0 中的金融服务。我们使用多个（如果不是数百个）帐户与不同的集中式网络平台（例如社交媒体或电子邮件服务）进行交互。问题是，当我们无法访问我们的帐户时，我们就会失去我们的数字身份，因为网站无法再识别我们是谁。这意味着我们实际上并不拥有我们的身份和数据。这有问题。我们需要收回数据和数字身份的所有权，而自主身份可以实现这一点，为我们进入 Web3.0 铺平道路。
自我主权身份是指一种让个人控制其数字身份的方法。自我主权身份 (SSI) 是一项运动，它声称数字身份应该与一个人的人类身份一样合法，同时所有人都可以访问、保护隐私并且不依赖于单一的政府或公司。
那么究竟什么是自我主权身份呢？自我主权身份是指一种让个人控制其数字身份的方法。为了更好地理解这个概念，让我们看一下两个模型：
Web 2.0 - 集中式模型我们的电子邮件帐户、网站帐户和社交媒体帐户目前允许数字服务在线识别我们。我们要么为每个平台创建一个帐户，要么使用 Facebook 或 Google 等服务提供商提供的单点登录。无论我们使用哪种方法，我们的数据都由帐户提供商集中存储。这种模式产生了一些严重的问题：
管理困难：我们努力管理众多帐户以访问不同的数字平台。此外，这些平台可以单方面决定关闭我们的帐户，或代表我们管理它。
安全和依赖风险：由于我们的大多数帐户都与我们的电子邮件地址相关联，如果我们的电子邮件访问受到威胁，黑客可以通过“忘记我的密码”方法更改密码来轻松接管使用该电子邮件的其他帐户。例如，黑客可以伪装成数字化的你，并在 Facebook 上欺骗你的家人和朋友。
隐私的脆弱性：如果我们使用的服务被黑客入侵，我们的数据很可能会被泄露，因为它是集中存储的。根据身份盗窃研究中心的数据，到 2021 年 10 月，将近 2.815 亿人受到某种数据泄露的影响。
缺乏数据自主权：我们无法控制我们的数据如何被使用或与其他平台共享。更糟糕的是，这些数据是代表我们的身份。
Web 3.0 - 去中心化模型为了克服中心化身份模型的上述所有问题，我们需要引入去中心化身份模型，从而实现自我主权身份。个人与对应方（例如个人、组织或物联网）之间的关系是点对点的。它不再依赖中心化的实体，而是利用去中心化的网络，即区块链技术。这种方法的一些好处：
弹性网络：区块链网络永远不会宕机，而集中式网络由公司运营。 可验证凭证：数据和信息由身份所有者选择的受信任方（例如政府和银行）作为凭证发布。如果授予访问权限，其他节点可以验证链上的凭证。 建立信任：不变性是区块链的本质，它确保了可验证凭证的真实性。例如，同行可以通过链上证明来验证文凭是否由大学颁发。 控制数据：自主身份的所有者可以决定何时共享凭据，以及共享哪些凭据。 自我主权身份是一种以用户为中心的数字身份，我们作为用户可以完全控制我们的在线身份，但它不仅适用于个人，也适用于组织甚至设备 (IoT) 或程序。我们相信在不久的将来，我们都将使用自主身份在数字世界中进行点对点交互，而不是依赖于其他方基于账户的数字身份。
身份类型 真实身份人类身份是一个复杂的话题，几个世纪以来哲学家们一直在争论这个问题，而我所说的任何话都无法解决这些争论。我将人的身份简化为两部分，这两部分对于一个人成为社会上有生产力的成员来说都是必不可少的。
内在同一性：这就是我们照镜子时所看到的。这是我们的性别认同、政治认同或文化认同。在我们与最亲密的知己的关系中，这就是我们的身份。它是我们固有的，是身份的最真实形式。
外在身份：这是其他人（通常是机构）识别我们的方式。驾照是最普遍的例子。虽然旨在证明您有资格在公共道路上行驶，但它也是金融机构、机场和酒吧识别您的方式。它之所以有效，是因为机构信任，并且有了驾照，您始终可以得到担保。而且它不仅限于政府、教育、专业和会员凭证都以同样的方式工作。
数字身份一些最大的社交媒体、博客和其他互联网平台的存在基本上是为了帮助人们表达他们内在的身份。但是（值得注意的是）仍然没有很好的方法来数字化管理我们的外在身份。我们仍然使用纸质文件和塑料卡来访问我们生活中一些最重要的服务，使我们身份的一些最敏感和最重要的方面受到欺诈。令人恐惧的是，在日益数字化的世界中，我们有时必须扫描、通过电子邮件发送或发送这些文件的照片才能完成一些基本的事情，例如获得购房资格或开设银行账户。
自我主权身份自我主权身份是真实身份与数字世界的结合，最终将使人们的生活更美好。它仍处于起步阶段，要真正使数字身份像现实世界一样合法，还有很长的路要走身份。但最近有几项非常有前途的技术进步代表了巨大的突破，其中最重要的是数字钱包的出现和可验证凭证的标准化，这些共同创造了一条首次将我们的外在身份在线化的途径。
技术组成 数字钱包数字钱包顾名思义：一个安全的数字环境，您可以在其中保存重要的卡片（例如驾照、员工身份证）或货币。就像在现实世界中一样，这个钱包有一些重要的属性：
钱包中的卡是由受信任的实体（即颁发的驾驶执照）提供给您的。
您可以随心所欲地使用这些卡片来证明您的身份或其他特征。
卡片是你的；没有人能把它们带走。但是，为您提供该卡的组织可能会撤销它或让它过期。
未经您的许可，任何人甚至无法查看您钱包中的内容，即使是钱包提供商。
您可以随意切换钱包。如果你找到另一个钱包，你可以相对轻松地将你的卡换到新的。
钱包，无论是实体钱包还是数字钱包，都只是一个容器。它需要有价值的内容，数字钱包持有的“卡片”被称为“可验证凭证”。
可验证凭证可验证凭证是在线表示外部身份的标准方式。作为 SSI 钱包中的主要内容，它们通常是您通常保存在实体钱包中的卡片的数字化、防篡改、不可转让、可验证版本。您可以在保护隐私的同时共享来自这些凭据的经过验证的信息（例如在不透露您的地址的情况下共享您的选民选区或在不透露您的 SSN 的情况下共享您的信用评分）。由于凭据是您的，因此您不需要用户名和密码即可访问它们。在未来的状态下，服务的访问可能基于这些凭据。
可验证凭证有很多实现线路，目前我所关注的是DID+DeCA模型的方案。
商业 自我主权身份对企业也有巨大的影响，在下面列出几个示例：
改进转换：当前的技术迫使公司在保证和转换之间做出权衡。借助 SSI，公司可以消除在银行、保险、医疗保健等高价值环境中即时加入新用户的摩擦，在这些环境中，简单的 CAPTCHA 是不够的。 新融合：额外的信任可以在哪些方面帮助您更好地与利益相关者互动？B2C 案例包括使用数字政府 ID 开立银行账户而无需平均24 天 KYC入职流程的银行、验证军人、教师和学生身份的零售公司，以及介于两者之间的一切。还有很多 B2B 案例，从供应链公司认证工业设施的审计合规性到医疗软件集成以简化保险理赔验证。 验证： 任何时候验证成本高昂或很重要，SSI 都可以提供帮助。尽管每年在身份验证上花费数十亿美元，但仍有数十亿美元因欺诈而损失。SSI 支持更好的身份验证过程，不仅适用于合法身份，还适用于任何特征。 风险：如果您的企业持有密码、社会安全号码、信用卡号码或其他高价值个人身份信息，您将面临数据泄露的风险。SSI 可以让您避免收集、存储、保护和维护异常的个人身份信息，从而降低您的风险。例如，您可以在不收集社保号码的情况下验证信用评分，或者在没有地址的情况下确认选民选区。 合规性：在过去十年中，合规性是第三方支付处理商（如 Stripe 和 PayPal）增长的重要驱动力。同样，GDPR、CCPA和无数其他数据保护法规正在推动 SSI 的采用。 自我主权身份将在全球所有市场释放巨大的宝贵机会，任何行业都将受到其影响。</description></item><item><title>采用零信任模型的13个必备功能</title><link>https://icorer.com/icorer_blog/posts/zerotrust/13-must-have-features-to-adopting-a-zero-trust-model/</link><pubDate>Sun, 11 Dec 2022 11:55:18 +0800</pubDate><guid>https://icorer.com/icorer_blog/posts/zerotrust/13-must-have-features-to-adopting-a-zero-trust-model/</guid><description> 处理服务网格安全性的最佳方法是采用零信任模型，这意味着每个连接，无论其来源如何，都必须经过验证和保护。为了帮助您评估服务网格技术并实施零信任安全，我们展示了13个必备功能，以确保您的应用程序连接安全。
1. 传输层安全性（TLS 和 mTLS）提供端到端加密以保护任何一对端点之间的移动数据。它可能是最基本的组件，但令人惊讶的是并非所有服务网格都完全支持双向 TLS。 2.授权例如，Open Policy Agent (OPA) 将服务 API 策略定义为代码。授权是身份验证的另一面，一旦您验证了他们的身份，便可以控制谁可以访问哪些资源。
3.证书管理从集中式平台控制和执行 SSL 证书以验证连接。证书轮换可能是一个痛苦的管理步骤，应该从容应对。这应该是可扩展的以支持外部权限，这意味着它将与您已经使用的企业身份和访问管理解决方案一起工作。
4.基于角色的联合出入控制(RBAC)和委托向用户授予与其职责相适应的权限，并再次在所有地方始终如一地应用此权限。这些控制可以应用于不同级别的操作员管理服务网格，也适用于构建在网格中运行的应用程序的开发人员。
5.联合信任域跨环境安全地验证用户和应用程序，在任何地方一致地扩展验证策略。否则，您将花费大量精力尝试保持各种角色的更新和同步——并且可能会犯一些错误。
6.联邦信息处理标准 (FIP) 140-2意味着您的服务网格技术已经过验证，可以满足美国政府制定的特定严格安全标准。有许多政府法规和行业最佳实践，但 FIPS 是一种常用的安全基准方法。
7.多租户和隔离让服务网格中的用户和应用程序安全地共享资源。拥有 RBAC 后，您可以安全地定义谁可以触摸什么，并有效地为不同角色创建隔离的工作区。 服务网格的授权策略也可用于防止不需要的流量到达您的应用程序。
8. 内置 Web 应用程序防火墙 (WAF)筛选入站流量中的威胁并阻止攻击渗透到您的边界。对于任何暴露在互联网上的边缘网关来说，它对于传入的用户和应用程序连接请求都是必不可少的,WAF除了边界网关模型，还需要内置进入各类端点程序，让WAF可以增强东西流量应用层的安全性。
9.数据丢失防护 (DLP)监控数据泄露或泄露，以防止数据丢失和数据泄漏。如果您的应用程序以某种方式受到损害，您不希望数据逃离您的边界。
10.与机密管理集成对于管理密码、安全令牌和加密密钥等敏感凭证的 Kubernetes。您会惊奇地发现这些信息仍然被硬编码到应用程序中或以纯文本形式存储的频率。
11.多集群访问可观察性提供整个系统所有活动的完整日志聚合和可审计性。这对于事件发生后的实时监控和取证都非常有用。对于分布式应用程序，有必要获得一个整体视图。许多人使用 Prometheus 和 Grafana 等开源工具来实现可观察性。 12.漏洞扫描和发布查找、解决和警告系统中的任何弱点。安全性取决于其最薄弱的环节，因此检查您的防御措施是否存在漏洞非常重要。 13.集群中继的安全拉取模型在整个系统中安全地共享配置。这非常微妙，但您希望确保任何配置更改都在请求时分发到边缘，并且仅在请求时分发。
附录 What is mtls The zero trust authorization core What is Certificate Management RBAC vs. ABAC: What’s the Difference Creating Federation Trust between organizations FIPS 140-2 OWASP Coraza WAF Web application firewall (WAF) What is DLP</description></item><item><title>Drand去中心化可验证随机数</title><link>https://icorer.com/icorer_blog/posts/web3/verifiable-random-number-drand-program-experiment/</link><pubDate>Thu, 08 Dec 2022 11:55:18 +0800</pubDate><guid>https://icorer.com/icorer_blog/posts/web3/verifiable-random-number-drand-program-experiment/</guid><description>Drand最初来自DEDIS实验室，由于使用基于配对的密码学，drand 能够以非常简单和有效的方式生成随机性，并以可靠的方式将其交付给客户端。Drand 旨在成为一种分布式服务，以与应用程序无关、安全且高效的方式提供公共随机性。随着 drand 的成熟，越来越多的组织（包括 NIST、Cloudflare、Kudelski Security、智利大学和协议实验室）开始感兴趣，并决定共同努力建立一个跨越这些组织的 drand 网络。
Drand 旨在成为一种互联网基础设施级服务，为应用程序提供随机性，类似于 NTP 提供计时信息和证书透明服务器提供证书吊销信息的方式，Drand去中心化随机数方案可以提供 去中心化随机性与可验证性两大核心功能。
为什么去中心化随机性很重要多年来，一代公共随机性(通常称为common coins)吸引了密码学研究社区的持续兴趣。许多分布式系统，包括各种共识机制、Tor等匿名网络或区块链系统，都假定可以访问这种公共随机性。例如，在最近的权益证明区块链中，矿工在每个时期都是通过一个共同的随机源随机选出的。然而，拥有一个不可偏置的、分布式的、可扩展的公共随机资源仍然是一个主要的缺失部分。目前存在一些集中式解决方案，尽管它们确实提供了一个统一的随机性来源，但这些信标既不可验证也不分散。可验证性是必要的。对于权益证明系统中的示例，可验证性是必要的，在该系统中，区块生产者需要证明他已被选为给定时期的矿工。
实验代码 1 2package main 3 4import ( 5 &amp;#34;context&amp;#34; 6 &amp;#34;encoding/hex&amp;#34; 7 &amp;#34;log&amp;#34; 8 &amp;#34;time&amp;#34; 9 10 &amp;#34;github.com/drand/drand/client&amp;#34; 11 &amp;#34;github.com/drand/drand/client/http&amp;#34; 12) 13 14var urls = []string{ 15 &amp;#34;https://api.drand.sh&amp;#34;, 16 &amp;#34;https://drand.cloudflare.com&amp;#34;, 17} 18 19var chainHash, _ = hex.DecodeString(&amp;#34;8990e7a9aaed2ffed73dbd7092123d6f289930540d7651336225dc172e51b2ce&amp;#34;) 20 21func main() { 22 c, err := client.New( 23 client.From(http.ForURLs(urls, chainHash)...), 24 client.WithChainHash(chainHash), 25 ) 26 27 if err !</description></item><item><title>2022 Wanxiang Blockchain Spring Hackathon - IceFireDB Won The First Prize</title><link>https://icorer.com/icorer_blog/posts/icefiredb2022wanxiang/</link><pubDate>Tue, 14 Jun 2022 12:55:18 +0800</pubDate><guid>https://icorer.com/icorer_blog/posts/icefiredb2022wanxiang/</guid><description>2022 Wanxiang Blockchain Spring Hackathon Wrapped up on June 12th,We are very lucky and grateful to Protocol Labs for giving us this honor. In addition to joy, we are more moved. Our efforts and innovation are recognized. Next, we will work harder to incubate our projects.
2022 Wanxiang Blockchain Spring Hackathon, an immensely successful hackathon packed with over 20 teams of passionate builders and developers wrapped up yesterday, under the theme of “Metaverse: A Shared Future on Blockchain”.</description></item><item><title>Gorilla：一个快速、可伸缩的内存时间序列数据库</title><link>https://icorer.com/icorer_blog/posts/gorilladb/</link><pubDate>Fri, 01 Apr 2022 17:26:18 +0800</pubDate><guid>https://icorer.com/icorer_blog/posts/gorilladb/</guid><description>摘要大规模互联网服务旨在出现意外故障时保持高可用性和高响应性。提供这种服务通常需要在大量系统上每秒钟监测和分析数千万次测量，一个特别有效的解决方案是在时间序列数据库(TSDB)中存储和查询这种测量。TSDB设计中的一个关键挑战是如何在效率、可伸缩性和可靠性之间取得平衡。在本文中，我们介绍Gorilla系统，脸书的内存TSDB。我们的见解是，监控系统的用户不太重视单个数据点，而是更重视综合分析，对于快速检测和诊断持续问题的根本原因而言，最新数据点比旧数据点更有价值。Gorilla优化了写入和读取的高可用性，即使在出现故障时也是如此，代价是可能会在写入路径上丢弃少量数据。为了提高查询效率，我们积极利用压缩技术，如增量时间戳和异或浮点值，将Gorilla的存储空间减少了10倍。这使我们能够将Gorilla的数据存储在内存中，与传统数据库(HBase)支持的时间序列数据相比，查询延迟减少了73倍，查询吞吐量提高了14倍。这种性能改进带来了新的监控和调试工具，比如时序关联搜索和更密集的可视化工具。Gorilla还可以优雅地处理从单个节点到整个区域的故障，几乎没有运营开销。
一、介绍大规模互联网服务即使在出现意外故障的情况下也能保持高可用性和对用户的响应。随着这些服务发展到支持全球客户，它们已经从运行在数百台机器上的几个系统扩展到服务数以千计的个人用户系统运行在数千台机器上，通常跨越多个地理复制的数据中心。
运行这些大规模服务的一个重要要求是准确监控底层系统的健康和性能，并在出现问题时快速识别和诊断问题。脸书使用时间序列数据库(TSDB)存储系统测量数据点，并在顶部提供快速查询功能。接下来，我们将指定监控和操作脸书需要满足的一些约束，然后描述Gorilla，这是我们新的内存TSDB，可以存储数千万个数据点(例如，CPU 负载、错误率、延迟等)。)并在几毫秒内响应对此数据的查询。
写占主导地位。我们对 TSDB 的主要要求是它应该始终可用于写入。由于我们有数百个公开数据项的系统，写入速率可能很容易超过每秒数千万个数据点。相比之下，读取速率通常要低几个数量级，因为它主要来自于观察“重要”时间序列数据的自动化系统、可视化系统或为希望诊断观察到问题的人类操作员提供仪表板。
状态转换。我们希望识别新软件发布中出现的问题、配置更改的意外副作用、网络中断以及导致重大状态转换的其他问题。因此，我们希望我们的TSDB支持短时间窗口内的细粒度聚合。在几十秒钟内显示状态转换的能力特别有价值，因为它允许自动化在问题变得广泛传播之前快速修复问题。
高可用性。即使网络分区或其他故障导致不同数据中心之间的连接断开，在任何给定数据中心内运行的系统都应该能够将数据写入本地TSDB机器，并且能够按需检索这些数据。
容错。我们希望将所有写入复制到多个区域，这样我们就可以在任何给定的数据中心或地理区域因灾难而丢失时幸存下来。
Gorilla是脸书的新TSDB，满足了这些限制。Gorilla用作进入监控系统的最新数据的直写缓存。我们的目标是确保大多数查询在几十毫秒内运行。Gorilla 的设计理念是，监控系统的用户不太重视单个数据点，而是更重视综合分析。此外，这些系统不存储任何用户数据，因此传统的 ACID保证不是TSDB的核心要求。 但是，高比例的写入必须始终成功，即使面临可能导致整个数据中心无法访问的灾难。此外，最近的数据点比旧的数据点具有更高的价值，因为直觉上，对于运营工程师来说，知道特定系统或服务现在是否被破坏比知道它是否在一个小时前被破坏更有价值，Gorilla 进行了优化，即使在出现故障的情况下也能保持高度的读写可用性，代价是可能会丢失少量数据写入路径。
高数据插入率、总数据量、实时聚合和可靠性要求带来了挑战。我们依次解决了这些问题。为了解决第一个要求，我们分析了 TSDB 操作数据存储(ODS),这是一个在脸书广泛使用的老的监控系统。我们注意到，对ODS的所有查询中，至少有85%是针对过去26小时内收集的数据。进一步的分析使我们能够确定，如果我们能够用内存中的数据库替换基于磁盘的数据库，我们可能能够为我们的用户提供最好的服务。此外，通过将这个内存中的数据库视为持久的基于磁盘的存储的缓存，我们可以实现具有基于磁盘的数据库的持久性的内存中系统的插入速度。
截至2015年春天，脸书的监控系统生成了超过20亿个独特的时间序列计数器，每秒钟增加约1200万个数据点。这代表每天超过1万亿个点。在每点16字节的情况下，产生的16TBRAM对于实际部署来说太耗费资源了。我们通过重新利用现有的基于XOR的浮点压缩方案来解决这一问题，使其以流的方式工作，从而允许我们将时间序列压缩到平均每点1.37字节，大小减少了12倍。
我们通过在不同的数据中心区域运行多个Gorilla实例并向每个实例传输数据流来满足可靠性要求，而不试图保证一致性。读取查询指向最近的可用Gorilla实例。请注意，这种设计利用了我们的观察，即在不影响数据聚合的情况下，单个数据点可能会丢失，除非Gorilla实例之间存在显著差异。Gorilla目前正在脸书的生产中运行，工程师们每天将其用于实时灭火和调试，并与Hive[27]和Scuba[3]等其他监控和分析系统结合使用，以检测和诊断问题。
二、背景和要求2.1 操作数据存储脸书的大型基础设施由分布在多个数据中心的数百个系统组成，如果没有能够跟踪其运行状况和性能的监控系统，运营和管理这些基础设施将会非常困难。业务数据储存库是脸书监测系统的一个重要部分。ODS由一个时间序列数据库(TSDB)、一个查询服务以及一个探测和警报系统组成。ODS的TSDB 构建在 HBase存储系统之上，如[26]中所述。图1显示了ODS组织方式的高级视图。来自运行在脸书主机上的服务的时间序列数据由ODS写入服务收集并写入 HBase。
ODS时间序列数据有两个消费者。第一个消费者是依赖制图系统的工程师，该系统从ODS生成图形和其他时间序列数据的直观表示，用于交互式分析。第二个消费者是我们的自动警报系统，该系统从 ODS读取计数器，将它们与健康、性能和诊断指标的预设阈值进行比较，并向oncall工程师和自动补救系统发出警报。
2.1.1 监控系统读取性能问题2013 年初，脸书的监控团队意识到其HBase时序存储系统无法扩展处理未来的读取负载。虽然交互式图表的平均读取延迟是可以接受的，但是P90的查询时间增加到了几秒钟，阻碍了我们的自动化。此外，用户正在自我审查他们的用户年龄，因为即使是几千个时间序列的中等规模查询的交互式分析也需要几十秒钟才能执行。在稀疏数据集上执行的较大查询会超时，因为HBase数据存储被调整为优先写入。虽然我们基于HBase的TSDB效率低下，但我们很快就对存储系统进行了大规模更换，因为 ODS的HBase存储拥有大约2PB 的数据[5]。脸书的数据仓库解决方案Hive也不合适，因为它的查询延迟比ODS 高几个数量级，而查询延迟和效率是我们主要关心的问题[27]。
接下来，我们将注意力转向内存缓存。ODS已经使用了一个简单的通读缓存，但它主要是针对多个仪表板共享相同时间序列的图表系统。一个特别困难的场景是当仪表板查询最近的数据点，在缓存中错过，然后发出请求直接发送到 HBase 数据存储。我们还考虑了基于独立Memcache[20]的直写缓存，但拒绝了它，因为向现有时间序列添加新数据需要一个读/写周期，从而导致Memcache服务器的流量非常高。我们需要更有效的解决方案。
2.2 Gorilla要求考虑到这些因素，我们确定了新服务的以下要求:
由一个字符串键标识的20亿个唯一的时间序列。 每分钟增加7亿个数据点(时间戳和值)。 存储数据26小时。 峰值时每秒超过40,000次查询。 读取在不到一毫秒的时间内成功。 支持15秒粒度的时间序列(每个时间序列每分钟 4 个点)。 两个内存中、不在同一位置的副本(用于灾难恢复容量)。 即使单个服务器崩溃，也始终提供读取服务。 能够快速扫描所有内存中的数据。 支持每年至少2倍的增长。 在第3节与其他 TSDB 系统进行简单比较后，我们在第4节详细介绍Gorilla的实现，首先在第4.1 节讨论其新的时间戳和数据值压缩方案。然后，我们将在第 4.4 节中描述Gorilla如何在单节点故障和区域性灾难的情况下保持高可用性。我们将在第5节描述Gorilla如何启用新工具。最后，我们在第6节描述了我们开发和部署Gorilla的经验。
三、与 TSDB 系统的比较有许多出版物详细介绍了数据挖掘技术，以有效地搜索、分类和聚类大量的时间序列数据[8,23,24]。这些系统展示了检查时间序列数据的许多用途，从聚类和分类[8,23]到异常检测[10,16] 到索引时间序列[9,12,24]。然而，很少有例子详细说明能够实时收集和存储大量时间序列数据的系统。Gorilla的设计侧重于对生产系统进行可靠的实时监控，与其他TSDB相比非常突出。Gorilla占据了一个有趣的设计空间，在面对优先于任何旧数据可用性的故障时，可用于读取和写入。
由于 Gorilla 从一开始就被设计为将所有数据存储在内存中，因此它的内存结构也不同于现有TSDB。但是，如果将Gorilla视为另一个磁盘上TSDB之前的时间序列数据内存存储的中间存储，那么Gorilla 可以用作任何 TSDB 的直写缓存(相对简单的修改)。Gorilla对摄取速度和水平扩展的关注与现有解决方案相似。
3.1 OpenTSDBOpenTSDB基于HBase[28]，非常接近我们用于长期数据的ODS HBase存储层。这两个系统依赖于相似的表结构，并且在优化和水平可伸缩性方面得出了相似的结论[26,28]。然而，我们发现支持构建高级监控工具所需的查询量需要比基于磁盘的存储所能支持的更快的查询。
与OpenTSDB不同，ODS HBase层确实为较旧的数据进行时间累积聚合以节省空间。这导致较旧的存档数据与ODS中较新的数据相比具有较低的时间粒度，而OpenTSDB将永远保留全分辨率数据。我们发现，更便宜的长时间查询和空间节省是值得的精度损失。</description></item><item><title>保护您的服务网格：十三项清单</title><link>https://icorer.com/icorer_blog/posts/13-item_checklist_for_securing_your_service_mesh/</link><pubDate>Thu, 17 Feb 2022 14:57:18 +0800</pubDate><guid>https://icorer.com/icorer_blog/posts/13-item_checklist_for_securing_your_service_mesh/</guid><description>世界各地的组织都在急于对其应用程序进行现代化改造，以便在云中 Kubernetes 编排的容器中运行。在此现代化过程中，这些公司必须计划保护其应用程序连接。当应用程序被重新平台化并重新构建为分布式微服务时，会出现新的连接模式，这些模式通常会促使构建一个或多个服务网格。
强大的服务网格可以处理南北连接（从边缘进入基于 Kubernetes 的应用程序）和东西连接（同一集群上的服务之间或不同集群之间）。但是，这些流量模式中的每一个都需要全面的安全性.
实现服务网格安全性的最佳方法是采用零信任模型，这意味着每个连接，无论其来源如何，都必须经过验证和保护。为了帮助您评估服务网格技术并实施零信任安全，我们提供了 13 个必备功能，以确保您的应用程序连接安全。这是清单：
传输层安全性（TLS 和 mTLS）提供端到端加密，以保护任何端点对之间的动态数据。它可能是最基本的组件，但令人惊讶的是，并非所有服务网格都完全支持双向 TLS。 内置 Web 应用程序防火墙 (WAF)可屏蔽入站流量以发现威胁并阻止攻击侵入您的周边。对于任何向 Internet 公开以接收传入用户和应用程序连接请求的边缘网关来说，这都是必不可少的。 数据丢失防护 (DLP)监控数据泄露或泄露，以防止数据丢失和数据泄露。如果您的应用程序以某种方式受到损害，您不希望数据泄露您的边界。 Kubernetes的机密管理集成，后者管理密码、安全令牌和加密密钥等敏感凭证。您会担心这些信息仍然被硬编码到应用程序中或以纯文本形式存储的频率。 证书管理从集中式平台控制和执行 SSL 证书以验证连接。证书轮换可能是一个痛苦的管理步骤，应该优雅地加以考虑。这应该可以扩展以支持外部权限，这意味着它将与您已经使用的企业身份和访问管理解决方案一起使用。 授权，例如使用开放策略代理 (OPA)，它将服务 API 策略定义为代码。授权是身份验证的另一面，一旦您验证了他们的身份，谁就可以访问哪些资源。 联合信任域可以安全地跨环境对用户和应用程序进行身份验证，从而在任何地方始终如一地扩展身份验证策略。如果没有这个，您将花费大量精力来尝试保持各种角色的更新和同步——并且可能会犯一些错误。 联合的基于角色的访问控制 (RBAC) 和委派向用户授予与其职责相符的权限，并且再次在任何地方始终如一地应用此权限。这些控制可以应用于管理服务网格的运营商的不同级别，也可以应用于构建在网格中运行的应用程序的开发人员。 多租户和隔离使服务网格中的用户和应用程序可以安全地共享资源。拥有 RBAC 后，您可以安全地定义谁可以接触什么，并为不同的角色有效地创建隔离的工作空间。Istio 的授权策略也可用于防止不需要的流量到达您的应用程序。 漏洞扫描和出版物发现、解决和警告系统中的任何弱点。安全性与其最薄弱的环节一样好，因此检查防御中的任何漏洞很重要。 多集群访问可观察性为整个系统的所有活动提供完整的日志聚合和可审计性。这对于事件后的实时监控和取证都很有用。对于分布式应用程序，有必要获得全局视图。许多人使用 Prometheus 和 Grafana 等开源工具来实现可观察性。 联邦信息处理标准 (FIP) 140-2意味着您的服务网格技术已经过验证，符合美国政府规定的特定严格安全标准。有许多政府法规和行业最佳实践，但 FIPS 是确定安全基准的一种常用方法。 集群中继的安全拉取模型在整个系统中安全地共享配置。这是非常微妙的，但是您要确保任何配置更改都在请求时分发到边缘，并且仅在请求时分发。 虽然严格来说不是服务网格的安全特性，但一个额外的考虑因素是企业支持的可用性和用于响应的定义服务级别协议 (SLA)。</description></item><item><title>使用区块链将零信任架构扩展到端点：最先进的审查</title><link>https://icorer.com/icorer_blog/posts/blockchain_with_zerotrust/</link><pubDate>Tue, 15 Feb 2022 23:50:18 +0800</pubDate><guid>https://icorer.com/icorer_blog/posts/blockchain_with_zerotrust/</guid><description>摘要为了防御当今无边界网络中的横向移动，零信任架构(ZTA)的采用势头越来越猛。有了全面的 ZTA 实施，对手不太可能从受损的端点开始通过网络传播。然而，已经经过身份验证和授权的受损端点会话可以被用来执行有限的(尽管是恶意的)活动，最终使端点成为 ZTA 的致命弱点。为了有效地检测此类攻击，已经开发了具有基于攻击场景的方法的分布式协同入侵检测系统。尽管如此，高级持续威胁(APTs)已经证明了它们绕过这种方法的能力，并且成功率很高。因此，对手可以不被发现地通过或潜在地改变检测记录机制，以实现隐蔽的存在。最近，区块链技术在网络安全领域展示了可靠的使用案例。在本文中，受基于 ZTA 和区块链的入侵检测和防御的融合的推动，我们研究了如何将 ZTA 扩展到端点。也就是说，我们对 ZTA 模型、以端点为重点的真实体系结构以及基于区块链的入侵检测系统进行了最先进的审查。我们讨论了区块链的不变性增强检测过程的潜力，并确定了开放的挑战以及潜在的解决方案和未来的方向。
一、介绍随着云计算的革命，大多数企业的资源和数据不再存储在内部。此外，最近的新冠肺炎疫情事件极大地改变了工作模式，因为大多数员工和企业不得不转向在家工作。在家工作(和远程工作)会给组织带来新的严重安全风险，因为许多“未经培训”的员工使用自己的设备连接到工作信息技术(IT)系统。云计算和远程工作是企业必须扩大其数字安全范围并适应当代趋势的例子。
在传统的基于外围的安全模型中，组织在外围的资源和资产被认为是良性的和可信的。边界通常由安全措施保护，如防火墙或入侵检测系统。这种模式在云计算和远程工作领域似乎不太有效，针对远程工作员工的几次网络攻击(例如[1-5])就表明了这一点。
信任是传统的基于边界的安全模型所依赖的基本原则。员工或合作者的设备和组织资产(即端点)通常在默认情况下是可信的，而不管其状况如何。如果攻击者能够控制这些端点中的任何一个，那么边界就会受到威胁，并且通过横向移动有可能实现对信息和数据的进一步访问。
防火墙、防病毒技术、入侵检测和防御系统(IDS/IPS)和网络应用防火墙(WAFs)，换句话说，大石墙和装甲前门，已经不足以保证现代 IT 和运营技术(OT)环境的安全[6]。基于外围的安全是多家公司采用的主要概念，尤其是当他们的数据驻留在内部数据中心时。建立在内部和外部差异基础上的传统防御模式正在过时[7]，而与此同时，威胁格局也在急剧演变[8]，最终导致基于外围的安全架构的衰落。
为了应对当今复杂的网络基础设施和当前不断发展的威胁形势，需要一种新的安全架构。ZTA 通过建立无边界的基于数字身份的边界脱颖而出，在这个边界中，数据处于安全架构的中心，破坏思维主导着威胁模型， 引领着访问控制环境、运营、托管环境、端点和互连基础架构。ZTA 提倡一种新的安全架构，默认情况下，任何设备、系统、用户或应用程序都不应该基于其在网络中的位置而受到固有的信任。相反，不管在什么地方，信任总是要赢得和验证的。然而，这并不一定意味着在ZTA 的情况下信任被消除，而是应该最小化，直到通过ZTA 信条和核心组成部分证明不是这样。
使用传统的基于边界的防御，如果坚定的攻击者能够在端点上建立经过身份验证和授权的立足点，他们仍然可以绕过 ZTA 安全健康检查。例如，操作系统内核中的潜在恶意软件可以篡改在 ZTA 环境中进行的安全检查。这最终导致绕过在 ZTA 实施的基本控制，这将允许攻击者除了横向移动之外，还执行一些以用户和设备为中心的恶意活动。因此，需要一种有效的入侵检测方法来解决端点的漏洞，这可以被视为 ZTAs 的致命弱点。
在本文中，我们旨在研究如何利用区块链的不变性增强入侵检测过程的潜力，将 ZTA 扩展到端点，以消除上述问题。为此，我们首先回顾零信任的核心原则、能力和要求。其次，我们对现有的现实世界零信任实现进行分类，并讨论它们的优缺点。第三，我们探索了区块链在开发和改进分布式协作入侵检测系统(DCIDSs)方面的潜力，该系统可以缓解ZTA 的致命弱点(即端点的脆弱性)。最后，我们讨论了开放的问题和挑战，并强调了ZTA和基于区块链的分布式入侵检测系统的潜在解决方案和研究方向。
据我们所知，这是第一个利用区块链技术成功将ZTA扩展到端点的工作。表1给出了本文中使用的主要缩写及其定义。
二、零信任（ZT）在本节中，我们简要介绍了“零信任”和 ZTA 的历史，并讨论了零信任的核心原则、核心能力、模型和现有方法，包括现实世界的实现。
2.1 零信任架构的历史2004 年的杰里科论坛提出了去周边化的想法(当时是激进的)[3]，随后发展成为更广泛的零信任概念。早在2010 年，J. Kindervag [15]就创造了“零信任”一词；然而，在此之前，网络安全领域就存在零信任概念。美国国防部和国防信息系统局(DISA)提出了一项名为“黑核”的安全战略，并于 2007 年发表[16]。Black core讨论了从基于外围的安全架构向强调保护单个交易的安全架构的过渡。
云和移动计算的广泛采用极大地促进了 ZTAs 的发展，例如，作为其中的一部分，基于身份的架构等方法慢慢获得了关注和更广泛的接受。谷歌以“BeyondCorp”的名义发布了一系列关于如何实现零信任架构的六个文档[17-22]。BeyondCorp项目倡导去边界化的概念，认为基于边界的安全控制已经不够，安全应该扩展到用户和设备。由于这个项目，谷歌放弃了传统的基于虚拟专用网络(VPNs)的远程工作方式，并设法提供了一个合理的保证，即所有公司用户都可以通过不安全和不受管理的网络访问谷歌的网络。
2.2 从传统的周边架构到ZTA作为一种理念，“零信任”假设对用户、设备、工作负载和网络流量的信任不应被隐含地授予[15]，其结果是所有实体都必须被明确地验证、认证、授权和持续监控。零信任的核心目标之一是，一旦对手成功危及用户的设备，甚至简单地窃取他们的凭据，就会严重抑制对手横向移动的能力。因此，需要相应地塑造和准备信息技术基础设施。
传统的基于外围的安全架构会创建多个信任区域[2]。并非所有区域都遵守相同的规则或相同的信任级别。事实上，如果相关组件没有明确允许，用户甚至可能无法进入下一个区域。这被称为纵深防御，正如史密斯[23]所讨论的，并在图1中描述，或者称为城堡和护城河方法[24]。请注意，在到达大型机之前，不同的区域(互联网、非军事区、可信和特权)受到各种基于外围的控制的保护，例如本地代理、虚拟专用网网关、多个防火墙和应用程序服务。在这个例子(即图1)中，大型机是一个核心银行系统，负责所有交易，因此它被完全隔离在一个特权区域中。
与传统的安全架构不同，零信任要求从内到外进行思考、构建和保护。基于谷歌[19] [20]、Jericho[3]和Kindervag[15] [25]的上述工作，有一个直接和重要的观察， 即在ZTA，一旦网络位置依赖性变得无关紧要，虚拟专用网技术就可以被消除。简而言之，虚拟专用网允许远程工作的用户(在图1中用“远程员工”表示)通过安全的加密通道连接到办公室(在图1中用“可信”表示)。但是，应该通过其他方式保护端点，因为虚拟专用网加密只处理“远程员工”和“可信”区域之间的隧道。当“远程员工”通过身份验证并成功建立隧道时，他/她会收到“可信”区域的远程网络中的一个 IP 地址。在该隧道上， 从“远程员工”到“可信”区域的流量被解封并路由，因此导致“官方”后门。此外，被称为“虚拟专用网网关”的单一入口点充当体系结构和网络的单一故障点或扼杀点。因此，如果我们开始认为网络位置无关紧要，同时应用一组适当的控制，那么如果没有进一步的依赖关系 (例如，具有传统协议的应用程序)，就可以消除虚拟专用网络。也就是说，身份验证和授权以及策略实施应该立即向网络边缘和端点靠拢。
为了反映上面的论点，我们绘制了图 2，显示了对 ZTA的引用。为了简化起见，在图中，我们只包括核心组件，例如，本地代理(LB)、远程员工、移动设备、不可信客户端和许多需要保护的服务。与基于边界的架构相比，如图 1 所示，没有区域，安全性是由内而外构建的。此外，既没有 VPN 网关，也没有防火墙来过滤网络流量， 最重要的是没有单一的入口网关。我们注意到；但是，控制平面上的策略执行点。这种 ZTA 参考不会像基于外围的架构那样产生任何瓶颈。</description></item><item><title>自主网络安全-保障未来颠覆性技术</title><link>https://icorer.com/icorer_blog/posts/autonomous_network_security_securing_future_disruptive_technologies/</link><pubDate>Fri, 28 Jan 2022 21:07:07 +0800</pubDate><guid>https://icorer.com/icorer_blog/posts/autonomous_network_security_securing_future_disruptive_technologies/</guid><description>From：2021 年 IEEE ⽹络安全与弹性国际会议 (CSR)
概述这篇论文讲述自主网络安全知识的系统化。诸如物联网、人工智能和自治系统等颠覆性技术正变得越来越普通，而且通常很少或者根本没有网络安全保护，这种缺乏安全性导致的网络攻击面不断扩大。自主计算计划旨在通过使复杂计算系统自我管理来解决管理复杂计算系统的复杂性。自主系统包含应对网络攻击的属性，例如新技术的自我保护和自我修复。有许多关于自主网络安全的研究项目，采用不同的方法和目标技术，其中许多具有破坏性。本文回顾了自主计算，分析了自主网络安全的研究，并提供研究知识的系统化，本文最后确定自主网络安全方面的差距，以供未来研究。
一、介绍随着恶意⾏为者变得善于发现和利⽤⽹络和计算机系统中的缺陷[1]，对计算机系统的攻击数量随着复杂程度和严重程度的增加⽽增加。新的颠覆性技术不断被引⼊并连接到企业⽹络和互联⽹，这些技术限制了有些甚⾄没有内置的⽹络安全。其中包括⽹络物理系统/物联⽹ (CPS/IoT)、⼈⼯智能(AI) 和⾃治系统等技术。计算系统通常会在事后添加⽹络安全，⽽不是从⼀开始就设计，尤其是新的颠覆性技术，尤其是匆忙推向市场的技术。
系统需要能够以⾃我管理的⽅式对攻击和固有的弱点做出反应，⽆论是单独还是与其他系统⼀起。将安全性本地嵌⼊到软件和硬件系统中将使它们能够对攻击做出反应，并单独保护和治愈⾃⼰，并且作为⼀个群体。从本质上讲，这是⽹络安全的⾃主⽅法。
伯纳尔等⼈[2]在2019 年确定了⽹络安全⽅⾯的⼀些研究挑战，并将“软件化和虚拟化CPS/IoT系统和移动⽹络中的⾃主安全编排和执⾏”列为第⼆名，仅次于“可互操作和可扩展的安全管理异构⽣态系统”。 他们指出，需要新的⾃主和上下⽂感知安全协调器，它们可以快速、动态地编排和实施适当的防御机制。
本⽂的⽬的是调查⾃主⽹络安全研究中的空⽩，并将这些知识系统化以探索未来的研究。该论⽂基于对⾃主⽹络安全⽂献的调查和⽅法分类。这提供了对未来研究可以帮助推动⾃主⽹络安全向前发展以保护未来颠覆性技术的洞察⼒。本⽂的其余部分结构如下：第⼆部分提供了⾃主计算(AC) 的背景以及如何将⽹络安全设想为⾃主系统的⼀部分。第三部分描述了⾃主⽹络安全的过去和当前研究。⼀些研究侧重于特定应⽤领域的⾃主⽹络安全，⽽其他研究则提供可⽤于⼀系列应⽤的⾃主⽹络安全框架。第四节提供了研究分类和分类知识库的系统化，第五节讨论了基于知识系统化的⽹络安全研究的差距，第六节提供了结论性意⻅。
二、背景Kephart 和 Chess 在 2003 年的⾃主愿景论⽂[3]中将⾃主计算定义为“根据管理员的⾼级⽬标，可以⾃我管理的计算系统”。使⽤“⾃主计算”⼀词是因为⾃主神经系统管理⾝体功能，调整这些功能以满⾜⾝体需求，并为更⾼层次的认知活动释放有意识的活动。⽹络安全也是如此，它应该在维护服务的同时，根据当前的⽹络情况⾃动 调整和调整系统资源。Kephart 和 Chess 概述了⾃主系统应 具备的四个要素：
⾃我配置 ⾃我修复 ⾃我优化 ⾃我保护，也称为Self CHOP 提出了⼀个参考架构来实现能够适应不断变化的环境的Self CHOP 属性（图 1）。
Monitor、Analyze、Plan、Execute 和 Knowledge 组件统称为 MAPEK 架构。⾃主计算系统并未被设想为单⼀的独⽴系统，⽽是交互的、⾃我管理的系统，它们共同⼯作以实现其⽬标（图2）。
Self CHOP属性在[3]中定义为：
⾃配置：系统通过动态调整其资源来⾃动配置和重新配置⾃⾝的能⼒ ⾃我修复：系统从常规和意外事件中⾃动检测、诊断和修复硬件和软件的能⼒ ⾃我优化：系统和⼦组件监控其部件以检测性能下降同时不断寻求⾃我改进的能⼒ ⾃我保护：系统针对故障和恶意对系统的攻击能力能够⾃动检测和防御 自主安全CHOP属性可以为系统提供⽹络安全⽀持，以保护⾃⾝并从⽹络攻击中恢复。Kephart 将⾃我保护属性描述为保护系统免受⾃我修复属性⽆法纠正的恶意攻击或级联故障。其他Self CHOP属性也⽀持⾃保护属性，⾃修复属性在系统受到攻击后通过更新和脱落受损组件来修复系统，⾃配置属性帮助系统在禁⽤受损⼦系统后重新配置⾃⾝，⾃优化属性可以帮助系统通过攻击运⾏，然后重新配置后重新优化。
⾃主⽹络安全建⽴在⾃主视觉和参考架构的基础上，以开发⾃我管理能⼒，利⽤Self CHOP特性检测⽹络攻击并从⽹络攻击中恢复 [4]。⾃主⽹络安全不仅使⽤⾃主计算的Self CHOP特性，⽽且还互连⾃主元素，以提供⾃主元素之间的信息通信和共享，以共同应对攻击并从攻击中恢复。
三、自主网络安全方法以下是对一系列领域实施自主网络安全的方法的调查，这些领域包括智能汽车、网络物理系统/物联网、工业控制系统、关键基础设施、自组织计算、高性能计算、云计算、企业计算和其他。一些方法集中在架构上，另一些集中在被保护的领域或底层技术上。以下描述了调查的不同方法。它们按照是否使用 MAPEK 参考体系结构、非MAPEK体系结构、实现特定的自主特性、是提供自主开发支持的框架还是自主安全开发工具来分组。
3.1 MAPEK方法3.1.1 认知和自主网络安全Maymir Ducharme等人[5]在2015年描述了使用上下文分析和自主元素的分层网络，该网络从分层结构中的不同抽象层次提供系统元素的不同视图。具有更高级视图的自治元素将具有企业任务级上下文。更高级别的自治元素将根据公司功能的关键程度对这些功能进行优先排序，以便在紧急情况或网络攻击时维持运营。与安全相关的元素，如防火墙，将在层次结构中较低的抽象级别表示。
3.1.2 零信任Eidle等在2017年提出利用autonomic网络安全实现网络零信任[6]。作者开发了一个网络安全测试平台，实现了基于观察、定向、决定、行动(OODA)模型的零信任网络的各个方面，该模型与 MAPEK 参考架构相似，平台观察网络用于监控和分析攻击特征的身份验证日志。他们集成了来自多个网络设备的威胁响应，以简化威胁的检测和缓解危害。
3.1.3 自主车辆网络Le Lann在 2018年描述了未来智能汽车网络如何具有自主组织和自愈特性[7]。车辆网络可以构成由一组车辆组成的系统系统。每辆车都将是一个自主元件，与附近的其他车辆相连。车辆将被动态地连接在一起，形成“队列”，它们像车队一样一起行进，并提供群体安全。车辆可以根据车辆需求动态添加和删除。出于安全目的，加入群组需要身份验证。
3.1.4 使用大数据的分布式计算中的自主入侵响应Vierira等人在2018年使用了自主计算和大数据分析的组合来检测和响应网络攻击[8]。作者为自主入侵响应系统提供了一个参考架构，并开发了一个概念验证实现。作者将其入侵响应参考体系结构建立在 MAPEK 参考体系结构的基础上，网络流量系统日志是通过监控 MAPEK子组件收集的。</description></item><item><title>系统调用级二进制兼容的Unikernel虚拟机</title><link>https://icorer.com/icorer_blog/posts/system_call_level_binary_compatible_unikernel_virtual_machine/</link><pubDate>Mon, 24 Jan 2022 19:00:18 +0800</pubDate><guid>https://icorer.com/icorer_blog/posts/system_call_level_binary_compatible_unikernel_virtual_machine/</guid><description>一、背景Unikernel 是最小的单一用途虚拟机，目前在研究领域非常受欢迎，但是目前想把已有的应用程序移植到当前的unikernel环境是很困难的。HermiTux是第一个提供与Linux应用程序的系统调用级二进制兼容的unikernel，它由一个管理程序和一个模拟负载及运行时Linux ABI的轻量级内核层组成。HermiTux将应用程序开发人员从移植软件的负担中解脱出来，同时通过硬件辅助虚拟化隔离、快速启动时间和低磁盘/内存占⽤、安全性等提供单核优势。通过二进制分析重写技术及共享库替换，可以快速实现系统调用和内核模块化。
论文中展示了HermiTux的独立架构特色，在x86-64和ARM aarch64 ISA架构上展示了一个原型，针对各种云以及边缘/嵌入式部署，也展示了HermiTux对⼀系列原⽣C/C++/Fortran/Python Linux 应⽤程序的兼容性。HermiTux与其他unikernel相比，也提供了相似程度的轻量级，并且在许多情况下与Linux性能相似，它在内存和计算密集型场景下性能开销平均损失3%，其I/O性能是可以接受的。
二、HermiTux对于Linux程序兼容性的思路Unikernels在学术领域变得很流行，它以虚拟化LibOS模型为基础，这种模型也带来了很多好处，主要包括：提高安全性、性能改进、隔离性提升、降低成本等。这样的优势也增加了很多应用场景：云和边缘部署的微服务/基于Saas和Faas的软件、服务器应用程序、NFV、IOT、HPC等。尽管unikernel被视为容器领域具有吸引力的替代品，但unikernels仍然在行业中很难获得显著的牵引力，并且它们的采用率相当缓慢，主要原因是将遗留/现有的应用程序移植到unikernel模型很困难，有时候甚至是不可能的。
在大型程序中，移植复杂的代码库很困难，这是由于诸如不兼容/缺少库/函数、复杂的构建过程、缺乏开发工具（调试器/分析器）、不受支持的语言等因素存在。移植到unikernel环境，也需要程序员具备这方面的专业知识，巨大的移植负担是阻碍广泛采用unikernels最大的障碍之一。
HermiTux提出了一个新型的unikernel模型，他为常规Linux应用程序提供二进制兼容性，同时保留了unikernel的优势，它允许开发工作集中在unikernel这层。HermiTux原型是HermitCore unikernel的扩展，它能够运行原生的Linux可执行文件作为unikernel。通过提供这种基础设施，HermiTux将应用程序员的移植工作转变为unikernel层开发人员的支持工作，在这个模型下不仅可以让原生Linux应用程序透明地获得unikernel的好处，而且还可以运行以前不可移植的应用程序。使用HermiTux将遗留应用程序作为unikernel移植和运行是不存在的，HermiTux支持静态和动态链接的可执行文件、兼容多种语言（C/C++/Fortran/Python等）、编译器（GCC和LLVM）、全面优化（-O3）和剥离/混淆的二进制文件。它支持多线程和对称多处理器（SMP）、检查点/重启和迁移。
大多数现有的unikernel不提供任何类型的二进制兼容性，一些系统通过在C库级别进行接口适配来提供二进制兼容性，其作用类似于动态链接库。这可以防止它们通过系统调用来支持何种需要操作系统服务的应用程序，而无需通过C库。为了保障最大化的兼容性，HermiTux没有采用通用做法，在系统调用级别实现了所有应用程序和编译库使用的标准化接口。
三、HermiTux的挑战HermiTux应对的第一个挑战是如何提供系统调用级别的二进制兼容性？，因此HermiTux根据Linux应用程序二进制接口ABI设置执行环境并在运行时模拟OS接口。基于自定义管理程序的ELF加载程序用于在单个空间虚拟机中与最小内核一起运行Linux二进制文件。程序运行的系统调用被重定向到unikernel提供的实现。
HermiTux应对的第二个挑战是如何在**提供二进制兼容性的同时保持unikernel的好处？**有些是自然具备的好处（小磁盘/内存占用、虚拟化强制隔离），而另一些（快速的系统调用、内核模块化）在假设无法访问源代码时会带来技术挑战。为了实现这些好处，HermiTux对于静态可执行文件使用了二进制重写与分析技术，并在运行时用一个可识别的unikernel的C库替代动态链接库的可执行文件。最后HermiTux针对低磁盘/内存占用和攻击面进行了优化，与现有的unikernel一样低或更低。
由于unikernel应用案例广泛，HermiTux当前目的是兼容服务器和嵌入式虚拟化场景，因此主要支持Intel x86-64和 ARM aarch64 (ARM64) 指令集架构 (ISA) 开发。HermiTux的设计基本原则是独立于架构，但是它的实现以及我们用来恢复unikernel的二进制重写/分析技术是ISA特定的。
总体来说，HermiTux做了以下出色工作：
一种新的unikernel模型，旨在执行本机Linux可执行程序，同时保持经典的unikernel优势。 提供可以在x86-64 和 aarch64 架构上的两个原型实现。 四、关键概念阐述4.1 Unikernelsunikernel是一个应用程序，它使用必要的库和一个精简OS层静态编译成一个二进制文件，能够作为虚拟机在管理程序上执行。Unikernel符合以下条件：
单一目的：一个unikernel只包含一个应用程序 单一地址空间：由于单一目的原则，所以unikernel不需要内存保护，因此应用程序和内核共享一个地址空间，所有代码都以最高权限级别执行。 这样的模型提供了显著的好处，在安全性方面提供了unikernel之间的强隔离，虚拟机管理程序让它成为云部署的良好候选者。此外unikernel仅包含运行给定应用程序所需的必要软件。结合非常小的内核尺寸，和常规VM相比，这导致应用程序攻击面显著减少。一些unikernel也是用提供内存安全保障的语言编写的。关于性能方面，unikernel系统调用很快，因为它们是常见的函数调用，特权级别之间没有代价昂贵的用户态与内核态切换。上下文切换也很快，因为没有页表切换或TLB刷新。除了由于小内核导致代码库减少之外，unikernel OS层通常是模块化的，可以将它们配置为仅包含给定应用程序的必要功能。
所有这些好处让unikernels的应用程序域非常丰富。他们非常适合运行大多数需要高度隔离的云应用程序和需要高性能、低操作系统开销的计算密集型作业的数据中心。unikernel减少的资源使用使它们特别适合嵌入式虚拟化，随着边缘计算和物联网等范式的出现，这个领域的重要性日益增加。由于unikernels的应用领域包括服务器和嵌入式机器，因此论文主要针对intel x86-64和 aarch64架构进行模型构建。
4.2将现有应用程序移植到Unikernel移植现有软件作为unikernel运行是很困难的，特别在某些情况下无法移植程序到unikernel环境，因为所有的程序都需要重新编译与链接。一个给定的unikernel支持一组有限的内核特性和软件库，如果不支持应用程序所需的函数、库或者特定版本的库，则该程序需要进行调整。在许多情况下，缺少函数/库意味着应用程序根本无法移植，此外unikernel使用复杂的构建基础架构，将一些遗留的应用程序（大型的Makefile、autotools、cmake）移植到unikernel工具链会很麻烦，更改编译器或者构建选项也是如此。
在如此大的移植成本上，所以unikernel发展缓慢是有原因的，一种解决方案是让unikernel为常规可执行文件提供二进制兼容性，同时仍保持经典 unikernel 的优势，例如⼩代码库/占⽤空间、快速启动时间、模块化等。这种新模型允许 unikernel 开发⼈员致⼒于推⼴unikernel 层以⽀持最⼤应⽤程序的数量，并减轻应⽤程序开 发⼈员的任何移植⼯作。这种⽅法还应该⽀持调试器等开发⼯具。在这种情况下，HermiTux 允许将 Linux ⼆进制⽂件作为unikernel 运⾏，同时保持上述优势。
4.3 轻量级虚拟化设计空间轻量级虚拟化设计空间包含unikernel、面向安全的LibOS、例如Graphene，以及带有软件和硬件强化技术的容器。HermiTux不需要应用程序移植工作，并且和其他二进制兼容的系统方案不同，不同点主要包括：
作为unikernel HermiTux运行硬件强制（扩展页表）虚拟机，这是一种从根本上比软件强制隔离（容器/软件LibOS）更强的隔离机制。当前在VM中运行容器以确保安全的趋势（clear containers）加强容器隔离的努力（gVisor）都表明了这一点，这通常用作支持unikernel与容器的安全依据。 HermiTux使更广泛的应用程序能够透明地无需任何移植工作即可获得unikernel的好处，无需修改代码以及维护单独分支的潜在复杂性。鉴于unikernel提供的安全性和减少占用空间的特性，这在当今的计算机系统环境中非常有价值，软件和硬件漏洞经常成为新闻，并且数据中心架构师正在寻求增加整合和减少资源/能源消耗的方法。二进制兼容允许HermiTux成为专有软件（其源代码不可用）作为unikernel运行的唯一方法。最后，HermiTux允许软件获得VM的传统优势，例如检查点/重启/迁移，而无需大量磁盘/内存占用的相关开销。 4.4 系统调用级二进制兼容两个现有的unikernel已经生成和应用程序的二进制兼容，OSv和Lupin Linux。需要注意的是，两者都提供二进制兼容性标准C库（libc）级别，unikernel包含一个动态加载程序，它在运行时捕获对libc函数的调用，例如printf、fopen并将它重定向到内核。
这种接口方法意味着假设所有系统调用都是通过libc进行的，当考虑到各种各样的现代应用程序二进制文件时，这并不成立。我们分析了整个Debian10 x86-64存储库 (主要，贡献 和 ⾮免费） 并统计了553个ELF可执⾏⽂件，包括⾄少⼀次调⽤系统调⽤指令：这些代表不通过libc 执⾏系统调⽤程序，因此 libc 级别的⼆进制兼容unikernel 不⽀持这些程序。这种有限的libc级兼容性组织了这些系统运行相对较大范围的应用程序，这些应用程序将从座位unikernel的执行中受益匪浅。举几个例子，大量的云服务是用Go语言编写的，Go是一种无须标准C库即可执行大多数系统调用的语言。此外，由于在系统调用层面缺乏兼容性，OSv不支持最流行的HPC共享内存编程框架OpenMP，最后libc接口排除了对静态二进制文件的支持。
HermiTux代表了一种尝试，通过增加一个更加标准和一致使用的接口（系统调用级别）上进行接口来进一步推动unikernel的兼容性程度。</description></item><item><title>阿里云FAASNET无服务器容器方案</title><link>https://icorer.com/icorer_blog/posts/alibaba_cloud_faasnet_serverless_container_solution/</link><pubDate>Tue, 18 Jan 2022 21:24:16 +0800</pubDate><guid>https://icorer.com/icorer_blog/posts/alibaba_cloud_faasnet_serverless_container_solution/</guid><description>背景这篇论文中采用容器化方案来实施ServerLess的落地过程，论文内部一方面基于大量的数据统计、一方面提出来FT树结构，用来优化容器冷启动。FAASNET是第一个为FaaS优化的容器运行时提供的端到端综合解决方案，FAASNET使用轻量级、分散和自适应的函数树来避免主要平台的瓶颈。
大会地址：https://www.usenix.org/conference/atc21/presentation/wang-ao
开源地址：https://github.com/mason-leap-lab/FaaSNet
一、网络流量的峰谷比 就如上图所示，不同的应用场景下，流量的高峰和低峰的请求比例是不一样的，比如游戏、IOT场景下流量的峰谷比高于22，这种峰谷比也表明了ServerLess场景的优势。
二、容器的冷启动情况冷启动的延迟对于Faas提供商是致命的，阿里巴巴首先对于冷启动的分布情况作了调研：
对于北京地区，大约57%的镜像拉取时间超过45秒 对于上海地区，超过86%的镜像拉取时间至少需要80秒 显示超过50%和60%的函数调用请求花费至少80%和72%的整体函数启动时间来拉取容器镜像，这表明镜像拉取时间成为了大多数功能的冷启动成本。 冷启动的成本，还需要结合冷启动的间隔时间和功能持续时间来综合评价，在两个地区内部，大约49%的功能冷启动的到达时间小于1秒。
三、FAASNET技术内幕 在图3(d)中可以看出北京地区的80%函数执行时间超过1秒，上海地区80%的函数执行时间小于32.5秒，90th百分位数为36.6秒，99th百分位数为45.6秒。这种分布说明冷启动优化是必要的。
优化容器配置的性能将为降低基于容器的云功能的冷启动成本带来巨大的好处。
2.1 设计概述FAASNET将跨虚拟机的容器配置分散化和并行化，引入了名为函数树（FT）的抽象，以实现高效的容器配置规模。FAASNET将FT管理器组件和一个工作者组件整合进入FAAS调度器和虚拟机代理中，以协调FT管理，阿里的Faas平台主要包含以下几个组成部分，工作的主体组成包括：
网关：租户身份管理认证，将函数请求转发给FAAS调度器，将常规的容器镜像转换为I/O高效数据结构， 一个调度器负责为函数调用请求提供服务，将FAASNET FT管理器集成到调度器来管理函数数、简称FT，通过FT的增删API进行管理。一个FT是一个二进制的树状覆盖，它连接多个虚拟机，形成一个快速和可扩展的容器供应网络。每个虚拟机运行一个FAAS代理，负责虚拟机本地的功能管理。将一个FAASNET工作者集成到VM代理中，用于容器的供应任务。 在函数调用的路径上，如果没有足够的虚拟机、或者所有的虚拟机都很忙的情况下，调度器首先与虚拟机管理器进行通信，从空闲的虚拟机池中扩展出活动的虚拟机池。然后调度器查询其本地的FT元数据，并向FT的FAASNET工作者发起RPC请求，从而启动容器供应流程。容器运行时供应过程实际上是分散的， 并在FT尚未有容器运行的本地供应的虚拟机进行准备工作。调度器在关键路径之外，而FAASNET工作层根据需求获取函数容器层，并从分配的对等虚拟机中并行地创建容器运行时。 在函数部署路径上，网关将函数的常规容器镜像转换为I/O的有效格式，从面向租户的容器注册表中提取常规镜像，逐块压缩镜像层，创建一个包含格式相关信息的元数据文件（镜像清单），并将转换后的层及其清单分别写入阿里云内部的容器注册表和元数据存储。 2.2 FT功能树论文中针对重点强调在设计FT时做了以下选择：
FT是和函数进行绑定的，FAASNET以函数为粒度来管理FT。 FT具备解耦的数据面和控制面，FT的每个虚拟机工作者都具有等同的、简单的容器供应（数据平面）的角色，而全局树管理（控制平面）则交给调度器。 FAASNET采用平衡的二叉树结构，可以动态的适应工作负载。 这些选择结合阿里云，可以达到以下目标：
最大限度的减少容器镜像和层数据下载的I/O负载。 消除中央根节点的树状管理瓶颈和数据播种瓶颈、这里阿里内部镜像采用P2P分发，播种友好。 适应虚拟机的动态加入和离开。 以函数的粒度管理树， FAASNET为每一个至少被调用过一次但未回收的函数管理一个单独、唯一的树。图5说明一个横跨5个虚拟机的三级FT拓扑结构。函数容器镜像从书的根部虚拟机往下流，直到达到叶子节点。
平衡的二叉树，FAASNET的核心是平衡的二进制树，在二进制树中，除了根节点和叶子节点，每个树节点（宿主虚拟机）有一条传入边和两条传出边。这种设计可以有效限制每个虚拟机的并发下载操作的数量，以避免网络争用。一个有N个节点的平衡二叉树的高度为log(N)，这种关系也限制了函数镜像和层数据从顶部到底部的最多跳跃次数。树的高度会影响数据传播的效率，并且二叉树的结构可以动态变化，以适应工作负载的动态化。FAASNET把每个FT组织成一个平衡的二叉树，FT管理程序调用两个API：增加和删除，以动态地增加或缩小一个FT。
插入，FT的第一个节点会被当做根节点插入，FT管理器通过BFS（广度优先搜索）跟踪每个树节点的子节点数量，并将所有拥有0或1个子节点的节点存储在一个队列中。要插入一个新节点，FT管理器会从队列中挑选第一个节点作为新节点的父节点。
删除，调度器可能会回收闲置了一段时间的虚拟机（阿里云配置为15分钟），因此FAAS虚拟机的寿命是有限的。为了使用这种虚拟机的回收，FT管理器调用删除来回收虚拟机。删除操作也会在需要的时候重新平衡FT的结构。与二进制搜索树（如AVL、红黑树）不同，FT的节点没有可比较的键值（及其相关值）。因此，FT树的平衡算法只有当任何节点的左右子树的高度差大于1就会触发平衡操作。
2.3 FT与FAAS整合论文中的FT整合是在阿里云的FAAS环境中，主要整合了FAAS平台的调度器和虚拟机代理。阿里把FAASNET的FT管理器集成到阿里云的FAAS调度器中，并将FAASNET的VM工作者集成到阿里云的FASS-VM代理中用于调度管理FT的虚拟机。
通过FT管理者，调度器在每个虚拟机代理上启动一个FAASNET工作者，工作者负责：
为调度员的命令提供服务，执行镜像下载和容器供应的任务 管理虚拟机上的函数容器。 FT元数据管理，调度器维护一个内存映射表，记录&amp;lt;functionID,FT&amp;gt;键值对，他将一个函数ID映射到其相关的FT数据结构。一个FT数据结构管理着一组代表函数和虚拟机的内存对象，以跟踪虚拟机的地址：端口信息。调度器是分片的，是高度可用的。每个调度器分片会定期将内存中的元数据状态与运行etcd的分布式元数据服务器同步。
函数在虚拟机上的放置，为了提高效率，FAASNET允许一个虚拟机容纳属于同一个用户的多个函数。只要虚拟机有足够的内存来承载函数，一个虚拟机可能参与到多个重叠的FT的拓扑结构中。
图8显示了一个可能的FT布局的例子，为了避免网络瓶颈，FAASNET限制了一台虚拟机可以放置的函数数量，目前设置是20个。
容器供应协议，FAASNET设计了一个协议来协调调度器和容器之间的RPC通信。
调度器和FAASNET的虚拟工人，并促进容器的供应。在一个调用请求中，如果调度器发现没有足够的活动虚拟机为请求提供服务，或者当前所有虚拟机都忙于为请求提供服务，调度员会从空闲的虚拟机池中保留一个或多个新的虚拟机，然后进入容器供应流程。
当调度器将函数元数据发送给VM，VM一旦收到信息会执行两个任务。从元数据存储库加载并检查清单，获取镜像层的URL，并把URL信息持久化到VM的本地存储中。VM回复调度器表明自己已经准备好开始为请求的函数创建容器运行时，调度器收到回复后向VM发送一个创建容器的RPC请求，VM处理清单配置，并向调度器发送一个RPC表明容器已经成功创建。
FT容错，调度器定期ping虚拟机，可以快速检测虚拟机故障。如果一个虚拟机发生故障，调度器会通知FT管理器执行树平衡操作以修复FT拓扑结构。
2.4 FT设计讨论FAASNET将元数据繁重的管理任务卸载到现有的FAAS调度器上，因此每个单独节点都扮演着从其父级对等获取数据的相同角色。FT的根节点没有父级对等物，而是从注册表中获取数据。FAASNET的FT设计可以完全消除到注册中心的I/O流量，只要一个FT至少有一个活跃的虚拟机存储所请求的容器。早些时候，我们的工作负载分析显示，一个典型的FAAS应用的吞吐量将始终高于0RPS，在实践中请求突发更有可能讲一个FT规模从1到N，而不是从0到N。
另一种设计是更细粒度的层（blobs）来管理拓扑关系。在这种方法中，每个单独的层形成一个逻辑树层，属于一个函数的容器镜像的层最终可能驻留在不同的虚拟机上。注意FAASNET的FT是层树模型的一个特例。
图10中显示了一个例子，在这个例子中，一个虚拟机中存储着不同函数容器镜像的层文件，因此当许多下游的虚拟机同事从这个虚拟机获取层时，可能会出现网络瓶颈。这是因为许多重叠的层树形成了一个完全连接的、端对端的网络拓扑结构。如果虚拟机用高带宽的网络连接，全对全的拓扑结构可能会有很好的规模。然而如果每个虚拟机都收到了资源限制，全对全的拓扑结构很容易造成网络瓶颈，阿里云内部使用的是2核CPU、4G内存、1Gbps网络的小型VM。
现有的容器分配技术依靠强大的根节点来完成一系列任务，包括数据播种、元数据管理、P2P拓扑结构管理。将这些框架移植到FAAS平台上，需要额外的、专用的、分片的根节点，这将给运营商增加不必要的成本。另一方面，FAASNET的FT设计使每个虚拟机工作者的逻辑保持简单，同时所有的调度逻辑卸载到现有的调度器。这种设计自然消除了网络I/O瓶颈和根节点的瓶颈。Kraken采用了基于层的拓扑结构，具有强大根节点。
2.5 优化I/O高效的数据格式，常规的docker pull 和 docker start是低效和耗时的，因为整个容器镜像和所有层的数据都必须从远程容器注册中心下载，然后才能启动容器。为了解决这个问题，阿里云内部设计了一个新的基于块的镜像获取机制，这种机制使用了一种I/O高效的压缩数据文件格式。原始数据被分割成固定大小的块，并分别进行压缩。一个偏离表被用来记录压缩文件中每个压缩块的偏移量。
FAASNET使用相同的数据格式来管理和配置代码包。一个代码包被压缩成一个二进制文件，它被虚拟机代码提取并最终安装在一个函数容器内。FAASNET分配代码包的方式与分配容器镜像的方式相同。
按需I/O，对于不需要在启动时一次性读取所有镜像层的应用程序，基于镜像块的获取方式提供了一个懒惰的按需方式从远程存储获取细粒度的镜像层数据。一个FAASNET的VM工作者从元数据存储中下载镜像的清单文件，并在本地进行镜像加载以加载.tar镜像清单，然后它计算第一个和最后一个压缩块的索引，然后查询偏移表以找到偏移信息。最后，它读取压缩块并解压，知道读取的数据量与要求的长度一致。由于底层（远程）块存储设备的读取必须是块边界对齐，应用程序可能会读取和解压比要求的更多的数据，造成读取放大。然而，在实践中，解压算法实现的数据吞吐量比块存储或网络的数据吞吐量高的多。在我们的使用场景中，用额外的CPU开销换取降低I/O成本是有益的。
RPC和数据流，FAASNET内部建立了一个用户态、零拷贝的RPC库。这种方法利用非阻塞的TCP sendmsg和recvmsg来传输一个 struct iovec 不连续的缓冲区。RPC库把RPC头直接添加到缓冲区，以便在用户空间实现高效、零拷贝的序列化。RPC库对请求进行标记、以实现请求流水线和失序接收，类似HTTP2的多路复用。当FAASNET工作者受到一个完整的数据块时，工作者会立即将该数据块传输给下游的节点。
三、FAASNET评测3.1 实验方法使用中等规模500个虚拟机池和一个大规模的1000个虚拟机池，所有的虚拟机均使用2核CPU、4GB内存、1Gbps网络的实例类型，维护一个免费的虚拟机池，FAASNET可以保留虚拟机实例来启动云函数。这样容器配置的延迟就不包括冷启动虚拟机实例的时间，FAASNET使用512KB的块大小，用于按需取用。
系统比较，FAASNET和一下三种配置进行比较。
Kraken，Uber的基于P2P的注册系统。 baseline，阿里巴巴云函数计算目前的生产设置，使用docker pull 从集中的容器中心下载镜像。 on-demand，一个基于baseline的优化系统，但按需获取容器层数据。 DADI+P2P，阿里巴巴的DADI启动了P2P，这种方法使用一个资源受限的虚拟机作为根节点来管理P2P拓扑结构。 目的，回答以下问题：</description></item><item><title>⽤于区块链可扩展性的⾼效能 FPGA-Redis 混合 NoSQL 缓存系统</title><link>https://icorer.com/icorer_blog/posts/blockchain_fpga_redis_nosql/</link><pubDate>Tue, 25 May 2021 22:35:12 +0800</pubDate><guid>https://icorer.com/icorer_blog/posts/blockchain_fpga_redis_nosql/</guid><description>一、FPGA-Redis介绍鼓舞人心的区块链技术在加密货币以外的领域取得了很多采用和成功领域落地，因为它的好处已经被探索和成功测试。可扩展性是区块链的最大挑战之一，许多设备（轻量级节点）尤其是物联网依赖于完整的区块链服务器，因此需要减少服务器上的工作负载以获得高性能。这篇论文提出了一种高性能、高效的混合（多级）和分布式NoSQL缓存系统，用于提高区块链应用程序的可扩展（吞吐量）。我们研究了区块链中的性能瓶颈，并设计了一种高效的千兆以太网FPGA NoSQL缓存架构，该架构通过Hiredis C客户端与Redis数据库协同工作。Curl和Jansson用于连接区块链。我们为特定于区块链的高效缓存设计了一个定制的SHA-256核心。我们的结果显示，当FPGA上发生缓存命中时，性能提高了103倍。所提出的FPGA-Redis系统获得了高达4.09倍的改进，还实现了较小的FPGA面积利用率和较低的功耗。
二、概述区块链技术激励了许多人，帮助许多企业和政府改进系统，解决了信任、安全、速度、成本、效率和中心化等诸多瓶颈问题。英国政府办公室的报告确认区块链可以保护数据、降低成本并为记录提供透明度。区块链由中本聪于2008年首次提出并支持加密货币（比特币）和许多其他用于医疗保健、身份管理、网络安全等应用程序。Corda是R3的区块链（由200多家公司组成的联盟，主要是金融机构），用于增强商业交易和网络，R3一直在为企业使用和探索区块链。
尽管区块链很强大，但可扩展性（低吞吐量、高延迟、存储问题和读取性能差）是其巨大的挑战，但研究较少。与非区块链应用程序相比，区块链应用程序的吞吐量要低很多。比特币和以太坊支持每秒3-4和15-20笔交易（TPS），而Visa和PayPal分别支持1667和193TPS，另一方面，与非区块链服务器相比，区块链服务器的查询响应（读取性能）也很差。例如在我们处理约每秒96个响应的区块链系统中，查询延迟超过10毫秒。同样，Blockcypher 区块链服务器⽀持每秒3个请求。与⾮区块 链服务器相⽐，Google和YouTube分别处理每秒84,405个请求和每秒85,021次观看。糟糕的读取性能是由于区块链的结构和巨大的尺寸（比特币超过288GB）以及区块链数据存储在硬盘上的事实。与用于存储Redis等NoSQL缓存的RAM（快150,000倍）不同，硬盘具有较高的访问延迟。由于这种糟糕的读取性能，现有的区块链无法处理有效服务器所需的每秒大量客户端请求。许多轻量级节点（数以千计的物联网设备和简化验证（SPV）节点），仅依赖区块链服务器来获取区块链数据，因为其庞大的规模，它们无法存储完整的区块链。现在越来越多的轻量级客户端使用区块链并将更多的工作放在区块链服务器上，因此必须减少区块链服务器上的工作量以提升性能，从而更好地扩展区块量应用程序。
NoSQL缓存是提高和增强区块量服务器读取性能的一种有效方式。Redis、Hadoop和Memcached等NoSQL缓存如今已广泛用于大型Web数据中心，例如Yahoo、Twitter、Facebook、Youtube甚至Google，其中数百个分布式NoSQL部署缓存服务器是为了改善许多性能和可伸缩问题并节省成本。NoSQL缓存具有非常高的性能进行大规模水平扩展的优势，并且比使用更强大的CPU和内存（垂直扩展）更新现有服务器更经济。水平扩展是指使用廉价商品服务器的副本来获得更好的性能，而不是传统的垂直扩展，其中将更强大的资源添加到单个服务器使系统更加昂贵。仅苹果公司就使用了超过75000个NoSQL缓存（Cassandra）表格系列集群来存储超过10PB的数据。
分布式 NoSQL 缓存由于其⾼性能以及区块链请求（尤其是块头请求）的时间局部性，可以极⼤地提⾼区块链服务器响应的吞吐量和延迟性能。许多轻量级节点（如简化⽀付验证节点（特殊⽬的公司 )在添加新块的⼏个⼩时内。
尽管具有⾼性能，但软件 NoSQL 缓存在⾼性能时会消耗⾼功率和更多CPU 资源（在⽹络处理上）。因此，当 FPGA 发⽣缓存命中时，使⽤ FPGA来降低功耗和 CPU 资源消耗并提⾼性能。然⽽，FPGA 中的⼩尺⼨和有限的内存给可以缓存在 FPGA 上的数据量带来了缺陷和限制，从⽽通过增加 FPGA 的未命中率来影响系统性能。
本⽂研究了区块链中的性能瓶颈，并提出了⼀种⾼效的⾼性能混合分布式NoSQL FPGA-Redis 缓存系统，以减少区块链服务器的⼯作负载并提⾼其性能。我们设计并实现了⼀个千兆以太⽹ FPGA ⽹络接⼝控制器 (NIC)，该控制器包含键值存储，⽤于有效地缓存 FPGA 上的区块链数据。Redis 软件缓存和 Redis 应⽤程序内置在 Redis 服务器 PC 中，它通过 FPGA 上实现的千兆总线主控直接内存地址 (BMD) PCI Express (PCIe) 端点连接到 NIC。Redis 应⽤程序使⽤Hiredis API（实现与Redis缓存对话的Redi 的C客⼾端）。整个缓存系统通过我们的服务器应⽤程序中内置的Curl和Jansson API 连接到全节点区块链服务器。
该系统改善了FPGA NoSQL缓存内存⼩的缺点，同时以更低的功耗提⾼了 软件缓存的性能。FPGA 和 Redis 协同⼯作。Redis 通过提供另⼀个缓存层来补充 FPGA 缓存的有限内存。当在 FPGA 上未找到请求的数据（发⽣缓存未命中）时，数据从 Redis（如果缓存）⽽不是存储在主内存中的主区块链中获取。由于 Redis ⽐主存更快，因此整个系统的性能得到了提⾼。反过来，FPGA 通过处理⽹络处理来降低Redis的⾼性能和CPU资源消耗。我们只在FPGA和Redis（包括缓存）上缓存频繁的请求（即块头、确认、块⾼度、时间跨度和 Merkle根），⽽在Redis上缓存不频繁和⼤数据请求（例如块请求）只要。此外，仅当FPGA上发⽣缓存未命中时才检查Redis 缓存。</description></item><item><title>TCP长连接在K8S环境下的负载均衡分析</title><link>https://icorer.com/icorer_blog/posts/cloudnative_k8s_tcp_upstream_balance/</link><pubDate>Fri, 25 Dec 2020 11:28:12 +0800</pubDate><guid>https://icorer.com/icorer_blog/posts/cloudnative_k8s_tcp_upstream_balance/</guid><description>K8S不支持长连接的负载均衡，所以负载可能不是很均衡。如果你在使用HTTP/2，gRPC, RSockets, AMQP 或者任何长连接场景，你需要考虑客户端负载均衡。
TL;DR: Kubernetes doesn&amp;rsquo;t load balance long-lived connections, and some Pods might receive more requests than others. If you&amp;rsquo;re using HTTP/2, gRPC, RSockets, AMQP or any other long-lived connection such as a database connection, you might want to consider client-side load balancing.
Kubernetes提供了两种方便的抽象来部署应用程序：Services 和 Deployments。 Deployments描述了在任何给定时间应运行哪种类型以及多少个应用程序副本的方法。每个应用程序都部署为Pod，并为其分配了IP地址；另一方面，Services类似于负载平衡器。它们旨在将流量分配给一组Pod。
将Services视为IP地址的集合通常很有用。每次您对Services提出请求时，都会从该列表中选择一个IP地址并将其用作目的地。 如果您有两个应用程序（例如前端和后端），则可以为每个应用程序使用Deployment和Service，然后将它们部署在集群中。 当前端应用发出请求时，不需要知道有多少Pod连接到后端服务；前端应用程序也不知道后端应用程序的各个IP地址。当它想要发出请求时，该请求将发送到IP地址不变的后端服务。 但是该服务的负载平衡策略是什么？
Kubernetes Services中的负载平衡Kubernetes Services不存在，没有进程监听服务的IP地址和端口。
您可以通过访问Kubernetes集群中的任何节点并执行netstat -ntlp来检查是否存在这种情况。
甚至在任何地方都找不到IP地址,Services的IP地址由控制器管理器中的控制平面分配，并存储在数据库etcd中。然后，另一个组件将使用相同的IP地址：kube-proxy。
Kube-proxy读取所有Services的IP地址列表，并在每个节点中写入一组iptables规则。这些规则的意思是：“如果看到此Services IP地址，则改写请求并选择Pod之一作为目的地”。Services IP地址仅用作占位符-这就是为什么没有进程监听IP地址或端口的原因。 iptables是否使用轮询？不，iptables主要用于防火墙，并且其目的不是进行负载平衡。但是，您可以制定一套聪明的规则，使iptables像负载均衡器一样工作。而这正是Kubernetes中发生的事情。
如果您有三个Pod，则kube-proxy编写以下规则：
选择Pod 1作为目的地，可能性为33％。 否则，移至下一条规则 选择Pod 2作为目的地，可能性为50％。 否则，请移至以下规则 选择Pod 3作为目的地（没有可能性） 复合概率是Pod 1，Pod 2和Pod 3都有三分之一的机会被选中（33％）。</description></item><item><title>微服务治理：APM-SkyWalking-PHP内核扩展源码分析</title><link>https://icorer.com/icorer_blog/posts/microservice_skywalking_php_kernel_source_analyze/</link><pubDate>Mon, 07 Sep 2020 14:42:13 +0800</pubDate><guid>https://icorer.com/icorer_blog/posts/microservice_skywalking_php_kernel_source_analyze/</guid><description>SkyWalking APM作为服务遥测的关键技术点，为了能够更好地运用这项技术，我们需要拥有把握这项技术的底层能力。目前公司在PHP领域存活不少业务系统，针对PHP领域的APM技术，我们首先从分析这款PHP内核扩展程序下手。
一. 总体架构PHP内核在php-fpm运行模式下是短生命周期，短生命周期的脚本运行如果直接连接SkyWalking的oap-server会造成大量的性能损耗，而且php也不擅长grpc通信，因此借助mesh架构思想为PHP-FPM进程池增加一个数据SideCar，主要的结构如下图所示： 从上图可以看出，PHP内核扩展程序拦截内核运行数据（主要是关键的外部IO调用）、数据被发送给SideCar，SideCar流转数据到SkyWalking-Server，数据流还可以被SkyWalking进行分析、从而通过WebHook流转报警时间到相关后续平台里。
二. PHP内核扩展源码分析针对目前开源社区的SkyWalking-PHP内核源码进行分析，源码的分析主要包括以下几部分：
工程结构分析 关键生命周期分析 关键运行函数Hook分析 2.1 工程结构分析SkyWalking PHP内核组件工程结构比较简单，主要是站在PHP内核基础上进行扩展设计与实现，主要包含的扩展文件有：
b64.h：base64编码函数的头文件、主要包含内存分配、base64字符表、b64_encode及b64_decode、b64_decode_ex的函数声明。 decode.c：base64序列化的函数具体实现。 encode.c：base64反序列化的函数具体实现。 components.h：针对skywalking协议中的component部分进行宏定义、这部分是apm协议的一部分，例如：tomcat、httpclient、dubbo、okhttp、grpc、jedis、更多查看附录1。 php_skywalking.h：关键的内核扩展声明部分，主要包括：APM协议宏定义、Redis指令类别、memcache指令类别、ContextCarrier上下文结构体、apm拦截所需的关键函数定义（具体见附录二），apm关键函数hook定义（具体见附录三），全局变量定义（具体见附录四）。 skywalking.c：具体内核扩展实现文件，里面包含了MI-MS、RI-RS、关键函数Hook等处理逻辑。 2.2 关键生命周期分析这块将针对内核扩展关键生命周期进行分析。
2.2.1 关键生命期函数Hook定义1static void (*ori_execute_ex)(zend_execute_data *execute_data); //PHP内核原始PHP层执行流程函数指针 2static void (*ori_execute_internal)(zend_execute_data *execute_data, zval *return_value);//PHP原始内核执行函数指针 3ZEND_API void sky_execute_ex(zend_execute_data *execute_data);//skywalking针对PHP层执行函数的替换指针 4ZEND_API void sky_execute_internal(zend_execute_data *execute_data, zval *return_value);//skywalking针对原始内核执行函数的替换指针 2.2.2 php.ini配置解析周期 1PHP_INI_BEGIN() 2#if SKY_DEBUG 3 STD_PHP_INI_BOOLEAN(&amp;#34;skywalking.enable&amp;#34;, &amp;#34;1&amp;#34;, PHP_INI_ALL, OnUpdateBool, enable, zend_skywalking_globals, skywalking_globals) //读取skywalking.enable配置项 4#else 5 STD_PHP_INI_BOOLEAN(&amp;#34;skywalking.enable&amp;#34;, &amp;#34;0&amp;#34;, PHP_INI_ALL, OnUpdateBool, enable, zend_skywalking_globals, skywalking_globals) //读取skywalking.enable配置项 6#endif 7 STD_PHP_INI_ENTRY(&amp;#34;skywalking.</description></item><item><title>微服务治理：服务遥测之APM-SkyWalking技术应用</title><link>https://icorer.com/icorer_blog/posts/microservice_governance_apm_application/</link><pubDate>Mon, 07 Sep 2020 13:33:12 +0800</pubDate><guid>https://icorer.com/icorer_blog/posts/microservice_governance_apm_application/</guid><description>一. 背景描述微服务应用过程中，如何构建微服务的可观测性，主要从以下三个方面进行考虑：
服务日志（log） 服务指标（metric） 服务链路（trace） 这三个服务监控领域有不同的技术栈进行支撑，但是如何快速构建一个基础的服务可观测能力？尽量减少业务的侵入性、尽量多的增加业界标准的观测指标，这里我就推荐APM技术体系，在APM技术领域中SkyWalking是一个优秀的解决方案。 二. 技术结构SkyWalking 在我当前公司的落地领域中，主要围绕PHP、Go两大技术领域，JAVA生态拥有SkyWalking默认友好支撑，针对PHP、Go这两种技术栈，主要包含的APM体系技术结构如下图所示： 从技术结构图可以看出，APM技术体系主要包括以下几部分：
技术结构最底层采用了apache SkyWalking开源项目作为方案支撑。 Go生态使用Go2sky客户端进行APM数据丰富与数据包发送。 PHP生态由于自身短生命期的特征，分为PHP内核APM扩展和数据中转SideCar两部分，PHP内核扩展通过函数Hook机制完成Redis、MySQL、PDO、grpc等关键网络IO的拦截，并无感构建APM数据包结构，在RS周期发送APM数据包到SideCar，SideCar负责流转PHP内核的APM监控数据包到APM-Server上。 三. 关键领域监控APM技术生态包含内容比较多，主要的使命就是对于服务应用进行运行态监控，这里主要阐述一下几方面的监控效果：
3.1 服务指标监控服务指标监控主要包括Apdex、平均响应时间、成功率、CPM、TP数据、也包括很多的服务EndPoint数据，主要用来阐述服务健康、性能、可靠性的指标数据。 3.2 服务调用链监控微服务场景下，调用关系复杂、服务调用关系层级深，所以APM构建了服务调用链监控体系，方面研发、架构对于自己服务的调用关系有较好的可视化效果，调用链也遵循OpenTracing协议，主要效果如下所示： 3.3 微服务内核Runtime监控服务监控除了需要对于服务自身的可靠性、服务之间的调用关系进行监控之外，还需要针对服务Runtime进行拦截分析，通常的实现方式有OAP编程、内核Runtime Hook方式，Runtime监控可以很好的监控服务不同EndPoint内部的关键不稳定点的性能情况，除了PDO、Redis、Mysql、GRPC等关键IO，也可以监控长时间的cpu计算等程序行为逻辑。 主要的效果图如下： 3.4 微服务拓扑关系监控针对微服务调用关系，除了可以使用全链路Trace这种表达形式，也可以通过更具有动感效果的拓扑关系图进行描述，在拓扑关系图中可以形象的显示服务的类别、服务的流量走向、服务的当前状态、服务调用间的频率等数据。相关的效果图如下所示: 三. 总结APM技术体系对于微服务治理工作有超强的观测领域能力的弥补，增强服务的可观测程度，是微服务治理的重要工作。</description></item><item><title>UtahFS: Encrypted File Storage - 加密文件存储</title><link>https://icorer.com/icorer_blog/posts/utahfs_encrypted_file_storage/</link><pubDate>Sun, 14 Jun 2020 10:17:18 +0800</pubDate><guid>https://icorer.com/icorer_blog/posts/utahfs_encrypted_file_storage/</guid><description>加密是最强大的技术之一，每个人每天都在不知不觉中使用它。传输层加密现在已经无处不在，因为它是创建可信赖的Internet的基本工具，它可以保护通过Internet发送到目标目的地的数据。磁盘加密技术可以无所不在地保护您的数据，因为它可以防止任何窃取您设备的人也能够看到您台式机上的内容或阅读您的电子邮件。
这项技术的下一个改进是端到端加密，它是指只有最终用户才能访问其数据的系统，而没有任何中间服务提供商。这类加密的一些最流行的例子是WhatsApp和Signal等聊天应用。端到端加密显著降低了用户数据被服务提供商恶意窃取或不当处理的可能性。这是因为即使服务提供商丢失了数据，也没有人拥有解密数据的密钥！
几个月前，我意识到我的计算机上有很多敏感文件（我的日记，如果你一定知道的话），我担心会丢失，但我不喜欢将它们放入Google Drive或Dropbox之类。尽管Google和Dropbox是绝对值得信赖的公司，但它们不提供加密功能，在这种情况下，我确实希望完全控制自己的数据。
环顾四周，我很难找到符合我所有要求的东西：
会同时加密和验证目录结构，这意味着文件名是隐藏的，其他人不可能移动或重命名文件。 查看/更改大文件的一部分不需要下载并解密整个文件。 是开源的，并且有一个文档化的协议。 所以我开始建立这样一个系统！最终我把它称为“ UtahFS”，其代码在此处提供。请注意，这个系统在Cloudflare的生产中没有使用：它是我在我们的研究团队工作时构建的概念。这篇博客文章的其余部分描述了我为什么要像以前那样构建它，但是如果您想跳过它，则代码仓库中有关于实际使用它的文档。
Storage Layer(存储层)存储系统的第一个也是最重要的部分是…存储。为此，我使用对象存储，因为它是在别人的硬盘上存储数据的最便宜和最可靠的方法之一。对象存储只不过是一个由云提供程序托管的键值数据库，通常被调整为存储大约几千字节大小的值。有许多具有不同定价方案的不同提供商，例如Amazon S3，Backblaze B2和Wasabi。它们全部都能够存储TB级的数据，并且许多还提供地理冗余。
Data Layer(数据层)对我来说很重要的一个要求是，在能够读取一部分文件之前，不必下载和解密整个文件。这一点很重要的一个地方是音频和视频文件，因为它能够快速开始播放。另一个例子是ZIP文件：许多文件浏览器都具有浏览压缩档案（例如ZIP文件）的能力，而无需将其解压缩。要启用此功能，浏览器需要能够读取存档文件的特定部分，仅解压缩该部分，然后移动到其他位置。
在内部，UtahFS从不存储大于配置大小（默认为32 KB）的对象。如果文件中的数据量超过该数据量，则该文件将分成多个对象，这些对象通过跳表连接。跳表是链接列表的稍微复杂一点的版本，它允许读者通过在每个块中存储指向比指向前一跳更远的其他指针来快速移动到随机位置。
当跳表中的块不再需要时，因为文件已被删除或截断，它们将被添加到特殊的“回收站”链接列表中。例如，当需要在其他位置使用块时，可以回收垃圾列表的元素，以创建新文件或将更多数据写入现有文件的末尾。这将最大限度地重用，意味着仅当垃圾箱列表为空时才需要创建新块。一些读者可能认为这是《计算机编程艺术：第一卷，2.2.3节》中描述的链接分配策略！ 使用链接分配的根本原因是，对于大多数操作而言，这是最有效的。 而且，这是一种分配内存的方法，该方法将与我们在接下来的三个部分中讨论的加密技术最兼容。
Encryption Layer(加密层)既然我们已经讨论了如何将文件分成块并通过跳表进行连接，我们就可以讨论如何实际保护数据。这有两个方面：
第一个是机密性，它对存储提供者隐藏每个块的内容。 只需使用AES-GCM加密每个块，并使用从用户密码中获得的密钥，即可实现这一点。
该方案虽然简单，但不提供前向保密或后向安全。前向保密意味着，如果用户的设备遭到破坏，攻击者将无法读取已删除的文件。后泄露安全性意味着一旦用户的设备不再泄露，攻击者将无法读取新文件。不幸的是，提供这两种保证之一意味着在用户的设备上存储加密密钥，这些密钥需要在设备之间同步，如果丢失，将使存档无法读取。
此方案也无法防止脱机密码破解，因为攻击者可以获取任何加密的块，并一直猜测密码，直到找到有效的块为止。通过使用Argon2（这使得猜测密码更为昂贵）和建议用户选择强密码，可以在一定程度上缓解这种情况。
我肯定会在将来改进加密方案，但认为上面列出的安全属性对于初始发行版来说太困难和脆弱。
Integrity Layer(完整性层)数据保护的第二个方面是完整性，它确保存储提供程序没有更改或删除任何内容。这是通过在用户数据上构建Merkle树来实现的。Merkle树在我们关于证书透明性的博客文章中得到了深入的描述。Merkle树的根哈希值与版本号相关联，该版本号随每次更改而递增，并且根哈希值和版本号均使用从用户密码派生的密钥进行身份验证。这些数据存储在两个位置：对象存储数据库中的一个特殊密钥下，以及用户设备上的一个文件中。
每当用户想从存储提供程序读取一块数据时，他们首先请求远程存储的根目录，并检查它是否与磁盘上的相同，或者版本号是否大于磁盘上的版本号。检查版本号可防止存储提供程序将存档还原为未检测到的以前（有效）状态。然后，可以根据最新的根散列验证读取的任何数据，该散列可防止任何其他类型的修改或删除。
在此处使用Merkle树的好处与“证书透明性”的好处相同：它使我们能够验证单个数据，而无需立即下载并验证所有内容。 另一个用于数据完整性的常用工具称为消息身份验证码（Message Authentication Code，简称MAC），虽然它既简单又有效，但它无法只进行部分验证。
我们使用Merkle树不能防止的一件事是分叉，在分叉中，存储提供商向不同的用户显示不同版本的存档。然而，检测fork需要用户之间的某种流言蜚语，这已经超出了最初实现的范围。
Hiding Access Patterns(隐藏访问模式)Oblivious RAM, or ORAM,是一种用于以随机方式对随机存取存储器进行读写的加密技术，它可以从存储器本身中隐藏执行了哪个操作（读或写）以及对该操作执行到了存储器的哪一部分！在我们的例子中，“内存”是我们的对象存储提供程序，这意味着我们要向他们隐藏我们正在访问的数据片段以及访问的原因。这对于防御流量分析攻击很有价值，在这种攻击中，对UtahFS这样的系统有详细了解的对手可以查看其发出的请求，并推断加密数据的内容。例如，他们可能会看到您定期上传数据，几乎从不下载，并推断您正在存储自动备份。
ORAM最简单的实现是始终读取整个内存空间，然后使用所有新值重写整个内存空间，只要您想读取或写入单个值。一个观察内存访问模式的对手将无法判断你真正想要的值，因为你总是触摸所有东西。然而，这将是极其低效的。
我们实际使用的结构称为Path ORAM，它稍微抽象了一点这个简单的方案，使其更有效。首先，它将内存块组织成二叉树，其次，它保留一个客户端表，该表将应用程序级指针映射到二叉树中的随机叶。诀窍是允许一个值存在于任何内存块中，该内存块位于指定叶和二叉树根之间的路径上。
现在，当我们要查找指针指向的值时，我们在表中查找它的指定叶，并读取根和该叶之间路径上的所有节点。我们正在寻找的价值应该在这条路上，所以我们已经拥有了我们需要的！在没有任何其他信息的情况下，对手看到的只是我们从树上读到一条随机路径。 从树中读取的内容看起来像是一条随机路径，最终包含了我们正在寻找的数据。
但是，我们仍然需要隐藏我们是在读还是在写，并重新随机分配一些内存，以确保此查询不会与将来的其他查询相关联。 所以为了重新随机化，我们将刚读取的指针分配给新叶子，然后将值从存储在其之前的块中移到新叶子和旧叶子的父块中。（在最坏的情况下，我们可以使用根块，因为根是所有内容的父对象。）一旦将值移动到适当的块中，并完成应用程序的使用/修改，我们将对提取的所有块重新加密并将其写回内存。这将把值放在根和它的新叶之间的路径中，同时只改变我们已经获取的内存块。 这个结构很好，因为我们只需要触摸分配给二叉树中单个随机路径的内存，这是相对于内存总大小的对数工作量。但即使我们一次又一次地读同一个值，我们每次都会从树上碰到完全随机的路径！但是，额外的内存查找仍然会导致性能损失，这就是为什么ORAM支持是可选的。
Wrapping Up(结束语)在这个项目上的工作对我来说是非常有益的，因为虽然系统的许多单独的层看起来很简单，但它们是许多改进的结果，并很快形成了一些复杂的东西。在这个项目上的工作对我来说是非常有益的，因为虽然系统的许多单独的层看起来很简单，但它们是许多改进的结果，并很快形成了一些复杂的东西。
原文链接：https://blog.cloudflare.com/utahfs/ 开源地址：https://github.com/cloudflare/utahfs</description></item><item><title>云原生架构定义：12因素应用、微服务、自服务、API协作、抗脆弱性</title><link>https://icorer.com/icorer_blog/posts/cloudnative_12_factors/</link><pubDate>Fri, 15 May 2020 14:17:18 +0800</pubDate><guid>https://icorer.com/icorer_blog/posts/cloudnative_12_factors/</guid><description>一. 12因素应用12因素应用是一系列云原生应用架构的模式集合，最初由Heroku提出。这些模式可以用来说明什么样的应用才是云原生应用。它们关注速度、安全、通过声明式配置扩展、可横向扩展的无状态/无共享进程以及部署环境的整体松耦合。如Cloud Foundry、Heroku和Amazon ElasticBeanstalk都对部署12因素应用进行了专门的优化。
在12因素的背景下，应用（或者叫app）指的是独立可部署单元。组织中经常把一些互相协作的可部署单元称作一个应用。
1.1 代码库每个可部署app在版本控制系统中都有一个独立的代码库，可以在不同的环境中部署多个实例。
1.2 依赖App应该使用适当的工具（如Maven、Bundler、NPM）来对依赖进行显式的声明，而不该在部署环境中隐式的实现依赖。
1.3 配置配置或其他随发布环境（如部署、staging、生产）而变更的部分应当作为操作系统级的环境变量注入。
1.4 后端服务后端服务，例如数据库、消息代理应视为附加资源，并在所有环境中同等看待。
1.5 编译、发布、运行构建一个可部署的app组件并将它与配置绑定，根据这个组件/配置的组合来启动一个或者多个进程，这两个阶段是严格分离的。
1.6 进程该app执行一个或者多个无状态进程（例如master/work），它们之间不需要共享任何东西。任何需要的状态都置于后端服务（例如cache、对象存储等）。
1.7 端口绑定该应用程序是独立的，并通过端口绑定（包括HTTP）导出任何/所有服务。
1.8 并发并发通常通过水平扩展应用程序进程来实现（尽管如果需要的话进程也可以通过内部管理的线程多路复用来实现）。
1.9 可任意处置性通过快速迅速启动和优雅的终止进程，可以最大程度上的实现鲁棒性。这些方面允许快速弹性缩放、部署更改和从崩溃中恢复。
1.10 开发/生产平等通过保持开发、staging和生产环境尽可能的相同来实现持续交付和部署。
1.11 日志不管理日志文件，将日志视为事件流，允许执行环境通过集中式服务收集、聚合、索引和分析事件。
1.12 管理进程行政或管理类任务（如数据库迁移），应该在与app长期运行的相同的环境中一次性完成。
这些特性很适合快速部署应用程序，因为它们不需要对将要部署的环境做任何假定。对环境假设能够允许底层云平台使用简单而一致的机制，轻松实现自动化，快速配置新环境，并部署应用。以这种方式，十二因素应用模式能够帮我们优化应用的部署速度。
这些特性也很好地适用于突发需求，或者低成本地“丢弃”应用程序。应用程序环境本身是100％一次性的，因为任何应用程序状态，无论是内存还是持久性，都被提取到后端服务。这允许应用程序以易于自动化的非常简单和弹性的方式进行伸缩。在大多数情况下，底层平台只需将现有环境复制到所需的数目并启动进程。缩容是通过暂停正在运行的进程和删除环境来完成，无需设法地实现备份或以其他方式保存这些环境的状态。就这样，12因素应用模式帮助我们实现规模优化。
最后，应用程序的可处理性使得底层平台能够非常快速地从故障事件中恢复。
此外，将日志作为事件流处理能够极大程度上的增强应用程序运行时底层行为的可见性。
强制环境之间的等同、配置机制的一致性和后端服务管理使云平台能够为应用程序运行时架构的各个方面提供丰富的可见性。以这种方式，十二因素应用模式能够优化安全性。
二. 微服务微服务将单体业务系统分解为多个“仅做好一件事”的可独立部署的服务。这件事通常代表某项业务能力，或者最小可提供业务价值的“原子“服务单元。
微服务架构通过以下几种方式为速度、安全、可扩展性赋能：
当我们将业务领域分解为可独立部署的有限能力的环境的同时，也将相关的变更周期解耦。只要变更限于单一有限的环境，并且服务继续履行其现有合约，那么这些更改可以独立于与其他业务来进行开展和部署。结果是实现了更频繁和快速的部署，从而实现了持续的价值流动。 通过扩展部署组织本身可以加快部署。由于沟通和协调的开销，添加更多的人，往往会使软件构建变得更加苦难。 弗雷德·布鲁克斯（Fred Brooks，人月神话作者）很多年前就教导我们，在软件项目的晚期增加更多的人力将会时软件项目更加延期。 然而，我们可以通过在有限的环境中构建更多的沙箱，而不是将所有的开发者都放在同一个沙箱中。 由于学习业务领域和现有代码的认知负担减少，并建立了与较小团队的关系，因此我们添加到每个沙箱的新开发人员可以更快速地提高并变得更高效。 可以加快采用新技术的步伐。大型单体应用架构通常与对技术堆栈的长期保证有关。这些保证的存在是为了减轻采用新技术的风险。采用了错误的技术在单体架构中的代价会更高，因为这些错误可能会影响整个企业架构。如果我们可以在单个整体的范围内采用新技术，将隔离并最大限度地降低风险，就像隔离和最小运行时故障的风险一样。 微服务提供独立、高效的服务扩展。单体架构也可以扩展，但要求我们扩展所有组件，而不仅仅是那些负载较重的组件。当且仅当相关联的负载需要它时，微服务才会被缩放。 三. 自服务敏捷架构使用云原生应用架构的团队通常负责其应用的部署和持续运营。云原生应用的成功采纳者已经为团队提供了自服务平台。
正如我们创建业务能力团队为每个有界的环境构建微服务一样，我们还创建了一个能力小组，负责提供一个部署和运行这些微服务的平台。
这些平台中最大好处是为消费者提供主要的抽象层。通过基础架构即服务（IAAS），我们要求API创建虚拟服务器实例、网络和存储，然后应用各种形式的配置管理和自动化，以使我们的应用程序和支持服务能够运行。现在这种允许我们自定义应用和支持服务的平台正在不断涌现。
应用程序代码简单地以预构建的工件（可能是作为持续交付管道的一部分生成的）或Git远程的原始源代码的形式“推送”。 然后，平台构建应用程序工件，构建应用程序环境，部署应用程序，并启动必要的进程。 团队不必考虑他们的代码在哪里运行或如何到达那里，这些对用户都是透明得，因为平台会关注这些。
这样的模型同样适合于后端服务。需要数据库？ 消息队列或邮件服务器？ 只需要求平台来配合您的需求。平台现在支持各种SQL/NoSQL数据存储、消息队列、搜索引擎、缓存和其他重要的后端服务。这些服务实例然后可以“绑定”到您的应用程序，必要的凭据会自动注入到应用程序的环境中以供其使用。从而消除了大量凌乱而易出错的定制自动化。
这些平台还经常提供广泛的额外操作能力：
应用程序实例的自动化和按需扩展 应用健康管理 请求到或跨应用程序实例间的动态路由和负载均衡 日志和指标的聚合 这种工具的组合确保了能力团队能够根据敏捷原则开发和运行服务，从而实现速度，安全性和规模化。
四. 基于API的协作在云原生应用架构中，服务之间的唯一互动模式是通过已发布和版本化的API。这些API通常是具有JSON序列化的HTTP REST风格，但也可以是其他协议和序列化格式。
只要有需要，在不会破坏任何现有的API协议的前提下，团队就可以部署新的功能，而不需要与其他团队进行同步。自助服务基础设施平台的主要交互模式也是通过API，就像其他业务服务一样。供给、缩放和维护应用程序基础设施的方式不是通过提交单据，而是将这些请求提交给提供该服务的API。
通过消费者驱动的协议，可以在服务间交互的双方验证协议的合规性。服务消费者不能访问其依赖关系的私有实现细节，或者直接访问其依赖关系的数据存储。实际上，只允许有一个服务能够直接访问任何数据存储。这种强制解耦直接支持云原生的速度目标。
五.抗脆弱性Nassim Taleb在他的Antifragile（Random House）一书中介绍了抗脆弱性的概念。如果脆弱性是受到压力源的弱化或破坏的质量系统，那么与之相反呢？许多人会以稳健性或弹性作出回应——在遭受压力时不会被破坏或变弱。然而，Taleb引入了与脆弱性相反的抗脆弱性概念，或者在受到压力源时变得更强的质量系统。什么系统会这样工作？联想下人体免疫系统，当接触病原体时，其免疫力变强，隔离时较弱。我们可以像这样建立架构吗？云原生架构的采用者们已经设法构建它们了。Netflix Simian Army项目就是个例子，其中著名的子模块“混沌猴”，它将随机故障注入到生产组件中，目的是识别和消除架构中的缺陷。通过明确地寻求应用架构中的弱点，注入故障并强制进行修复，架构自然会随着时间的推移而更大程度地收敛。</description></item><item><title>HTTP/3与HTTP/2的性能比较</title><link>https://icorer.com/icorer_blog/posts/performance_comparison_between_http3_and_http2/</link><pubDate>Thu, 16 Apr 2020 15:17:18 +0800</pubDate><guid>https://icorer.com/icorer_blog/posts/performance_comparison_between_http3_and_http2/</guid><description>这是一篇来自cloudflare公司的博客译文，阐述了一些HTTP3与HTTP2的性能对比。 我们在去年Cloudflare的生日周宣布支持HTTP/3，它是HTTP/2的继承者。我们的目标是并且一直是帮助建立一个更好的互联网。在标准方面的合作是其中的一个重要部分，我们很幸运能在这里做到这一点。
尽管HTTP/3仍然处于草稿状态，但我们已经看到了很多用户的兴趣。到目前为止，已经有超过113000个区域激活了HTTP/3，如果您使用的是一个实验性的浏览器，那么可以使用新的协议访问这些区域！看到这么多人启用HTTP/3真是太棒了：通过HTTP/3访问真正的网站意味着浏览器有更多不同的属性可以测试。
当我们启动对HTTP/3的支持时，我们与Google合作，后者同时在Google Chrome中启动了实验性的支持。从那时起，我们看到更多的浏览器增加了实验性的支持：Firefox加入了他们的夜间版本，其他基于Chrome的浏览器，如Opera和Microsoft Edge通过底层Chrome浏览器引擎，Safari通过他们的技术预览。我们密切关注这些开发，并尽可能地与之合作；拥有一个拥有许多启用了HTTP/3的站点的大型网络，为浏览器实现者提供了一个极好的测试平台，可以用来测试代码。
那么，现在的情况如何，我们现在在哪里？IETF标准化过程将协议开发为一系列文档草稿版本，最终目的是生成一个最终草稿版本，该版本可以标记为RFC。QUIC工作组的成员在分析、实现和互操作规范方面进行协作，以便找到工作不太正常的地方。我们在支持HTTP/3的Draft-23的情况下启动了它，并一直在跟上每一个新的草案，其中27是最新的。在每一份草案中，小组都提高了QUIC定义的质量，并更接近于关于其行为方式的“粗略共识”。为了避免永久性的分析瘫痪和无休止的调整，每一个新的草案都增加了对规范提出修改的门槛。这意味着版本之间的更改更小，最终的RFC应该与我们在生产中运行的协议非常匹配。
优点HTTP/3的主要优点之一是提高了性能，特别是同时获取多个对象。使用HTTP/2，TCP连接中的任何中断（包丢失）都会阻塞所有流（行首阻塞）。因为HTTP/3是基于UDP的，如果一个数据包被丢弃，它只会中断一个流，而不是所有的流。
此外，HTTP/3还提供了0-RTT支持，这意味着在建立连接时，通过消除来自服务器的TLS确认，后续连接可以更快地启动。这意味着客户端请求数据的速度要比完整的TLS协商快得多，这意味着网站可以更早地开始加载。
下面说明数据包丢失及其影响：HTTP/2多路复用两个请求。一个请求从客户端通过HTTP/2到达服务器，请求两个资源（我们将请求及其相关的响应涂成绿色和黄色）。响应被分成多个包，唉，一个包丢失了，所以两个请求都被延迟了。
上面显示了HTTP/3复用2个请求。一个影响黄色响应的数据包丢失，而绿色的数据包运行良好。
会话启动的改进意味着到服务器的“连接”启动得更快，这意味着浏览器开始更快地查看数据。我们很好奇有多大的进步，所以我们做了一些测试。为了衡量0-RTT支持带来的改进，我们运行了一些基准测试时间到第一字节（TTFB）。平均来说，对于HTTP/3，我们看到的第一个字节出现在176ms之后，而对于HTTP/2，我们看到的是201ms，这意味着HTTP/3的性能已经提高了12.4%！
有趣的是，并不是协议的每一个方面都受草案或RFC的约束。实现选择会影响性能，例如有效的分组传输和拥塞控制算法的选择。拥塞控制是计算机和服务器用来适应过载网络的一种技术：通过丢弃数据包，传输随后会受到限制。因为QUIC是一种新的协议，要想使拥塞控制设计和实现正确，需要进行实验和调整。
为了提供安全和简单的起点，“丢失检测和拥塞控制”规范建议使用Reno算法，但允许端点选择他们可能喜欢的任何算法。 我们从New Reno开始，但我们从经验中知道，我们可以通过其他方式获得更好的性能。 我们最近已迁移到CUBIC，并且在我们的网络中，由于传输量较大且数据包丢失，CUBIC的性能比New Reno有所提高。 请继续关注，以获取更多详细信息。
对于我们现有的HTTP / 2堆栈，我们目前支持BBR v1（TCP）。 这意味着在我们的测试中，我们没有进行精确的比较，因为这些拥塞控制算法在较小传输和较大传输之间的行为会有所不同。 话虽这么说，与HTTP / 2相比，使用HTTP / 3的小型网站已经有了加速。 对于较大的区域，改进后的HTTP / 2堆栈的拥塞控制在性能上大放异彩。
对于15KB的小测试页，HTTP/3平均需要443ms来加载，而HTTP/2则需要458ms。然而，一旦我们将页面大小增加到1MB，这种优势就消失了：在我们今天的网络上，HTTP/3的速度比HTTP/2稍慢，加载速度为2.33秒，而加载速度为2.30秒。
合成基准很有趣，但是我们想知道HTTP/3在现实世界中的表现。
为了衡量，我们希望第三方可以在我们的网络上加载网站，模仿浏览器。WebPageTest是一个常用的框架，它使用漂亮的瀑布图来度量页面加载时间。为了分析后端，我们使用了 Browser Insights，以捕获我们的边缘看到的时间。然后，我们用一些自动化技术把这两部分结合在一起。
作为一个测试案例，我们决定使用这个博客来监控性能。我们配置了分布在世界各地的webgetest实例，以便通过HTTP/2和HTTP/3加载这些站点。我们还启用了HTTP/3和浏览器洞察力。因此，每当我们的测试脚本启动一个网页测试，使用支持HTTP/3的浏览器加载网页时，浏览器分析就会报告数据。冲洗并重复HTTP/2以进行比较。
下图显示了真实页面blog.cloudflare.com的页面加载时间，以比较HTTP/3和HTTP/2的性能。我们有从不同地理位置运行的这些性能度量。
如您所见，在北美，HTTP / 3性能仍落后于HTTP / 2性能，平均水平约为1-4％，在欧洲，亚洲和南美也看到了类似的结果。 我们怀疑这可能是由于拥塞算法不同所致：BBR v1上的HTTP / 2与CUBIC上的HTTP / 3不同。 将来，我们将努力在两者上支持相同的拥塞算法，以实现更准确的“苹果对苹果”比较。
结论总体而言，我们很高兴被允许推动这一标准的发展。 我们的实现效果很好，在某些情况下提供了更好的性能，并且在最坏的情况下类似于HTTP / 2。 随着标准的定稿，我们期待浏览器在主流版本中增加对HTTP / 3的支持。 对于我们而言，我们将继续支持最新的草案，同时寻找更多的方法来利用HTTP / 3获得更好的性能，无论是拥塞调整，优先级划分还是系统容量（CPU和原始网络吞吐量）。
同时，如果你想尝试一下，只需在我们的仪表板上启用HTTP/3并下载一个主要浏览器的夜间版本。关于如何启用HTTP/3的说明可以在我们的开发人员文档中找到。
附录：
原文地址：https://blog.cloudflare.com/http-3-vs-http-2/
Go QUIC库：https://github.com/lucas-clemente/quic-go</description></item><item><title>Redis6客户端缓存的相关设计</title><link>https://icorer.com/icorer_blog/posts/related-design-of-redis6-client-cache/</link><pubDate>Mon, 16 Mar 2020 13:15:18 +0800</pubDate><guid>https://icorer.com/icorer_blog/posts/related-design-of-redis6-client-cache/</guid><description>这篇文章翻译自Redis官方博客，这篇文章阐述了Redis6中将如何支持客户端缓存功能。
纽约Redis一天结束了，我于5:30在酒店起床，仍然与意大利时区保持同步，并立即走在曼哈顿的街道上，完全爱上了风景和美好的生活感觉。 但是我在Redis 6发行版中的感觉是，可能是最重要的功能，即新版本的Redis协议（RESP3）的采用曲线将非常缓慢，这是有充分理由的： 明智的人会在没有充分理由的情况下避免使用工具。 毕竟我为什么要这么严重地改进协议？主要有两个原因，即为客户提供更多的语义答复，并开放使用旧协议难以实现的新功能。 对我来说，最重要的功能之一就是客户端缓存。
让我们回到一年前。我来到旧金山的Redis Conf 2018，当时我坚信客户端缓存是Redis未来最重要的事情。 如果我们需要快速存储和高速缓存，那么我们需要在客户端中存储信息的子集。这是对延迟较小且规模较大的数据提供服务的想法的自然扩展。事实上，几乎所有的大公司都已经这样做了，因为这是唯一的生存之道。然而，Redis无法在此过程中协助客户。 一个幸运的巧合希望Ben Malec在Redis Conf上确切地谈论客户端缓存[1]，仅使用Redis提供的工具和许多非常聪明的想法。
[1] https://www.youtube.com/watch?v=kliQLwSikO4
本采取的方法确实打开了我的想象。 Ben为了使他的设计工作而使用了两个关键思想。首先是使用Redis Cluster的“哈希槽”概念，以将key分为16k组。这样，客户端将无需跟踪每个key的有效性，但可以将单个元数据条目用于一组key。Ben使用Pub / Sub来更改键时发送通知，因此他需要应用程序各个部分的帮助，但是该架构非常可靠。 修改key？同时发布一条使它无效的消息。 在客户端，您是否在缓存key？记住缓存每个key的时间戳，并且在接收到无效消息时，还要记住每个插槽的无效时间。 当使用给定的缓存key时，通过检查缓存的key是否具有比该key所属的插槽接收到的失效时间戳更旧的时间戳，来进行懒惰驱逐：在这种情况下，该key是陈旧数据， 必须再次询问服务器。
看完演讲之后，我意识到这是在服务器内部使用的好主意，以便允许Redis为客户端完成部分工作，并让客户端缓存更简单、更有效,所以我回家后,写了一个文档描述设计[2]。
[2] https://groups.google.com/d/msg/redis-db/xfcnYkbutDw/kTwCozpBBwAJ
但是，要使我的设计正常工作，我必须专注于将Redis协议切换到更好的协议，因此我开始编写规范，然后编写RESP3的代码，以及其他Redis 6之类的东西，例如ACL等，并且客户端缓存加入了 由于缺乏时间，我以某种方式放弃了Redis的许多构想的巨大空间。
但是我还是在纽约街头思考这个想法。 后来和会议的朋友一起去吃午餐和喝咖啡休息时间。 当我回到酒店房间时，剩下的整个晚上都是在飞机起飞前的第二天，所以我开始遵循我一年前写给小组的建议，开始编写Redis 6客户端缓存的实现。 看起来仍然很棒。
Redis服务器辅助的客户端缓存，最终称为跟踪(但我可能会改变想法)，是一个非常简单的功能，由几个关键的想法组成。
key空间被划分为“缓存槽”，但它们比Ben使用的哈希槽大得多。 我们使用CRC64输出的24位，因此有超过1600万个不同的插槽。为什么这么多?因为我认为您希望有一个拥有1亿key的服务器，而一条无效消息应该只影响客户端缓存中的几个key。Redis中无效表的内存开销是130mb:一个8字节的数组，指向16M个条目。这对我来说是可以的，如果你想要这个功能，你就要充分利用你在客户端的所有内存，所以使用130MB的服务器端是可以的;您所赢得的是一个更细粒度的失效。
客户端通过简单的命令以opt方式启用该特性：
1 CLIENT TRACKING on 服务器会回复旧的+ OK，从那一刻开始，命令表中标记为“只读”的每个命令不仅会把键返回给调用者，而且还会产生副作用 客户端到目前为止请求的所有键的缓存插槽（但只有使用只读命令的键才是，这是服务器与客户端之间的协议）。Redis存储此信息的方法很简单。每个Redis客户端都有一个唯一的ID，因此，如果客户端ID 123执行有关将key散列到插槽1、2和5的MGET，我们将获得带有以下条目的无效表：
11 -&amp;gt; [123] 22 -&amp;gt; [123] 35 -&amp;gt; [123] 但是稍后客户端ID 444也会询问插槽5中的key，因此该表将如下所示：
15 -&amp;gt; [123, 444] 现在，其他一些客户端更改了插槽5中的某些key。发生的事情是Redis将检查Invalidation Table，以发现客户端123和444都可能在该插槽上缓存了key。我们将向这两个客户端发送无效消息，因此他们可以自由地以任何形式处理该消息：要么记住上一次插槽无效的时间戳记，然后以懒惰的方式检查时间戳记（或者 如果您更喜欢此渐进式“时期”：它比较安全），然后根据比较结果将其逐出。否则，客户端可以通过获取其在此特定插槽中缓存的内容的表来直接直接回收对象。这种具有24位哈希函数的方法不是问题，因为即使缓存了数千万个key，我们也不会有很长的列表。发送无效消息后，我们可以从无效表中删除条目，这样，我们将不再向这些客户端发送无效消息，直到它们不再读取该插槽的key为止。
请注意，客户端不必真正使用hash函数的所有24位。例如，他们可能只使用20位，然后也会转移Redis发送给他们的无效消息槽。不确定这样做是否有很多好的理由，但在内存受限的系统中可能是一个想法。
如果您严格按照我所说的进行操作，您会认为相同的连接同时接收到正常的客户端响应和无效消息。对于RESP3，这是可能的，因为无效消息是作为“推送”消息类型发送的。 但是，如果客户端是阻塞客户端，而不是事件驱动的客户端，则这将变得很复杂：应用程序需要某种方式不时读取新数据，并且看起来复杂而脆弱。 在这种情况下，最好使用另一个应用程序线程和另一个客户端连接，以便接收无效消息。 因此，您可以执行以下操作：</description></item><item><title>Redis Client Side Cache - Redis客户端缓存 - RedisConf18</title><link>https://icorer.com/icorer_blog/posts/redis-client-side-cache-redis-client-side-cache-redisconf18/</link><pubDate>Sun, 15 Mar 2020 16:22:18 +0800</pubDate><guid>https://icorer.com/icorer_blog/posts/redis-client-side-cache-redis-client-side-cache-redisconf18/</guid><description>一. 背景描述客户端缓存是一个有意思的话题，它不是空穴来风的技术，在最新的Redis RC版本已经正式开始着手CSC方案的设计，虽然目前版本的CSC还不能真正的商用，但是市面上也有一些其他公司开始着手试探CSC相关方案的设计与实现。
目标比较有名的模型是两种：
Ben Malec paylocity公司方案 Redis6 RC方案 这两种方案并不是独立的，他们各有各的优势，paylocity公司的方案被redis团队所赞赏，并吸收了一些思路进入Redis RC版本中，Redis RC版本主要是提供了一些server端的协助，但是本质上还是没有完整的CSC方案。
二. RedisConf2018大会 Ben Malec分享这里，我们将阐述RedisConf 2018年的经典分享，这个分享围绕CSC机制的相关设计与实现，并且方案已经被广泛使用在paylocity公司，有很高的的借鉴意义。 Ben Malec的分享主要围绕如何实现一个和Redis缓存同步的本地内存缓存。
首先，我们看一下简单的网站模型，模型图如下：
接着，Ben提出很重要的缓存象限，缓存象限图如下所示：
缓存最好的应用场景就是针对更改少、请求频繁的数据读写场景。
客户端缓存，首先需要面对的问题就是 “缓存数据滞后”
这部分演讲，Ben发散思维了所有Web服务器尝使用的“文件系统观察”功能。
随后，客户端缓存会出现“跨服务器缓存数据不一致”问题。
这种问题并不是只会在不同的机器间出现，还会在同一台机器不同进程中出现。
比如在两台机器针对缓存都设置了相同的TTL生命期，但是由于机器间时间可能不同步，从而造成缓存不一致情况。更坏的情况就是，数据已经更新了，但是客户端缓存没办法及时更新，造成用户请求到旧的数据，如果再多台机器负载的情况下，极有可能出现一会新值、一会旧值得问题，这种飘忽不定的缓存返回会造成用户较差的使用体验。
接下来，Ben提出一个很重要的时间观点，服务器间想在大约相同的时间内更新相关的key，这个大约相同的时间证明这个缓存方案并不一定能够满足分布式强一致，只是在合理的时间范围内数据一致。
接下来，Ben提出第三个缓存问题，“缓存踩踏”问题
这里所说的就是如果自己完全制作一个进程内缓存，有很多需要考虑，比如启动数据加载，数据池的备份，服务器扩容过程，等等问题。
Redis可以提供简单的缓存解决方案。
Redis缓存可以很好地解决缓存一致性问题，也可以解决缓存数据滞后问题，也不会有数据践踏。
但是redis也有一些其他问题，比如每次缓存获取都需要tcp往返通信，虽然redis已经很快了，但是本地内存的访问速度仍然比网络io速度高太多。
这里，Ben提出如果在redis基础上，再增加进程内缓存，效果就会更好了。
针对这种本地缓存方案，首先提出了三个需要做的事情：
解决数据一致性问题 解决数据滞后问题，主要围绕进程内缓存和远程redis之间的滞后问题 不要让网络爆炸，要控制合理的网络通信 借助redis，我们是不是可以更好的实现这个功能呢？
上面这部分讲述了一个问题，如果我们想让机器间的数据保证一致性，如果仅仅通过广播变更的key-value，这将是致命的，因为大量的key-value将引爆网络，还有一个原因就是你广播了key-value数据，并不是所有的节点以后都会使用，这就会造成效率问题，这些问题几乎都是围绕网络，但是还没考虑网络的质量问题，比如网络质量很差的情况下，节点可能收到多组不同的改动，这些改动可能会数据践踏，但是你不知道践踏的顺序，从而造成数据的不一致问题。
因此，我们并不是广播key-value，而是只广播key，但是你也知道redis支持key数据，最大可以达到512MB，就算不是512MB，就算是1kb的数据，我们的网络就能抗住吗，所以简单的广播key是不理智的。
redis集群中采用hash槽位来进行数据分片，那么我们是否可以借鉴这种思路呢？我们不再广播key，而是广播key所计算的hash值，这样如果key的数据多么大，我们都能控制在网络上传输的数据大小。
我们放弃了广播key，而选择同步16bit的key hash槽数据，这样操作的优势明显，首先广播数据的大小被控制了，并且解决了数据一致性问题，我们只是广播hash，并没有广播数据，当某个hash出现了脏数据，它将会在下次访问时被感知并被更新。这个也有一点缺陷需要注意，因为我们借助了hash槽位，所以一个hash slot上会包含很多key，这些key中的一个被更新，则这组hash slot都将失效。
计算遍历所有的 key 吗？命中脏 slots 的话，就删除这个key？但是这样的话相当于对每一个缓存更新操作，客户端都要遍历计算一遍自己所有 key 的 slot，显然是不可接受的。
这里也是采用惰性计算的思想：客户端收到了 slot 更新的广播，只把 slot 存起来，当真正用到在此 slot 中的 key 的时候才去 Redis 更新。那么就会有这样一种情况，slot 中部分 key 更新了，部分 key 没有更新，如何区分开哪些 key 已经在 slot 更新之后更新过了呢？这里只要记一下 slot 更新的 timestamp 就可以，每一个 key-value 也带有一个 timestamp 属性。如果 key 的 timestamp 早于 slot 的 timestamp，那 key 就是需要更新的；更新之后 key 的 timestamp 就晚于 slot 的 timestamp 了。下次可以直接用。</description></item><item><title>Go的垃圾收集者之旅 [Getting to Go: The Journey of Go's Garbage Collector]</title><link>https://icorer.com/icorer_blog/posts/getting-to-go-the-journey-of-gos-garbage-collector/</link><pubDate>Thu, 12 Mar 2020 13:21:18 +0800</pubDate><guid>https://icorer.com/icorer_blog/posts/getting-to-go-the-journey-of-gos-garbage-collector/</guid><description>一 . 背景介绍这篇文章是一片演讲笔记，这是Richard L. Hudson于2018.06.18在国际内存管理研讨会(ISMM)上的演讲。
理查德·哈德森（Rick）因其在内存管理方面的工作而闻名，其中包括发明了Train，Sapphire和Mississippi Delta算法以及GC堆栈映射，这些算法能够以静态类型的语言（例如Modula-3，Java）进行垃圾收集 ，C＃和Go。 Rick目前是Google Go团队的成员，他致力于Go的垃圾回收和运行时问题。
Original URL : https://blog.golang.org/ismmkeynote
二. 演讲内容 在我们正式研究这些东西之前，我们首先需要展示一下GC在Go中看着像什么？
首先，Go程序有成千上万个堆栈，他们被Go调度器管理着并且总是在GC安全点被抢占。Go调度器将Go协程多路复用到系统线程上，希望每一个物理线程运行一个系统线程。我们通过复制堆栈和修改栈指针来管理栈及其大小。因为这些是本地操作所以很容易扩展。
接下来，我们需要讨论一个重要的内容，和传统C系统语言类似、Go也是一种“值定向”语言，而不是类似众多runtime管理型语言的“参考导向”语言。正如上面的例子展示了tar包中某一个类型如何在内存中布局存储，所有的字段均直接内嵌在Reader变量中。这使程序员可以在需要的时候更好的控制内存布局。可以把有关联值的字段进行临近分配，这样的策略有利于提高缓存的存储位置。
以值为导向有助于使用外部功能接口(有助于不同语言之间通信)，Go语言和C/C++语言能够很快的FFI (语言交互接口 ) 操作，谷歌内部有大量可用的功能、但是他们使用C++编写的。Go语言迫不及待的实现这些功能，因此Go必须使用外部功能访问接口来实现这些功能。
基于这个设计上的决定导致Go运行时必须执行一些惊人的东西，这些可能是Go和其他带有GC的计算机语言最重要的不同之处。
Go语言当然会有指针的存在，但是事实上Go甚至可以有内部指针[ interior pointer ]。这些指针可以让数据的整体具有活性，而且他们很常见。
Go语言有一套完善的预编译系统，从而一个单独的二进制运行体文件就可以包含完整的运行时环境。
运行时也不需要JIT热点重新编译，这有优点也有缺点。首先，这种模式下程序执行的可重现性要容易很多，这使得编译器改进的步伐变得更快。
可悲的是，我们没有机会像使用JITed系统那样可以反馈优化。因此，静态预编译存在上述优缺点。
Go 提供了两个旋钮用来控制GC。第一个是GCPercent，这个旋钮基本上是用来调整要使用的CPU和内存的数量，默认值为100、代表一半的堆专用于活动内存、一半的堆用来分配。当然，你可以按照你需要的比例方向就行旋钮调整。
最大堆，这个属性目前尚未发布、但已经在内部使用和评估了，这个参数允许编程人员控制最大的堆使用空间。内存不足、内存溢出(OOM)、在Go语言上很难；暂时的内存使用高峰应该通过增加CPU成本来解决，不是通过终止程序。基本上，如果GC遇到了内存压力，它应该通知应用程序应该减轻负载。当一切恢复正常之后，GC会通知应用程序让其恢复到正常负载。最大堆特性还为调度提供更多的灵活性。运行时不必总是对可用的内存量有多大的幻想，而是可以将堆的大小调整为最大堆的大小。
这结束了我们对垃圾回收器很重要的Go片段的讨论。
现在让我们来谈谈Go语言运行时以及我们如何到达这里，如何达到自己所在的位置。这句话是演讲者想表达Go运行时GC是如何一路发展的。
2014年，毫无疑问、如果Go不能以某种方式解决GC延迟问题，则Go是不会成功的。
其他新语言也会遇到同样的问题。Rust之类的语言采用了不通的解决方式，但是这里我们将讲述Go所走的道路。
为什么延迟如此的重要？
延迟是个累积量，数学对此是不能完全解释的。
99%的隔离式GC延迟服务级别目标(SLO)，例如 99% 的GC周期小于10ms，只是根本无法扩展。重要的是整个会话期间的延迟或一天中多次使用程序的延迟（这里表达的含义是：单次GC看着不重，但是无论对于单次长会话、还是长期运行的程序体，这会产生累计损害）。假设浏览一个网页的会话在一个会话中最终发出100个服务器请求，或者发出20个请求，并且一天中您有5个会话。 在这种情况下，只有37％的用户将在整个会话中获得一致的10毫秒以下体验。
正如我们所建议的那样，如果您希望这些用户中有99％的用户具有10ms以下的体验，则数学计算表明您确实需要定位4个9s或99.99％ile。
所以是2014年，杰夫·迪恩（Jeff Dean）发表了他的论文《The Tail at Scale》(规模的尾巴)，进一步探讨了这一问题。 由于它对Google的向前发展和试图以Google规模扩展产生严重影响，因此在Google周围被广泛阅读。
我们称这个问题为9s暴政。
那么，我们是如何对抗这场“暴政”的呢？
我们在2014年做了不少事情。
如果您想要10个答案，请再输入几个，然后选择前10个，这些就是您在搜索页面上输入的答案。如果请求超过50％ile，则重新发出请求或将请求转发到另一台服务器。 如果GC将要运行，请拒绝新请求或将请求转发到另一台服务器，直到完成GC。 依此类推。这段文字讲述的是类似负载均衡模式降低系统整体的响应时间。
所有这些变通办法来自非常聪明的人，他们有非常实际的问题，但他们没有解决GC延迟的根本问题。 在Google规模上，我们必须解决根本问题。 为什么？
冗余无法扩展，冗余成本很高。 它花费了新的服务器场。
我们希望能够解决这个问题，并把它看作是一个改善服务器生态系统的机会，并在这个过程中拯救一些濒临灭绝的玉米田，让一些玉米粒有机会在7月4日达到膝盖高点，让玉米更好的生长。 （这段话的意思就是，希望通过节约服务器机房成本而保护环境。）
这就是2014年的SLO，是的，的确，我在打沙袋，在团队中我是新手，这对我来说是个新过程，我不想过分承诺。(这张PPT展示了2014年的GC能力)
此外，有关其他语言的GC延迟的演讲简直令人恐惧。
最初的计划是执行无读屏障的并发复制GC。 那是长期计划。 读屏障的开销存在很多不确定性，因此Go希望避免这些屏障。
但是在2014年短期，我们必须采取行动。我们必须将所有运行时和编译器都转换为Go。它们当时是用C编写的。没有更多的C语言了，因为C语言程序员不了解GC，但是对如何复制字符串有了一个很酷的想法，因此不再有很多错误。我们需要专注与GC延迟领域的技术方案或任何东西，但是这些东西带来的性能损失必须小于编译器提供的加速。因此我们受到了限制。基本上，我们花费一年在编译器性能上的改进，可以被GC并发协程消耗完。就是这样。 我们不能放慢Go程序的速度。 这在2014年将是站不住脚的。（艰苦的2014年）</description></item><item><title>Linux内核-内存管理: Out Of Memory Management 源码分析</title><link>https://icorer.com/icorer_blog/posts/linux-kernel-memory-management-out-of-memory-management-source-code-analysis/</link><pubDate>Sun, 08 Mar 2020 11:45:18 +0800</pubDate><guid>https://icorer.com/icorer_blog/posts/linux-kernel-memory-management-out-of-memory-management-source-code-analysis/</guid><description>我们这篇文章中描述了Linux内核对于 Out Of Memory Management 场景下的相关策略，接下来我们将进行Linux 5.0内核的OOM内核源码分析。
一. 关键数据结构针对源码部分，我们首先需要阐述oom_kill部分的核心数据结构。
文件路径：/linux/include/linux/oom.h
1.1 oom_control 结构体首先，我们给出具体的内核定义：
1/* 2 * Details of the page allocation that triggered the oom killer that are used to 3 * determine what should be killed. 4 */ 5struct oom_control { 6 /* Used to determine cpuset */ 7 struct zonelist *zonelist; 8 9 /* Used to determine mempolicy */ 10 nodemask_t *nodemask; 11 12 /* Memory cgroup in which oom is invoked, or NULL for global oom */ 13 struct mem_cgroup *memcg; 14 15 /* Used to determine cpuset and node locality requirement */ 16 const gfp_t gfp_mask; 17 18 /* 19 * order == -1 means the oom kill is required by sysrq, otherwise only 20 * for display purposes.</description></item><item><title>Linux内核-内存管理: Out Of Memory Management - OOM</title><link>https://icorer.com/icorer_blog/posts/linux-kernel-memory-management-out-of-memory-management-oom/</link><pubDate>Sat, 07 Mar 2020 11:49:18 +0800</pubDate><guid>https://icorer.com/icorer_blog/posts/linux-kernel-memory-management-out-of-memory-management-oom/</guid><description>一. 引言这篇文章，我们将要讨论的是内存不足(OOM)管理器，OOM检查是否有足够的可用内存来满足系统运行需求，如果没有足够的可用内存则进行进程kill操作。这是Linux内核虚拟内存模块中一个有争议的部分，有人建议在很多情况下删除它。所以在使用OOM的时候，首先需要确认OOM是否在待操作的Linux内核中存在，还需要确定OOM在Linux内核中的开启与关闭选项。
二. 检查可用内存（Checking Available Memory）对于某些操作，例如使用brk()扩展堆或使用mremap()重新映射地址空间，系统将检查是否有足够的可用内存来满足请求。请注意，这与当前文章后面介绍的out_of_memory()是不同部分，Linux内核的内存分配机制和内存可用度检查用于尽可能避免系统处于OOM状态。
检查可用内存时，所需的页数作为参数传递给vm_enough_memory()。除非系统管理员指定系统应超量使用内存，否则将检查可用内存的装载。为了确定有多少页面是可用的，Linux总结了以下数据位：
Total page cache (总页面缓存)：页面缓存很容易回收。 Total free pages (总空闲页面)：总可用页面，它们已经可用。 Total free swap pages(总自由交换页) ：用户空间页面可能会被换出。 Total pages managed by swapper_space(由swapper_space管理的总页面)： 尽管这将重复计算空闲交换页面。这是平衡某些情况，此选项有时保留但不使用。 Total pages used by the dentry cache(dentry缓存使用的总页面)： 这部分内存很容易被回收，主要用于vfs Total pages used by the inode cache (inode缓存使用的总页面)： 这部分内存很容易被回收，主要用于vfs-inode索引 如果在此处添加的页面总数足以满足请求，则vm_enough_memory() 将true返回给调用方。 如果返回false，则调用者知道该内存不可用，通常决定将-ENOMEM返回给用户空间。
三. 确定OOM状态（Determining OOM Status）当机器内存不足时，将回收旧的页面框架，但是尽管回收了页面，但仍可能发现即使以最高优先级进行扫描，也无法释放足够的页面来满足请求。如果无法释放页帧，则会调用out_of_memory() 以查看系统是否内存不足，是否需要终止进程。 不幸的是，系统可能没有内存不足，只需要等待IO完成或页面交换到外部存储。不幸的是，这不是因为系统具有内存，而是因为这个函数被不必要地调用，导致不必要地关闭进程。在决定终止一个进程之前，它要经过以下检查表。
是否还有足够的交换空间(nr_swap_pages&amp;gt; 0) ？如果是，则不进行OOM 从上次失败到现在已经超过5秒了吗?如果是，则不进行OOM 我们在最后一秒失败了吗?如果没有，则不进行OOM 如果在过去5秒内没有10次失败，就不进行OOM 最近5秒钟内进程是否被杀死？ 如果是，则不进行OOM 四. 选择一个进程（Selecting a Process）函数select_bad_process()负责选择要终止的进程。它通过逐步执行每个正在运行的任务并计算使用badness()函数杀死它的适合程度来做出决定。坏度的计算方法如下，请注意，平方根是使用int_sqrt()计算的整数近似值。
1badness_for_task = total_vm_for_task / (sqrt(cpu_time_in_seconds) * 2sqrt(sqrt(cpu_time_in_minutes))) 这个公式是为了选择一个使用大量内存但寿命不是很长的进程。已经运行了很长时间的进程不太可能是导致内存不足的原因，因此这个计算可能会选择一个使用了大量内存但没有运行很长时间的进程。如果该进程是根进程或具有CAP_SYS_ADMIN功能，则将坏度值除以4，因为假定根特权进程表现良好。类似地，如果它具有CAP_SYS_RAWIO功能(访问原始设备)特权，则坏度值进一步除以4，因为不希望杀死一个直接访问硬件的进程。</description></item><item><title>PHP-rdkafka 内核扩展相关源码分析</title><link>https://icorer.com/icorer_blog/posts/php-rdkafka-kernel-extension-related-source-code-analysis/</link><pubDate>Fri, 06 Mar 2020 12:41:18 +0800</pubDate><guid>https://icorer.com/icorer_blog/posts/php-rdkafka-kernel-extension-related-source-code-analysis/</guid><description>这篇文章主要针对PHP生态的的kafka组件 php-rdkafka 进行相关的内核源码分析，方便大家把握组件的相关使用，目前文章主要针对kafka生产者部分。
一. 样例PHP代码 1public function __construct($config) 2 { 3 $conf = new \RdKafka\Conf(); 4 $conf-&amp;gt;set(&amp;#39;metadata.broker.list&amp;#39;, $config[&amp;#39;brokerList&amp;#39;]); 5 $conf-&amp;gt;set(&amp;#39;message.max.bytes&amp;#39;, $config[&amp;#39;messageMaxBytes&amp;#39;]); 6 $conf-&amp;gt;set(&amp;#39;metadata.request.timeout.ms&amp;#39;, $config[&amp;#39;requestTimeout&amp;#39;]); 7 $conf-&amp;gt;set(&amp;#39;session.timeout.ms&amp;#39;, $config[&amp;#39;sessionTimeout&amp;#39;]); 8 $this-&amp;gt;producer = new \RdKafka\Producer($conf); 9 $this-&amp;gt;producer-&amp;gt;addBrokers($config[&amp;#39;brokerList&amp;#39;]); 10 } 11 12 public function sendMessage($data){ 13 $result = 1; 14 $topic = $this-&amp;gt;producer-&amp;gt;newTopic($data[0][&amp;#39;topic&amp;#39;]); 15 $topic-&amp;gt;produce(RD_KAFKA_PARTITION_UA, 0, $data[0][&amp;#39;value&amp;#39;]); 16 $this-&amp;gt;producer-&amp;gt;poll(0); 17 for ($flushRetries = 0; $flushRetries &amp;lt; 10; $flushRetries++) { 18 $result = $this-&amp;gt;producer-&amp;gt;flush(10000); 19 if (RD_KAFKA_RESP_ERR_NO_ERROR === $result) { 20 break; 21 } 22 } 23 if (RD_KAFKA_RESP_ERR_NO_ERROR !</description></item><item><title>Redis哨兵-官方文档翻译</title><link>https://icorer.com/icorer_blog/posts/redis-sentinel-official-document-translation/</link><pubDate>Mon, 24 Feb 2020 22:36:18 +0800</pubDate><guid>https://icorer.com/icorer_blog/posts/redis-sentinel-official-document-translation/</guid><description>Sentinel概述Redis Sentinel为Redis提供高可用性。实际上，这意味着使用&amp;quot;哨兵&amp;quot;可以创建一个不需要人工干预就能抵抗某些类型失败的Redis部署。
Redis Sentinel还提供其他附属任务，如监控、通知和为客户提供配置。
这是宏观上（即全局）Sentinel功能的完整列表：
监视：Sentinel会不断检查你的主实例和副本实例是否按预期工作。 通知：Sentinel可以通过API通知系统管理员或其他计算机程序，其中一个被监控的Redis实例出了问题。 自动故障转移：如果一个主服务器没有按照预期工作，Sentinel可以启动一个故障转移过程，其中一个副本被提升到主服务器，其他附加的副本被重新配置以使用新的主服务器，使用Redis服务器的应用程序在连接时被告知要使用的新地址。 组态设定提供者：Sentinel充当客户端服务发现的授权来源：客户端连接到Sentinels，以询问负责给定服务的当前Redis主服务器的地址。 如果发生故障转移，Sentinels将报告新地址。 Sentinel的分布式性质Redis Sentinel是一个分布式系统：
哨兵本身被设计成在一个有多个协作的哨兵进程的配置中运行。有多个哨兵进程协作的好处如下:
当多个哨兵一致认为某个主节点不再可用时，就会执行故障检测。这降低了误报的概率。 即使不是所有的哨兵进程都在工作，哨兵也能工作，这使得系统对故障具有健壮性。毕竟，拥有一个本身就是单点故障的故障转移系统是毫无乐趣的。 哨兵、Redis实例(主实例和副本实例)和连接到哨兵和Redis的客户机的所有组成部分是一个更大的具有特定属性的分布式系统。在本文档中，将逐步介绍概念，从为了理解Sentinel的基本属性所需的基本信息，到为了理解哨兵的工作原理的更复杂的信息（可选）。
快速入门获得哨兵当前版本的Sentinel称为Sentinel 2。它是对最初的哨兵实现的重写，使用了更强大、更简单的预测算法(在本文档中有解释)。
自Redis 2.8起已发布稳定版本的Redis Sentinel。
在不稳定分支中进行了新的开发，并且有时新功能一旦被认为是稳定的，便会立即移植回最新的稳定分支。
Redis Sentinel版本1(随Redis 2.6一起发布)是不推荐使用的。
运行哨兵如果您正在使用redis-sentinel可执行文件(或者如果您有一个与redis-server可执行文件同名的符号链接)，您可以使用以下命令行运行Sentinel：
1redis-sentinel /path/to/sentinel.conf 否则，您可以直接使用redis-server可执行文件以Sentinel模式启动它：
1redis-server /path/to/sentinel.conf --sentinel 这两种方法的工作方式相同。
但是，在运行Sentinel时必须使用一个配置文件，因为系统会使用这个文件来保存在重新启动时要重新载入的当前状态。如果没有配置文件，或者配置文件路径不可写，Sentinel将拒绝启动。
哨兵默认情况下会监听TCP端口26379的连接，因此，为了使哨兵正常工作，必须打开服务器的端口26379，以接收来自其他哨兵实例的IP地址的连接。 否则，哨兵无法讨论也不能就该做什么达成共识，因此将永远不会执行故障转移。
部署哨兵前需要了解的基本内容 一个健壮的部署至少需要三个Sentinel实例。 应将三个哨兵实例放置到被认为以独立方式发生故障的计算机或虚拟机中。例如在不同的可用区域上执行的不同物理服务器或虚拟机。 Sentinel + Redis分布式系统不保证在故障期间保留已确认的写入，因为Redis使用异步复制。但是，有一些部署Sentinel的方法使窗口丢失写入仅限于某些时刻，而还有其他一些不太安全的方法来部署它。 您的客户需要Sentinel支持。 流行的客户端库具有Sentinel支持，但不是全部。 如果您不经常在开发环境中进行测试，那么就没有HA设置是安全的，如果您可以在生产环境中进行测试，如果它们能够工作，那就更好了。你可能有一个错误的配置，只有当它变得太晚(凌晨3点当master停止工作)才会变得明显。 Sentinel，Docker或其他形式的网络地址转换或端口映射应该小心混合：Docker执行端口重新映射，破坏了其他Sentinel进程的Sentinel自动发现以及主数据库的副本列表。有关更多信息，请参阅本文档后面有关Sentinel和Docker的部分。 配置哨兵edis源发行版包含一个名为Sentinel .conf的文件，它是一个自文档化的示例配置文件，您可以使用它来配置Sentinel，但是典型的最小配置文件，如下所示：
1sentinel monitor mymaster 127.0.0.1 6379 2 2sentinel down-after-milliseconds mymaster 60000 3sentinel failover-timeout mymaster 180000 4sentinel parallel-syncs mymaster 1 5 6sentinel monitor resque 192.</description></item><item><title>MKV-高性能分布式内存KV-开篇</title><link>https://icorer.com/icorer_blog/posts/mkv-high-performance-distributed-memory-kv-opening/</link><pubDate>Wed, 19 Feb 2020 11:43:18 +0800</pubDate><guid>https://icorer.com/icorer_blog/posts/mkv-high-performance-distributed-memory-kv-opening/</guid><description>一. 背景描述目前缓存环境中，使用较多的是Redis缓存，但是Redis单线程机制，在特高并发场景中还是能达到吞吐瓶颈，又由于很多大数据应用场景需要单次GET 1000或者更多的key，所以直接打到Redis服务器上，很容易让Redis主线程出现阻塞情况，产生吞吐大大下降的情况。
在这样的情况下，我们就设想架构设计一个分布式内存的缓存系统（MKV），主要设计目标包括一下：
多线程机制保障多核使用，提高云服务器的CPU使用率。 实现高性能、并发安全、存储具备数据完整性的内存缓存存储，支撑单次1000以上的key获取操作。 支持Redis-RESP应用层协议，由于大部分业务方使用redis缓存，尽量避免缓存切换带来的系统调整成本。 服务可用性达到99.99% 支持分布式场景不是和使用。 等等。。。 二. 模型试验由于团队一直在研究Redis内核及其通信协议，因此我们首先需要对多线程版本的缓存MKV 进行模型实验，证明猜想的有效性。
于是，我们分别针对官方Redis内核 和 我们目前的多线程版本缓存KV组件 - MKV进行性能测试对比。
2.1 测试环境我们的测试在下面的环境中进行：
Linux 5.0.0 Kernel Intel(R) Core(TM) i7-8550U CPU @ 1.80GHz [4核] 16GB内存 单次请求 ：1000 个key 使用Redis官方 redis-benchmark 工具进行压测 2.2 Redis 官方版本压测【SET: 85w/s GET: 105w/s 】1redis-benchmark -p 6379 -t get -n 5000000 -P 1000 -c 10 压测结果如下：
1====== SET ====== 2 10000000 requests completed in 11.75 seconds 3 10 parallel clients 4 3 bytes payload 5 keep alive: 1 6 70.</description></item><item><title>LibCurl连接复用原理</title><link>https://icorer.com/icorer_blog/posts/libcurl-connection-multiplexing-principle/</link><pubDate>Fri, 14 Feb 2020 13:35:18 +0800</pubDate><guid>https://icorer.com/icorer_blog/posts/libcurl-connection-multiplexing-principle/</guid><description>一. 背景描述Curl是计算机中使用最多的网络请求工具，很多开源项目在内核中对于HTTP、FTP的操作是通过libcurl库获得的技术支持。这篇文章主要调研libcurl库中的TCP连接复用部分。
二. 连接池Libcurl针对tcp连接采用了连接池管理，一次传输完成后，它将在“连接池”（有时也称为连接缓存）中保持N个连接处于活动状态，以便恰好能够重用现有连接之一的后续传输可以使用它而不是创建一个新连接。
重用一个连接而不是创建一个新的连接在速度和所需资源方面提供了显著的好处。
当libcurl准备建立一个新的连接来进行传输时，它首先会检查池中是否有可以重用的现有连接。**连接重用检查是在使用任何DNS或其他名称解析机制之前完成的，因此它完全基于主机名。**如果已经存在到正确主机名的实时连接，则还将检查许多其他属性（端口号，协议等），以确保可以使用它。
三. 连接池场景Libcurl 几乎在所有的实现场景中都自动加入了连接池支持，主要的场景包括以下三种：
Easy API pool Multi API pool Sharing the &amp;ldquo;connection cache&amp;rdquo; 3.1 Easy API pool当您使用easy API，或更具体地说，使用curl_easy_perform()时，libcurl将使该池与特定的easy句柄关联。 然后重用同一简单句柄将确保它可以重用其连接。
3.2 Multi API pool当您使用multi API时，连接池将与multi句柄相关联。这允许您自由地清理和重新创建easy句柄，而不会有丢失连接池的风险，并且允许一个easy句柄使用的连接在以后的传输中被另一个简单句柄重用。只需重用multi句柄。
3.3 Sharing the &amp;ldquo;connection cache&amp;rdquo;从libcurl 7.57.0开始，应用程序可以使用 share interface，以使其他独立的传输共享同一连接池。
四. Curl-TCP长连接和DNS解析的关系libcurl具有自己的内部DNS缓存，默认情况下它将在其中缓存解析的地址60秒（此选项可以更改） 。因此具有相同名称的后续解析将使用该时间范围内的缓存结果。
curl的连接缓存完全基于URL中使用的主机名，因此，如果缓存中已有与“ example.com”的可用连接，则该连接将用于对同一主机名的后续请求。 curl既不知道也不关心该名称的IP地址是什么，或者自连接启动以来它是否更改。 重用连接时，它将跳过整个dns解析阶段。
传输完成且连接仍然处于活动状态时，将把连接放回连接缓存中(或者，如果由于达到了限制而认为缓存已满，则关闭连接)。
由于连接重用是基于名称完成的，因此使用另一个名称解析为现有连接的相同IP不会使curl重复使用该连接。 它将解析名称并为此创建一个新的连接。
一个连接可以无限期地保留在连接缓存中，除非它被杀死以腾出空间或被重用。 如果它“死了”（由于它从另一端关闭），则当它被注意到时，它将最终从缓存中删除。
HTTP/2
可以通过HTTP/2发送的PING帧不会在连接缓存中处理(atm)连接，这将导致它们很快被服务器杀死。(libcurl 7.62.0添加了一个新的API，允许应用程序保持这样的连接，参见curl_easy_upkeep)
DoH
随着curl 7.62.0引入了DoH (dn -over- https)支持，DNS缓存将缓存TTL秒数的名称，而不仅仅是使用默认的60秒。
四. 重点总结 Libcurl连接重用检查是在使用任何DNS或其他名称解析机制之前完成的，因此它完全基于主机名。当libcurl的池中已经有了到主机名的活动连接时，它会跳过名称解析，而是直接进行重用。 libcurl长连接 和 dns请求没有相关关系，因此原生的libcurl库并不能对于dns解析变化有很好的的感知过程。 五. LibCurl 和 DNS解析的结合方案由于从上面的内容可以看出，LibCurl和DNS解析之间没有动态感应的过程，所以如果需要增加DNS动态感应过程不能从LibCurl下手，而应该通过LibCurl的调用方增加一定的策略来下手，主要的策略包括以下三种:
DNS TTL方案： 针对LibCurl库调用包装一层，增加一层域名的DNS TTL读取功能，根据TTL进行DNS请求定时器的设计，从而感应DNS的变化过程。但是需要注意的是TTL数据在标准的POSIX DNS解析 API中不可用，可以使用非dns完成名称解析。 Libcurl Handle 增强控制方案：Libcurl库对外统一暴露了handle内存区，为了感应到dns变化，我们就必须要让handle强制进入到dns解析阶段，因此可以针对Libcurl handle内存区的存活时长 和 内存区域使用次数下手，当时间超过了最大存活时长 或者 handle使用次数超过了最大复用次数，则强行进行Libcurl-handle内存区域释放，从而促使Libcurl进入dns解析过程。 参考资料：</description></item><item><title>LibCurl-DNS超时参数解析</title><link>https://icorer.com/icorer_blog/posts/libcurl-dns-timeout-parameter-analysis/</link><pubDate>Fri, 14 Feb 2020 12:07:18 +0800</pubDate><guid>https://icorer.com/icorer_blog/posts/libcurl-dns-timeout-parameter-analysis/</guid><description>一. 名称CURLOPT_DNS_CACHE_TIMEOUT - 设置DNS缓存条目的生存时间
二. 摘要1#include &amp;lt;curl/curl.h&amp;gt; 2 3CURLcode curl_easy_setopt(CURL *handle, CURLOPT_DNS_CACHE_TIMEOUT, long age); 三. 描述传递一个long类型参数，这会设置超时时间(以秒为单位)。名称解析将保存在内存中，并使用此秒数。设置为0将完全禁用缓存，或设置为-1使缓存的条目永远保持不变。默认情况下，libcurl缓存该信息60秒。
除非明确告知（例如，通过调用res_init（3）），否则各种libc实现的名称解析功能都不会重新读取名称服务器信息。这可能会导致libcurl继续使用旧的服务器，即使DHCP已经更新了服务器信息，对于一般的libcurl-app用户来说，这可能是一个DNS缓存问题。
请注意，DNS条目具有“ TTL”属性，但libcurl不使用该属性。 DNS缓存超时完全是推测性的，一个名称将在未来的一小段时间内解析为相同的地址。
默认值60
协议ALL
样例 1CURL *curl = curl_easy_init(); 2if(curl) { 3 curl_easy_setopt(curl, CURLOPT_URL, &amp;#34;http://example.com/foo.bin&amp;#34;); 4 5 /* only reuse addresses for a very short time */ 6 curl_easy_setopt(curl, CURLOPT_DNS_CACHE_TIMEOUT, 2L); 7 8 ret = curl_easy_perform(curl); 9 10 /* in this second request, the cache will not be used if more than 11 two seconds have passed since the previous name resolve */ 12 ret = curl_easy_perform(curl); 13 14 curl_easy_cleanup(curl); 15} 可用性Always</description></item><item><title>Go 十年</title><link>https://icorer.com/icorer_blog/posts/ten-years-of-go/</link><pubDate>Tue, 24 Dec 2019 13:18:18 +0800</pubDate><guid>https://icorer.com/icorer_blog/posts/ten-years-of-go/</guid><description>Russ Cox，代表Go团队
2019年11月8日
Happy birthday, Go!
这个周末，我们庆祝Go发布10周年，庆祝Go作为一种开源编程语言和构建现代网络软件的生态系统的10周年。
为了纪念这一时刻，Go gopher的创始人蕾妮·弗兰奇描绘了这一令人愉快的场景:
庆祝Go十周年让我回想起2009年11月上旬，那时我们正准备与世界分享Go。 我们不知道会有什么样的反应，也不知道是否有人会关心这种小小的语言。我希望，即使没有人最终使用Go，我们至少也会注意到一些好的想法，特别是Go的并发性和接口方法，它们可能会影响后续语言。
当人们对Go感到兴奋的时候，我研究了流行语言的历史，比如C、C++、Perl、Python和Ruby，考察了它们被广泛采用所花的时间。例如，在我看来，Perl似乎在上世纪90年代中后期就已经完全成形了，有了CGI脚本和web，但它是在1987年首次发布的。这一模式几乎适用于我所研究的每一种语言:一种新的语言要真正起飞，似乎需要大约十年的安静、稳定的改进和传播。
我在想:十年后会是什么样子?
今天，我们可以回答这个问题:Go无处不在，全世界至少有一百万开发者在使用它。
Go最初的目标是网络系统基础设施，也就是我们现在所说的云软件。如今，每个主要的云提供商都使用用Go编写的核心云基础设施，如Docker、Etcd、Istio、Kubernetes、Prometheus和Terraform;云计算基金会的大多数项目都是用Go编写的。无数的公司也在使用Go将他们自己的工作转移到云上，从从无到有的创业公司到现代化软件栈的企业。Go的应用范围也远远超出了它最初的云目标，从使用GoBot和TinyGo来控制微型嵌入式系统，到使用GRAIL进行大规模的大数据分析和机器学习来检测癌症，以及两者之间的一切。
所有这一切都说明，Go的成功超乎我们的想象。Go的成功不仅仅在于语言。它是关于语言，生态系统，特别是社区的合作。
在2009年，该语言是一个不错的主意，并带有一个实现的工作草图。 go命令不存在：我们运行了诸如6g的命令进行编译，并运行了6l的命令来链接二进制文件，这些命令使用makefiles自动执行。 我们在语句末尾键入分号。 整个程序在垃圾回收期间停止，然后努力利用两个内核。 Go只能在Linux和Mac，32位和64位x86和32位ARM上运行。
在过去的十年里，在全球Go开发人员的帮助下，我们已经将这个想法和草图发展成为一种富有成效的语言，它具有出色的工具、高质量的产品实现、最先进的垃圾收集器以及12个操作系统和10个体系结构支持。
任何编程语言都需要蓬勃发展的生态系统的支持。 开源版本是该生态系统的种子，但是从那时起，许多人贡献了自己的时间和才干，用出色的教程，书籍，课程，博客文章，播客，工具，集成以及可重复使用的Go来填充Go生态系统。 可通过go get导入的软件包。 没有这个生态系统的支持，Go永远不可能成功。
当然，生态系统需要蓬勃发展的社区的支持。 在2019年，全球有数十个Go会议，以及超过90个成员超过150个Go会议团体。GoBridge和Going Who Go通过指导，培训和会议奖学金帮助将新的声音带入Go社区。仅今年一年，他们就在社区成员教授和指导新加入者的研讨会上，教育了数百名来自传统代表性不足群体的人。
全球有超过一百万的Go开发人员，全球各地的公司都在寻求雇用更多的人。 实际上，人们经常告诉我们，学习Go帮助他们获得了技术行业的第一份工作。 最后，我们为Go感到最自豪的不是设计完善的功能或巧妙的代码，而是Go在这么多人的生活中产生的积极影响。我们的目标是创造一种语言，帮助我们成为更好的开发人员，我们很高兴Go帮助了这么多人。
作为＃GoTurns10，我希望每个人都花一点时间来庆祝Go社区以及我们所取得的一切。 代表Google的整个Go团队，感谢过去十年来加入我们的每个人。 让下一个更不可思议！
Original URL : https://blog.golang.org/10years</description></item><item><title>Curl-VS-Guzzle 性能测试</title><link>https://icorer.com/icorer_blog/posts/curl-vs-guzzle-performance-test/</link><pubDate>Fri, 22 Feb 2019 13:40:18 +0800</pubDate><guid>https://icorer.com/icorer_blog/posts/curl-vs-guzzle-performance-test/</guid><description>Curl-VS-Guzzle 性能测试这里项目围绕Curl 和 Guzzle这两个HTTP请求组件进行一些压力测试,看一下性能差距.我们围绕两个组件的连接复用情况来测试.(文章中会强调opcache的作用)
一. 测试阐述 测试curl和guzzle在连接复用情况下的性能差别 (guzzle不开启opcache) 测试curl和guzzle在连接复用情况下的性能差别 (guzzle开启opcache) 二. 性能测试过程2.1 测试条件 在相同的Nginx,PHP,LibCurl库环境 测试脚本包含curl对象的复用,每次测试请求执行10次外部http请求 2.2 Guzzle测试代码 1//GuzzleClient.php 2use \GuzzleHttp\Client; 3class GuzzleClient 4{ 5 protected static $guzzleClientConnection = null; 6 7 public static function getGuzzleClient($baseUrl, $persistent = true) 8 { 9 if (!$persistent || !self::$guzzleClientConnection) { 10 self::$guzzleClientConnection = new Client([&amp;#39;base_uri&amp;#39; =&amp;gt; $baseUrl]); 11 } 12 13 return self::$guzzleClientConnection; 14 } 15 16} 17 18//get_loop_simple.php 内部循环调用多次 19for ($i=0;$i&amp;lt;10;$i++){ 20 try { 21 //获取Client静态变量,复用curl单体 22 $client = GuzzleClient::getGuzzleClient(&amp;#34;http://127.</description></item><item><title>PHP-CURL-Guzzle-HTTP-连接复用内核原理</title><link>https://icorer.com/icorer_blog/posts/php-curl-guzzle-http-connection-reuse-kernel-principle/</link><pubDate>Fri, 22 Feb 2019 13:16:18 +0800</pubDate><guid>https://icorer.com/icorer_blog/posts/php-curl-guzzle-http-connection-reuse-kernel-principle/</guid><description>PHP-CURL连接复用内核原理0.写在前面PHP是一个时代的产物,它的底层支持是C语言,因此它在CPU密集型计算或者系统内核调用上有天生的优势,Zend引擎把PHP执行生命期分成了五个阶段1,这五个阶段并不是全部都能常驻进程,这种模式下,对于很多使用场景会造成不好的影响,比如网络IO.
对于网络IO中的HTTP请求 , 很多工程师使用 php-curl 系列函数 . 所以这篇文章将从内核角度讲解php如何支持curl请求的连接复用(这里的连接复用也是指在一个RINIT2&amp;ndash;&amp;gt;RSHUTDOWN3周期内复用).
1. PHP引擎借力CURL库函数PHP需要使用curl组件进行HTTP系列通信,因此它在底层需要curl有相关的支撑,所以curl首先需要在系统环境中被部署或者被编译,并对外部提供动态链接库文件,PHP通过调用curl相关的动态链接库函数来进行自己内核函数的实现过程.
多说一句,PHP并不一定需要curl才能完成http请求,因为php引擎中已经包含了socket完善的函数库,所以有些php扩展包支持curl和原生stream_socket(tcp)两种模式,例如:guzzle
2. PHP-CURL基础数据结构(php_curl结构体) 1147 typedef struct { 2148 php_curl_write *write; 3149 php_curl_write *write_header; 4150 php_curl_read *read; 5151 zval std_err; 6152 php_curl_progress *progress; 7153 #if LIBCURL_VERSION_NUM &amp;gt;= 0x071500 /* Available since 7.21.0 */ 8154 php_curl_fnmatch *fnmatch; 9155 #endif 10156 } php_curl_handlers; 11 12173 typedef struct { 13174 CURL *cp; //curl库 实体结构体 14175 php_curl_handlers *handlers; //header 头部 15176 zend_resource *res; //引擎资源指针 16177 struct _php_curl_free *to_free; 17178 struct _php_curl_send_headers header; 18179 struct _php_curl_error err; //错误码 19180 zend_bool in_callback; 20181 uint32_t* clone; 21182 } php_curl; 3.</description></item><item><title>PHP内核函数: microtime</title><link>https://icorer.com/icorer_blog/posts/php-kernel-function-analysis-microtime/</link><pubDate>Fri, 22 Feb 2019 13:04:18 +0800</pubDate><guid>https://icorer.com/icorer_blog/posts/php-kernel-function-analysis-microtime/</guid><description>microtime Description ¶
microtime ([ bool $get_as_float = FALSE ] ) : mixed
microtime() returns the current Unix timestamp with microseconds. This function is only available on operating systems that support the gettimeofday() system call.
source file:** /php-src/ext/standard/microtime.c**
Part-1 : 内核抛出定义1.1 源码185 /* {{{ proto mixed microtime([bool get_as_float]) 286 Returns either a string or a float containing the current time in seconds and microseconds */ 387 PHP_FUNCTION(microtime) 488 { 589 _php_gettimeofday(INTERNAL_FUNCTION_PARAM_PASSTHRU, 0); 690 } 791 /* }}} */ Part-2 : 源码分析2.</description></item><item><title>基于CMake构建标准GoLang编译和打包框架</title><link>https://icorer.com/icorer_blog/posts/build-standard-go-compilation-and-packaging-framework-based-on-cmake/</link><pubDate>Tue, 19 Feb 2019 14:32:18 +0800</pubDate><guid>https://icorer.com/icorer_blog/posts/build-standard-go-compilation-and-packaging-framework-based-on-cmake/</guid><description>##一. 背景描述
为了简化团队内部中间件的编译及打包和方便运维伙伴的线上环境部署过程 , 我们开始尝试使用标准的rpm安装包来进行线上的环境部署,虽然制作rpm安装包可以采用很多途径 , 但是我们选择采用CMake方式 , 采用这种方式的优点如下:
利用CMake 可以构建出很强大的自动编译系统. CMake在编译周期结束后,支持rpm , zip等格式的自动打包. 下面的内容从两个方面来阐述: 利用CMake 构建Go语言的自动编译环境 , 利用CMake 进行rpm包制作
二. 实现Go语言的通用CMake编译框架2.1 文件结构这里将构建一个具有通用性的Go语言工程编译环境,旨在为后续Go语言开发工程师,提供团队内部统一的构建基础环境, 首先我们来查看一下文件结构,文件结构的树形图如下:
在这个文件结构中,我们先阐述一下相关文件的作用:
CMakeLists.txt : 构建系统的总入口 cmake目录 : 这个目录存储构建系统的子功能模块 cmd : 这个目录是一个功能单元的样例环境, 这里的CMakeLists.txt 被根CMakeList 加载. 2.2 重要文件描述上面的工程结构,保障了CMake工程的结构化清晰,这里将对几个重要文件做详细阐述
2.2.1 CMakeLists.txt这个文件是CMake工程的总入口 , 它负责的工作包括:
加载cmake子目录下的子功能单元 定义Go工程的相关工程属性: 工程名, 工程版本号 加载go语言编译器 加载各个子编译体的源码目录 加载rpm , zip 等打包模块 2.2.2 CMakeDetermineGoCompiler.cmake这个文件Go语言编译器的总入口 , 它负责的工作包括:
在操作系统环境中寻找Go语言编译器 加载Go编译器参数 拷贝必要的编译配置文件 ####　2.2.3 golang.cmake
这个文件是在CMakeDetermineGoCompiler.cmake文件基础上实现了必要的Go代码编译函数,主要功能函数包括:
go get 支持 : 为编译所需的外部包的引入提供自动加载功能 编译单体程序 : 编译指定路径下的go源代码,生成单体程序体 2.</description></item><item><title>IO读取缓冲器-BufReader</title><link>https://icorer.com/icorer_blog/posts/io-read-buffer-bufreader/</link><pubDate>Thu, 03 Jan 2019 16:59:18 +0800</pubDate><guid>https://icorer.com/icorer_blog/posts/io-read-buffer-bufreader/</guid><description>一. IO问题思考IO读取缓冲器,顾名思义就是针对系统的IO读取操作添加一层缓冲层,有这层缓冲层到底有啥好处呢?针对这个问题,我先问大家以下几个问题.
对于IO读取操作,无论针对的是对象,还是针对网络,每次IO操作均需要陷入内核调用,频繁内核调用会严重影响性能,请问有没有什么办法优化这部分? 针对网络IO读取过程,网络时好时坏,如何让网络IO能够发挥最大的性能潜力,在网络好的时候抓紧多读,在网络差的时候适当少读? 对于文件读取,和网络短连接读取,我们可以很快的根据EOF来结束io连接,但是对于网络长连接,我们无法即使获取到IO的EOF事件,我们该如何避免数据包读取过程的最终状态判断造成的延时问题? 如何提高文件读取,网络读取的内存使用率? 针对上面三个问题,我们均可以使用IO读取缓冲器来解决.
二. 无IO缓冲器IO无用户态缓冲器下,[数据源]和[数据接收端]这两方之间通过程序语言提供的IO API进行数据通信,这种通信模式图如下:
从上图可以看到
三. 缓冲器作用缓冲器建立在传统IO对象上,在传统的IO操作基础上,我们不立刻把读取到的数据传达给调用层代码,而是放进内存缓冲区,并启动针对缓冲区的两个指针(写入指针,读取指针).
相关的模型图如下:</description></item><item><title>开源: 高性能网络监听库-NetHandle</title><link>https://icorer.com/icorer_blog/posts/open-source-high-performance-network-monitoring-library-nethandle/</link><pubDate>Wed, 02 Jan 2019 13:39:18 +0800</pubDate><guid>https://icorer.com/icorer_blog/posts/open-source-high-performance-network-monitoring-library-nethandle/</guid><description>NetHandle这是一个库,方便构建高性能TCP服务端应用程序,站在Go语言的巨人肩膀上
项目地址: https://github.com/gitsrc/NetHandle
一. 特点 高性能,低资源消耗 非常简单易用的开发接口 支持众多协议,TCP,UDP,UNIX 二. 安装go get -u github.com/gitsrc/NetHandle
三. 性能测试:3.1 50*10000 (50线程 X 10000请求) 3.2 50*20000 (50线程 X 20000请求) 3.3 100*10000 (100线程 X 10000请求) 四. 样例代码:使用这个库的时候,只需要自定义简单的回调函数,即可构造出性能强悍的网络监听.
1package main 2 3import ( 4 &amp;#34;fmt&amp;#34; 5 &amp;#34;github.com/gitsrc/NetHandle&amp;#34; 6 &amp;#34;log&amp;#34; 7 &amp;#34;sync&amp;#34; 8) 9 10var addrTcp = &amp;#34;127.0.0.1:10000&amp;#34; 11 12func main() { 13 log.SetFlags(log.Lshortfile | log.LstdFlags) 14 15 var mu sync.RWMutex 16 count := 0 17 go log.Printf(&amp;#34;started server at %s&amp;#34;, addrTcp) 18 19 err := NetHandle.</description></item><item><title>源码阅读：YAF框架系列文章(3) - (yaf_application.c)</title><link>https://icorer.com/icorer_blog/posts/source-code-reading-yaf-framework-series-articles-3-yaf_application.c/</link><pubDate>Thu, 22 Nov 2018 15:33:18 +0800</pubDate><guid>https://icorer.com/icorer_blog/posts/source-code-reading-yaf-framework-series-articles-3-yaf_application.c/</guid><description>这个文件主要围绕Yaf_Application类的注册，这里，按照倒叙的方式来进行讲解。
一、注册yaf_application类
1YAF_STARTUP_FUNCTION(application) { 2//定义一个zend_class_entry实例变量 3 zend_class_entry ce; 4 5/* 初始化一个CLASS ENTRY 6#define YAF_INIT_CLASS_ENTRY(ce, name, name_ns, methods) \ 7 if(YAF_G(use_namespace)) { \ 8 INIT_CLASS_ENTRY(ce, name_ns, methods); \ 9 } else { \ 10 INIT_CLASS_ENTRY(ce, name, methods); \ 11 } 12*/ 13 YAF_INIT_CLASS_ENTRY(ce, &amp;#34;Yaf_Application&amp;#34;, &amp;#34;Yaf\\Application&amp;#34;, yaf_application_methods); 14 15 // https://src.icorer.com/xref/php-src/Zend/zend_API.c#2752 16 //注册一个类到内核类表中 17 yaf_application_ce = zend_register_internal_class_ex(&amp;amp;ce, NULL); 18 //修改类属性为终极类 19 yaf_application_ce-&amp;gt;ce_flags |= ZEND_ACC_FINAL; 20 21 //声明一个属性定义，为Protected类型 22 zend_declare_property_null(yaf_application_ce, 23 ZEND_STRL(YAF_APPLICATION_PROPERTY_NAME_CONFIG), ZEND_ACC_PROTECTED); 24 zend_declare_property_null(yaf_application_ce, 25 ZEND_STRL(YAF_APPLICATION_PROPERTY_NAME_DISPATCHER), ZEND_ACC_PROTECTED); 26 27 //声明一个NULL元素，为static protected类型 28 zend_declare_property_null(yaf_application_ce, 29 ZEND_STRL(YAF_APPLICATION_PROPERTY_NAME_APP), ZEND_ACC_STATIC | ZEND_ACC_PROTECTED); 30 zend_declare_property_null(yaf_application_ce, 31 ZEND_STRL(YAF_APPLICATION_PROPERTY_NAME_MODULES), ZEND_ACC_PROTECTED); 32 //声明一个布尔类型的元素，为protected类型 33 zend_declare_property_bool(yaf_application_ce, 34 ZEND_STRL(YAF_APPLICATION_PROPERTY_NAME_RUN), 0, ZEND_ACC_PROTECTED); 35 //声明一个字符串类型的元素 ， 为protected类型 36 zend_declare_property_string(yaf_application_ce, 37 ZEND_STRL(YAF_APPLICATION_PROPERTY_NAME_ENV), YAF_G(environ_name), ZEND_ACC_PROTECTED); 38 //声明一个长整数类型的元素，为protected类型 39 zend_declare_property_long(yaf_application_ce, 40 ZEND_STRL(YAF_APPLICATION_PROPERTY_NAME_ERRNO), 0, ZEND_ACC_PROTECTED); 41 zend_declare_property_string(yaf_application_ce, 42 ZEND_STRL(YAF_APPLICATION_PROPERTY_NAME_ERRMSG), &amp;#34;&amp;#34;, ZEND_ACC_PROTECTED); 43 44 return SUCCESS; 45} 二、添加类方法 上面讲解了创建一个类的过程，但是类中还有很多方法，通过yaf_application_methods方法集进行管理，具体对于函数的添加代码如下。</description></item><item><title>高级编程：PHP扩展的 INI 配置文件操作</title><link>https://icorer.com/icorer_blog/posts/ini-configuration-file-manipulation-for-php-extensions/</link><pubDate>Thu, 22 Nov 2018 10:24:18 +0800</pubDate><guid>https://icorer.com/icorer_blog/posts/ini-configuration-file-manipulation-for-php-extensions/</guid><description>Extension INI Entries (扩展INI配置项)Defining php.ini directives (i.e., INI entries) in an extension is easy. Most of the work involves setting up the global struct explained earlier in Section 14.10.3 Each entry in the INI structure is a global variable in the extension and thus has an entry in the global struct and is accessed using FOO_G(my_ini_setting). For the most part you can simply comment out the indicated sections in the skeleton created by ext_skel to get a working INI directive, but we will walk through it here anyway.</description></item><item><title>源码阅读：YAF框架系列文章(2) - (yaf.c)</title><link>https://icorer.com/icorer_blog/posts/source-code-reading-yaf-framework-series-articles-2-yaf.c/</link><pubDate>Thu, 22 Nov 2018 10:04:18 +0800</pubDate><guid>https://icorer.com/icorer_blog/posts/source-code-reading-yaf-framework-series-articles-2-yaf.c/</guid><description>这个文件是yaf框架的整体组成框架文件，因为yaf的设计思路是模块化的，因此在这个文件中进行了总体整合。整合的思路分为以下几个部分。
INI配置文件的解析 注册系统使用的常量 注册各个模块 对扩展模块的各个生命期做拦截监控 注册扩展模块 一、INI配置文件解析功能
在php_yaf.h文件中对于全局变量进行了定义工作，随后在yaf.c中进行了声明工作，声明操作 ZEND_DECLARE_MODULE_GLOBALS(yaf); ，声明操作之后，并在PHP_GINIT_FUNCTION钩子函数期进行了全局变量的初始化工作，框架进行了配置文件的加载过程，配置文件的操作定义如下：
1/** {{{ PHP_INI_MH(OnUpdateSeparator) 2 */ 3PHP_INI_MH(OnUpdateSeparator) { 4 YAF_G(name_separator) = ZSTR_VAL(new_value); 5 YAF_G(name_separator_len) = ZSTR_LEN(new_value); 6 return SUCCESS; 7} 8/* }}} */ 9 10/** {{{ PHP_INI 11 */ 12PHP_INI_BEGIN() 13 STD_PHP_INI_ENTRY(&amp;#34;yaf.library&amp;#34;, &amp;#34;&amp;#34;, PHP_INI_ALL, OnUpdateString, global_library, zend_yaf_globals, yaf_globals) 14 STD_PHP_INI_BOOLEAN(&amp;#34;yaf.action_prefer&amp;#34;, &amp;#34;0&amp;#34;, PHP_INI_ALL, OnUpdateBool, action_prefer, zend_yaf_globals, yaf_globals) 15 STD_PHP_INI_BOOLEAN(&amp;#34;yaf.lowcase_path&amp;#34;, &amp;#34;0&amp;#34;, PHP_INI_ALL, OnUpdateBool, lowcase_path, zend_yaf_globals, yaf_globals) 16 STD_PHP_INI_BOOLEAN(&amp;#34;yaf.use_spl_autoload&amp;#34;, &amp;#34;0&amp;#34;, PHP_INI_ALL, OnUpdateBool, use_spl_autoload, zend_yaf_globals, yaf_globals) 17 STD_PHP_INI_ENTRY(&amp;#34;yaf.</description></item><item><title>源码阅读：YAF框架系列文章(1) - (php_yaf.h)</title><link>https://icorer.com/icorer_blog/posts/source-code-reading-yaf-framework-series-articles-1-php_yaf.h/</link><pubDate>Wed, 21 Nov 2018 14:30:18 +0800</pubDate><guid>https://icorer.com/icorer_blog/posts/source-code-reading-yaf-framework-series-articles-1-php_yaf.h/</guid><description>这个文件的核心使命是构建yaf基础定义，这部分定义主要包括
对于内核函数的宏定义 对于框架变量类型的宏定义 对于框架所使用的全局变量进行定义 一、对于内核函数进行宏定义
1#define YAF_STARTUP_FUNCTION(module) ZEND_MINIT_FUNCTION(yaf_##module) 2#define YAF_RINIT_FUNCTION(module) ZEND_RINIT_FUNCTION(yaf_##module) 3#define YAF_STARTUP(module) ZEND_MODULE_STARTUP_N(yaf_##module)(INIT_FUNC_ARGS_PASSTHRU) 4#define YAF_SHUTDOWN_FUNCTION(module) ZEND_MSHUTDOWN_FUNCTION(yaf_##module) 5#define YAF_SHUTDOWN(module) ZEND_MODULE_SHUTDOWN_N(yaf_##module)(INIT_FUNC_ARGS_PASSTHRU) 这个部分表现了yaf框架的模块化设计，yaf通过宏定义对于模块相关ZEND函数进行了封装，每个模块都将有自己的模块加载、关闭函数。例如YAF_STARTUP_FUNCTION(module) 的宏定义展开形式就是 zm_startup_yaf_module(int type, int module_number)
二、对于框架自定义变量类型进行定义
1#define yaf_application_t zval 2#define yaf_view_t zval 3#define yaf_controller_t zval 4#define yaf_request_t zval 5#define yaf_router_t zval 6#define yaf_route_t zval 7#define yaf_dispatcher_t zval 8#define yaf_action_t zval 9#define yaf_loader_t zval 10#define yaf_response_t zval 11#define yaf_config_t zval 12#define yaf_registry_t zval 13#define yaf_plugin_t zval 14#define yaf_session_t zval 15#define yaf_exception_t zval 三、对内核中将用到的函数做声明</description></item><item><title>设计文档：PulseFlow_IPC_Backend</title><link>https://icorer.com/icorer_blog/posts/design-document-pulseflow_ipc_backend/</link><pubDate>Wed, 22 Aug 2018 21:54:18 +0800</pubDate><guid>https://icorer.com/icorer_blog/posts/design-document-pulseflow_ipc_backend/</guid><description>PulseFLow还有一部分功能是集中在信息后端的，当PHP引擎发送信息给后端程序后，后端程序再把信息进行组装，发给下一级程序。
一 . 组成部分后端程序，分为以下几个部分：
配置中心：（配置文件 + 配置解析器）（采用ini文件配置格式）。
进程管理器：维持进程池，保持进程池的存活量。
信息发送： 信息组装 + 信息发送（UDP发送）
二. 工作流程2.1 总体流程图 2.2 系统模型（进程池模型） 后端组件采用进程池模型，主程序启动时，首先读取配置文件中关于进程池大小的配置选项，然后启动相关数量的子工作进程。
随后主进程进入稳定性极高的进程池监控流程，如果拦截到子进程有挂掉的情况发生，读取挂掉的状态并在相应的进程池位置开辟新的工作子进程。
通过进程池可以大大提高进程读取内核消息队列的效率，通过进程池管理程序可以大大提高整体后端程序的稳定性。
2.3 功能分配1. 主进程负责【管理进程池】，负责【创建可用的内核消息队列】。2. 工作子进程负责 【监控内核消息队列】&amp;mdash;&amp;gt;【读取消息】&amp;mdash;&amp;gt;【组装信息】&amp;mdash;&amp;gt;【UDP发送下游】</description></item><item><title>设计文档: PulseFLow PHP性能监控插件</title><link>https://icorer.com/icorer_blog/posts/design-documentation-pulseflow-php-performance-monitoring-plugin/</link><pubDate>Fri, 17 Aug 2018 13:18:18 +0800</pubDate><guid>https://icorer.com/icorer_blog/posts/design-documentation-pulseflow-php-performance-monitoring-plugin/</guid><description>一. 背景描述随着公司PHP项目体的不断增大，随着不同工程师的功能迭代，如何有效获取PHP项目的执行性能，对于系统整体模块显得异常重要，PulseFlow是一个公司团队内部自研地性能跟踪扩展，它可以在程序员无感知的情况下有效跟踪每一个函数的执行效率，主要分析CPU时间消耗、内存大小消耗，执行次数这三个指标，下面我们将从 PHP生命期 到 组件设计 到 性能优化这三个方面来进行阐述组件。
二 . 插件和 PHP生命期PHP生命周期通常包括 MI（模块初始化）、RI（请求初始化）、RS（请求终止）、MS（模块终止） 这四个步骤，这四个部分使我们能够进行功能渗透的生命期子过程。在MI阶段会包含INI配置文件的解析，在RI阶段会针对每一个CGI请求进行请求初始化操作，在RS阶段会针对每一个请求的关闭进行相关功能拦截。并不是每一次执行PHP均要经历这四个阶段，在CLI模式下，会完整经历这四个阶段，在PHP-FPM这种类CGI模式下，为了提高请求性能，并不会经历过全部阶段，它会着重经历RI、RS阶段。
了解了PHP的生命期轮廓后，我们绘制了下图阐述大概执行流程所属的生命期阶段。
三. 插件和ZEND引擎在上述的PHP生命周期阶段内，我们可以在不同的阶段分块插件的功能，其次，我们还需要和ZEND引擎打交道，因为ZEND引擎是真正的执行者，我们目前需要托管他们的 zend_execute_ex 内核函数，这个内核函数就是C语言的函数指针，这个内核函数顾名思义就是PHP的内核执行函数。
为了阐述方便，我们使用一个执行流程图，来看一下插件该如何拦截ZEND引擎的执行流程。 三. 开始造轮子3.1 插件流程分析首先，我们需要构建插件的执行流程，及各个部分的信息传送关系，我们目前把插件分为两部分，一部分是PHP扩展，用于在PHP生命周期内来进行性能拦截，这部分信息通常存储于 系统进程堆区 或者 系统进程静态区域，第二部分是后台数据转发程序，它负责从信息通道里读取PHP扩展写入的信息，并转发给相应的下一级程序，相关流程图如下。 3.2 环境选择（系统组件选择）这一步我们选择相应的环境，或者称之为系统组件选择，我们在选择相应组件时根据插件各个执行周期来进行选择。
3.2.1 PHP引擎环境 （PHP7+）首先PHP引擎我们选择7.0以上，因为 PHP7 与 PHP5 的内核数据结构差距甚大，目前针对PHP7，后面会移植代码覆盖PHP5版本。
3.2.2 插件语言 （C）虽然现在编写PHP扩展可以使用Go语言、zephir语言、但是为了和原PHP内核及Linux操作系统进行最好性能交互，我们选择C语言进行研发。
3.2.3 信息队列（System V 消息队列）在3.1中，我们提及了一个很重要的组件，并用红色进行了标记，PHP扩展和后台信息转发程序 如何 沟通？哪一条路最快？
为了选择这条信息通路，我们做了大量实验，覆盖面积包括TCP、unix domain socket、zeromq、nanomsg、共享内存、posix 内核消息队列、system V 内核消息队列，目前最快的是共享内存，其次是system V 和 posix 内核队列。
共享内存虽然是最快的，但是我们目前针对的模型是 多写、多读，为了不对PHP-FPM 内存 和 对系统内存能够更好更有力管理，在第一版中我们将采用system V内核队列，但是我们也已经开放了 共享内存版本的分支 和 给予epoll模型的 posix 内核队列 代码分支，这两个代码分值中均写好模型代码，在后面阶段将会一步步融入主线版本。
为什么选择 system V 队列？ 首先system V内核队列在 Linux Kernel 2.</description></item><item><title>检测并分析PHP扩展的内存泄露</title><link>https://icorer.com/icorer_blog/posts/detect-and-analyze-memory-leaks-in-php-extensions/</link><pubDate>Tue, 31 Jul 2018 09:11:18 +0800</pubDate><guid>https://icorer.com/icorer_blog/posts/detect-and-analyze-memory-leaks-in-php-extensions/</guid><description>1. 背景描述基于C/C++开发的程序，内存管理是很大程度上的工作，我们在这篇文章里来给大家讲解一下如何监控程序体可能存在的内存泄露。
工欲善其事必先利其器，这里选择使用 Valgrind 工作来进行内存监控。http://valgrind.org/
2. Valgrind工具安装1 git clone git://sourceware.org/git/valgrind.git 2 ./autogen.sh 3 ./configure --prefix=/usr/local/valgrind 4 make 5 make install 3. 测试命令样例1valgrind --tool=memcheck --leak-check=full --show-reachable=yes --trace-children=yes php PulseFlow.php 4. 一次针对PHP扩展的内存泄露检测过程针对已经开源的 PulseFLow 插件，今天我们将进行相关的内存泄露检测，由于我们是对PHP扩展进行泄露检查，所以：
第一步，需要给PHP打开debug 编译参数，相关的编译参数如 ./configure --enable-debug 。
第二步，我们需要关闭zend 内存管理 ，添加相关的环境变量 export USE_ZEND_ALLOC=0 export ZEND_DONT_UNLOAD_MODULES=1 第三步，我们执行相关命令
1ZEND_DONT_UNLOAD_MODULES=1 USE_ZEND_ALLOC=0 valgrind --tool=memcheck --leak-check=full --show-reachable=yes --trace-children=yes php PulseFlow.php 第四步，查看报告，获得总体报告如下
1==20296== LEAK SUMMARY: 2==20296== definitely lost: 0 bytes in 0 blocks 3==20296== indirectly lost: 0 bytes in 0 blocks 4==20296== possibly lost: 0 bytes in 0 blocks 5==20296== still reachable: 75,936 bytes in 29 blocks 6==20296== suppressed: 0 bytes in 0 blocks 5.</description></item><item><title>开源项目：PulseFLow 性能跟踪扩展</title><link>https://icorer.com/icorer_blog/posts/open-source-project-pulseflow-performance-tracking-extension/</link><pubDate>Wed, 25 Jul 2018 13:48:18 +0800</pubDate><guid>https://icorer.com/icorer_blog/posts/open-source-project-pulseflow-performance-tracking-extension/</guid><description>背景描述随着公司PHP项目体的不断增大，随着不同工程师的功能迭代，如何有效获取PHP项目的执行性能，对于系统整体模块显得异常重要，PulseFlow是一个性能跟踪扩展，它可以在程序员无感知的情况下有效跟踪每一个函数的执行效率，主要分析CPU时间消耗、内存大小消耗，这个组件除了能够快速记录每个函数体的性能信息，还具备一系列的发送机制，主要包括共享内存队列（System V 和 Posix）、UDP、Unix Domain Socket 等模式。
编译安装此为PHP扩展，按照正常的扩展安装，我们需要执行以下几步操作：
git clone https://github.com/gitsrc/PulseFlow.git 进入源码目录 phpize ./configure &amp;ndash;with-php-config= （ php-config文件路径） CFLAGS=&amp;rsquo;-g -lrt&amp;rsquo; CXXFLAGS=&amp;rsquo;-lrt' make make install 编译特别注意由于在扩展中使用了 posix 共享内存队列，所以我们编译时需要引入lrt库，上面在configure过程中附加的 CFLAGS 和 CXXFLAGS 参数用来给Makefile中的相应字段添加 -lrt，最终构造完后的Makefile对应配置应该为：
1CFLAGS = -g -lrt -O0 2 3CXXFLAGS = -lrt -g -O0 设计点1：PHP INI 配置选项PulseFlow由于是一个基于C语言的PHP扩展，为了保持程序体的扩展性，配置选项一律从php.ini文件中读取，本节将描述所有与扩展程序有关系的配置信息。
1.1 扩展功能开关参数 （PulseFlow.enabled）1.1.1 参数介绍这个参数是插件的功能开关，属于布尔类型，有效参数如下，默认 false：
true：开启 false：关闭 1.2 日志功能开关参数 （PulseFlow.debug）1.2.1 参数介绍这个参数是控制插件是否向页面输出调试信息，有效参数如下，默认 false：
true：开启 false：关闭 1.3 禁止跟踪函数列表 （PulseFlow.disable_trace_functions）1.3.1 参数介绍这个参数是一个逗号分隔的字符串，代表一系列函数列表，这个函数列表内的函数不进行性能跟踪，默认空字符串。
配置样例：PulseFlow.disable_trace_functions = &amp;ldquo;getLoader,findFile,loadClassLoader,getInitializer,findFileWithExtension,&amp;rdquo;
1.4 禁止跟踪类列表 （PulseFlow.disable_trace_class）1.4.1 参数介绍这个参数是一个逗号分隔的字符串，代表一系列类列表，这个类列表内的类不进行性能跟踪，默认空字符串。</description></item><item><title>编程笔记：C动态连接库编程</title><link>https://icorer.com/icorer_blog/posts/programming-notes-c-dynamic-link-library-programming/</link><pubDate>Tue, 24 Jul 2018 09:15:18 +0800</pubDate><guid>https://icorer.com/icorer_blog/posts/programming-notes-c-dynamic-link-library-programming/</guid><description>动态链接库，可以方便程序体扩展功能、更新组件，相对于编译时连接，具有更大的灵活性，下面我们从三个方面来讲解一个案例。
库函数定义在这里，我们首先定义一个简单的加法函数。
1#include &amp;lt;stdio.h&amp;gt; 2 3int add(int a,int b){ 4 return a+b; 5} 动态链接库编译我们通过编译命令对于源码文件进行编译，在linux系统中编译为so文件。
1gcc -shared -fPIC ./io.c -o add.so 编译参数解析 -shared该选项指定生成动态连接库（让连接器生成T类型的导出符号表，有时候也生成弱连接W类型的导出符号），不用该标志外部程序无法连接，相当于一个可执行文件。
-fPIC：表示编译为位置独立的代码，不用此选项的话编译后的代码是位置相关的所以动态载入时是通过代码拷贝的方式来满足不同进程的需要，而不能达到真正代码段共享的目的。
测试动态链接库是否可用编写测试代码
1#include &amp;lt;stdio.h&amp;gt; 2#include &amp;lt;dlfcn.h&amp;gt; 3 4int main() { 5 void *handle = dlopen(&amp;#34;./add.so&amp;#34;, RTLD_LAZY); //打开动态链接库文件 6 char *dlerr = dlerror(); //跟踪动态链接库错误 7 8 if (handle == NULL || dlerr != NULL) { 9 printf(&amp;#34;%s\n&amp;#34;, dlerr); 10 return -1; 11 } 12 13 int (*add)(int, int) = dlsym(handle, &amp;#34;add&amp;#34;); //加载动态链接库函数 转换为函数指针 14 printf(&amp;#34;%d\n&amp;#34;, add(1, 2)); //根据函数指针调用动态链接库函数 15 return 0; 16} 编译测试代码时，需要链接dl库 ，编译命令如下：</description></item><item><title>阅读笔记：动态内存分配 + 指针小结</title><link>https://icorer.com/icorer_blog/posts/reading-notes-dynamic-memory-allocation-+-pointer-summary/</link><pubDate>Mon, 23 Jul 2018 17:36:18 +0800</pubDate><guid>https://icorer.com/icorer_blog/posts/reading-notes-dynamic-memory-allocation-+-pointer-summary/</guid><description>1.什么是内存的动态分配 2.怎样建立内存分配 3. 指针小结</description></item><item><title>阅读笔记：指针数组和多重指针</title><link>https://icorer.com/icorer_blog/posts/reading-notes-pointer-arrays-and-multiple-pointers/</link><pubDate>Mon, 23 Jul 2018 15:58:18 +0800</pubDate><guid>https://icorer.com/icorer_blog/posts/reading-notes-pointer-arrays-and-multiple-pointers/</guid><description>1. 什么是指针数组一个数组，其元素均为指针类型的数据，被成为指针数组。也就是说，指针数组中的每一个元素都存放一个地址，相当于一个指针变量。下面定义一个指针数组。 ##1.1 样例分析 2. 指向指针的指针</description></item><item><title>阅读笔记：指针数组和多重指针</title><link>https://icorer.com/icorer_blog/posts/reading-notes-c-language-function-pointer/</link><pubDate>Mon, 23 Jul 2018 13:51:18 +0800</pubDate><guid>https://icorer.com/icorer_blog/posts/reading-notes-c-language-function-pointer/</guid><description>1.指向函数的指针1.1什么是指针函数 1.2 怎样定义指向函数的指针变量定义指向函数的指针变量一般形式为： 例如 int (*p)(int a, int b); 这里的 “类型名” 是指函数返回值的类型。
1.2.1说明 定义指向函数的指针变量，并不意味着这个指针变量可以指向任何函数，它只能指向在定义时指定的类型的函数。在同一个程序中，一个指针变量可以先后指向同类型的不同函数。
在给指针变量赋值时，只需给出函数名，而不需要给出参数，如果带上参数，会让编译器误认为正在调用函数。
对指向函数的指针变量不能进行加减运算、因为这些云端是没有意义的。
通过函数名，只能调用一个函数，而通过函数指针变量，便可以实现动态调用不同的函数。
1.3 使用函数指针调用函数如果想调用一个函数，除了使用函数名进行调用之外，还可以使用指向此函数的函数指针变量进行调用，简单样例如下。
1#include &amp;lt;stdio.h&amp;gt; 2 3int main() { 4 int (*p)(int a, int b); 5 int add(int a, int b); //函数声明 6 p = add; //函数指针变量赋值 or p = &amp;amp;add; 7 int a = 100, b = 200; 8 int c = (*p)(a, b); //函数指针调用 9 printf(&amp;#34;%d\n&amp;#34;, c); 10 11 return 0; 12} 13 14int add(int a, int b) { 15 return a + b; 16} 1.</description></item><item><title>环境搭建：CLion 搭建 PHP 扩展开发环境</title><link>https://icorer.com/icorer_blog/posts/clion-builds-a-php-extension-development-environment/</link><pubDate>Tue, 10 Jul 2018 10:06:18 +0800</pubDate><guid>https://icorer.com/icorer_blog/posts/clion-builds-a-php-extension-development-environment/</guid><description>#1. PHP扩展代码框架搭建 此处，可以参考本博客原来的文章进行框架代码搭建。 【PHP扩展开发1：代码框架搭建】
2. 从源文件导入CLion工程 点击clion菜单栏File -&amp;gt; Import Project 选择扩展目录 -&amp;gt; 选择项目所要的文件 -&amp;gt; 点击确认 因为clion是由CMakeList.txt文件进行，所以当导入后clion会自动生成基本的配置文件。
#3. 修改CMakeList.txt 加入库文件索引等，样例配置如下。
1cmake_minimum_required(VERSION 3.10) 2project(PulseFlow C) 3 4set(CMAKE_C_STANDARD 11) 5 6set(SOURCE_FILES 7 php_PulseFlow.h 8 PulseFlow.c) 9 10add_executable(PulseFlow ${SOURCE_FILES}) 11 12add_custom_target(makefile COMMAND make &amp;amp;&amp;amp; sudo make install WORKING_DIRECTORY ${PROJECT_SOURCE_DIR}) 13 14 15include_directories(.) 16set(PHP_SOURCE /usr/local/php/include/php) 17 18include_directories(${PHP_SOURCE}/main) 19include_directories(${PHP_SOURCE}/Zend) 20include_directories(${PHP_SOURCE}/sapi) 21include_directories(${PHP_SOURCE}/pear) 22include_directories(${PHP_SOURCE}) #4. 调试代码
4.1 在CMakeList.txt文件中添加编译命令1add_custom_target(makefile COMMAND make &amp;amp;&amp;amp; sudo make install WORKING_DIRECTORY ${PROJECT_SOURCE_DIR}) 4.2 添加运行配置 (很重要 一定要选择 makefile编译)</description></item><item><title>编程笔记：C语言回调函数</title><link>https://icorer.com/icorer_blog/posts/programming-notes-c-language-callback-function/</link><pubDate>Mon, 09 Jul 2018 16:56:18 +0800</pubDate><guid>https://icorer.com/icorer_blog/posts/programming-notes-c-language-callback-function/</guid><description>在计算机程序设计中，回调函数，或简称回调（Callback 即call then back 被主函数调用运算后会返回主函数），是指通过函数参数传递到其它代码的，某一块可执行代码的引用。这一设计允许了底层代码调用在高层定义的子程序。 假设我们要使用一个排序函数来对数组进行排序，那么在主程序(Main program)中，我们先通过库，选择一个库排序函数(Library function)。但排序算法有很多，有冒泡排序，选择排序，快速排序，归并排序。同时，我们也可能需要对特殊的对象进行排序，比如特定的结构体等。库函数会根据我们的需要选择一种排序算法，然后调用实现该算法的函数来完成排序工作。这个被调用的排序函数就是回调函数(Callback function)。
结合这幅图和上面对回调函数的解释，我们可以发现，要实现回调函数，最关键的一点就是要将函数的指针传递给一个函数(上图中是库函数)，然后这个函数就可以通过这个指针来调用回调函数了。注意，回调函数并不是C语言特有的，几乎任何语言都有回调函数。在C语言中，我们通过使用函数指针来实现回调函数。那函数指针是什么？不着急，下面我们就先来看看什么是函数指针。
什么是函数指针函数指针也是一种指针，只是它指向的不是整型，字符型而是函数。在C中，每个函数在编译后都是存储在内存中，并且每个函数都有一个入口地址，根据这个地址，我们便可以访问并使用这个函数。函数指针就是通过指向这个函数的入口，从而调用这个函数。
函数指针的使用函数指针的定义函数指针虽然也是指针，但它的定义方式却和其他指针看上去很不一样，我们来看看它是如何定义的：
1/* 方法1 */ 2void (*p_func)(int, int, float) = NULL; 3 4/* 方法2 */ 5typedef void (*tp_func)(int, int, float); 6tp_func p_func = NULL; 这两种方式都是定义了一个指向返回值为 void 类型，参数为 (int, int, float) 的函数指针。第二种方法是为了让函数指针更容易理解，尤其是在复杂的环境下；而对于一般的函数指针，直接用第一种方法就行了。 如果之前没见过函数指针，可能会觉得函数指针的定义比较怪，为什么不是 void ()(int, int, float)*p_func 而是 void (*p_func)(int, int, float) 这种形式？这个问题我也不知道，也没必要纠结，花点时间理解下它与普通指针的区别，实在不行就先记住它的形式。
函数指针的赋值在定义完函数指针后，我们就需要给它赋值了我们有两种方式对函数指针进行赋值：
1void (*p_func)(int, int, float) = NULL; 2p_func = &amp;amp;func1; 3p_func = func2; 上面两种方法都是合法的，对于第二种方法，编译器会隐式地将 func_2 由 void ()(int, int, float) 类型转换成 void (*)(int, int, float) 类型，因此，这两种方法都行。</description></item><item><title>源码阅读：PHP TSRM 线程安全管理器</title><link>https://icorer.com/icorer_blog/posts/source-code-reading-php-tsrm-thread-safety-manager/</link><pubDate>Sun, 08 Jul 2018 23:49:18 +0800</pubDate><guid>https://icorer.com/icorer_blog/posts/source-code-reading-php-tsrm-thread-safety-manager/</guid><description>TSRM 简介在查看php源代码或开发php扩展的时候，会出现大量 TSRMLS_ 宏字样在函数参数的位置，这些宏就是Zend为线程安全机制所提供的（Zend Thread Safety，简称ZTS）用于保证线程的安全 , 是防止多线程环境下以模块的形式加载并执行PHP解释器，导致内部一些公共资源读取错误，而提供的一种解决方法。
什么时候需要用 TSRM只要服务器是多线程环境并且PHP以模块的形式提供，那么就需要TSRM启用，例如apache下的 worker 模式(多进程多线程)环境，这种情况就必须要使用线程安全版本的PHP，也就是要启用TSRM , 在Linux下是编译PHP的时候指定是否开启TSRM、windows下是提供线程安全版本和非线程安全版本的PHP。
PHP 如何实现 TSRM正常多线程环境下操作公共的资源都是加上互斥锁，而PHP没有选择加锁，因为加锁可能多少会有些性能损耗，PHP的解决方法是为每一个线程都copy一份当前PHP内核所有的公共资源过来，每个线程指向自己的公共资源区，互不影响，各操作各的公共资源。
公共资源是什么就是各种各样的 struct 结构体 定义。
#TSRM数据结构
tsrm_tls_entry结构体tsrm_tls_entry 线程结构体、每个线程都有一份该结构体。
1typedef struct _tsrm_tls_entry tsrm_tls_entry; 2struct _tsrm_tls_entry { 3 void **storage; 4 int count; 5 THREAD_T thread_id; 6 tsrm_tls_entry *next; 7} 8static tsrm_tls_entry **tsrm_tls_table = NULL //线程指针表头指针 9static int tsrm_tls_table_size; //当前线程结构体数量 ###字段说明
void **storage ：资源指针、就是指向自己的公共资源内存区 int count : 资源数、就是 PHP内核 + 扩展模块 共注册了多少公共资源 THREAD_T thread_id ： 线程id tsrm_tls_entry *next：指向下一个线程指针，因为当前每一个线程指针都存在一个线程指针表里（类似于hash表），这个next可以理解成是hash冲突链式解决法.</description></item><item><title>PHP扩展开发2.2：线程安全</title><link>https://icorer.com/icorer_blog/posts/php-extension-development-2.2-thread-safety/</link><pubDate>Fri, 06 Jul 2018 17:26:18 +0800</pubDate><guid>https://icorer.com/icorer_blog/posts/php-extension-development-2.2-thread-safety/</guid><description>背景介绍 线程安全是编程中的术语，指某个函数、函数库在多线程环境中被调用时，能够正确地处理多个线程之间的共享变量，使程序功能正确完成。
一般来说，线程安全的函数应该为每个调用它的线程分配专门的空间，来储存需要单独保存的状态（如果需要的话），不依赖于“线程惯性”，把多个线程共享的变量正确对待（如，通知编译器该变量为“易失（volatile）”型，阻止其进行一些不恰当的优化），而且，线程安全的函数一般不应该修改全局对象。
很多C库代码（比如某些strtok的实现，它将“多次调用中需要保持不变的状态”储存在静态变量中，导致不恰当的共享）不是线程安全的，在多线程环境中调用这些函数时，要进行特别的预防措施，或者寻找别的替代方案。 更多线程安全信息请浏览维基百科：链接地址
在PHP初期，是作为单进程的CGI来运行的，所以并没有考虑线程安全问题。我们可以随意的在全局作用域中设置变量并在程序中对他进行修改、访问，内核申请的资源如果没有正确的释放，也会在CGI进程结束后自动地被清理干净。
后来，php被作为apache多进程模式下的一个模块运行，但是这仍然把php局限在一个进程里，我们设置的全局变量，只要在每个请求之前将其正确的初始化，并在每个请求之后正确的清理干净，便不会带来什么麻烦。由于对于一个进程来说，同一个时间只能处理一个请求，所以这是内核中加入了针对每个请求的内存管理功能，来防止服务器资源利用出现错误。
随着使用在多线程模式的软件系统越来越多，php内核中亟需一种新的资源管理方式，并最终在php内核中形成了一个新的抽象层：TSRM(Thread Safe Resource Management)。
线程安全与非线程安全在一个没有线程的程序中，我们往往倾向于把全局变量声明在源文件的顶部，编译器会自动的为它分配资源供我们在声明语句之下的程序逻辑中使用。（即使通过fork()出一个子进程，它也会重新申请一段内存，父子进程中的变量从此没有了任何联系）
但是在一个多线程的程序中，如果我们需要每个线程都拥有自己独立的资源的话，便需要为每个线程独立开辟出一个区域来存放它们各自的资源，在使用资源的时候，每个线程便会只在自己的那一亩三分地里找，而不会拔了别人的庄稼。
线程安全资源池（Thread-SafeDataPools）在扩展的ModuleInit里，扩展可以调用ts_allocate_id()函数来告诉 TRSM 自己需要多少资源。TRSM 接收后更新系统使用的资源，并得到一个指向刚分配的那份资源的id。
1typedef struct { 2 int sampleint; 3 char *samplestring; 4} php_sample_globals; 5int sample_globals_id; 6 7PHP_MINIT_FUNCTION(sample) 8{ 9 ts_allocate_id(&amp;amp;sample_globals_id, 10 sizeof(php_sample_globals), 11 (ts_allocate_ctor) php_sample_globals_ctor, 12 (ts_allocate_dtor) php_sample_globals_dtor); 13 return SUCCESS; 14} 当一个请求需要访问数据段的时候，扩展从TSRM层请求当前线程的资源池，以ts_allocate_id()返回的资源ID来获取偏移量。换句话说，在代码流中，你可能会在前面所说的MINIT语句中碰到SAMPLE_G(sampleint)=5;这样的语句。在线程安全的构建下，这个语句通过一些宏扩展如下：
1(((php_sample_globals*)(*((void ***)tsrm_ls))[sample_globals_id-1])-&amp;gt;sampleint = 5; 如果你看不懂上面的转换也不用沮丧，它已经很好的封装在PHPAPI中了，以至于许多开发者都不需要知道它怎样工作的。
当不在线程环境时因为在PHP的线程安全构建中访问全局资源涉及到在线程数据池查找对应的偏移量，这是一些额外的负载，结果就是它比对应的非线程方式（直接从编译期已经计算好的真实的全局变量地址中取出数据）慢一些。 考虑上面的例子，这一次在非线程构建下：
1typedef struct { 2 int sampleint; 3 char *samplestring; 4} php_sample_globals; 5php_sample_globals sample_globals; 6 7PHP_MINIT_FUNCTION(sample) 8{ 9 php_sample_globals_ctor(&amp;amp;sample_globals TSRMLS_CC); 10 return SUCCESS; 11} 首先注意到的是这里并没有定义一个int型的标识去引用全局的结构定义， 只是简单的在进程的全局空间定义了一个结构体。 也就是说SAMPLE_G(sampleint) = 5;展开后就是sample_globals.</description></item><item><title>PHP扩展开发2.1：PHP生命周期</title><link>https://icorer.com/icorer_blog/posts/php-extension-development-2.1-php-lifecycle/</link><pubDate>Fri, 06 Jul 2018 16:14:18 +0800</pubDate><guid>https://icorer.com/icorer_blog/posts/php-extension-development-2.1-php-lifecycle/</guid><description>#1. PHP SAPI 无论是Web模式、FastCgi模式、CLI模式，PHP的工作原理都是一样的，都是作为一种SAPI在运行（Server Application Programming Interface : the API sed by PHP to interface with Web Servers）。当我们在终端敲入php这个命令时候，它使用的是&amp;quot;”command lines api！它就像一个mini的web服务器一样来支持php完成这个请求，请求完成后再重新把控制权交给终端。简单来说,SAPI就是PHP和外部环境的代理器。它把外部环境抽象后,为内部的PHP提供一套固定的,统一的接口,使得PHP自身实现能够不受错综复杂的外部环境影响，保持一定的独立性
#2. PHP的启动与终止 PHP的启动和终止有两层含义，第一层是基于宿主进程、第二层是基于用户请求，前者被称为模块、后者成为请求。
在最初的初始化时候，就是PHP随着Apache的启动而诞生在内存里的时候，它会把自己所有已加载扩展的MINIT方法(全称Module Initialization，是由每个模块自己定义的函数。)都执行一遍。在这个时间里，扩展可以定义一些自己的常量、类、资源等所有会被用户端的PHP脚本用到的东西。但你要记住，这里定义的元素都会随着Apache常驻内存，可以被所有请求使用，直到Apache卸载掉PHP模块！
内核中预置了PHP_MINIT_FUNCTION()宏函数，来帮助我们实现这个功能：
1int minit_startTime = 0 ; 2PHP_MINT_FUNCTION(extension_name){ 3 minit_startTime = time(NULL); 4 php_printf(&amp;#34;%d\n&amp;#34;,minit_startTime); 5 return SUCCESS; 6} 当一个页面请求到来时候，PHP会迅速的开辟一个新的环境，并重新扫描自己的各个扩展，遍历执行它们各自的RINIT方法(俗称Request Initialization)，这时候一个扩展可能会初始化在本次请求中会使用到的变量等，还会初始化等会儿用户端（即PHP脚本）中的变量之类的，内核预置了PHP_RINIT_FUNCTION()这个宏函数来帮我们实现这个功能：
1int rinit_startTime = 0 ; 2PHP_RINIT_FUNCTION(extension_name){ 3 rinit_startTime = time(NULL); 4 php_printf(&amp;#34;%d\n&amp;#34;,rinit_startTime); 5 return SUCCESS; 6} 好了，现在这个页面请求执行的差不多了，可能是顺利的走到了自己文件的最后，也可能是出师未捷，半道被用户给die或者exit了，这时候PHP便会启动回收程序，收拾这个请求留下的烂摊子。它这次会执行所有已加载扩展的RSHUTDOWN（俗称RequestShutdown）方法，这时候扩展可以抓紧利用内核中的变量表之类的做一些事情，因为一旦PHP把所有扩展的RSHUTDOWN方法执行完，便会释放掉这次请求使用过的所有东西，包括变量表的所有变量、所有在这次请求中申请的内存等等。
内核预置了PHP_RSHUTDOWN_FUNCTION宏函数来帮助我们实现这个功能
1PHP_RSHUTDOWN_FUNCTION(extension_name){ 2 FILE*fp=fopen(&amp;#34;time_rshutdown.txt&amp;#34;,&amp;#34;a+&amp;#34;); 3 fprintf(fp,&amp;#34;%ld\n&amp;#34;,time(NULL)); 4 fclose(fp); 5 return SUCCESS; 6} 前面该启动的也启动了，该结束的也结束了，现在该Apache老人家歇歇的时候，当Apache通知PHP自己要Stop的时候，PHP便进入MSHUTDOWN（俗称ModuleShutdown）阶段。这时候PHP便会给所有扩展下最后通牒，如果哪个扩展还有未了的心愿，就放在自MSHUTDOWN方法里，这可是最后的机会了，一旦PHP把扩展的MSHUTDOWN执行完，便会进入自毁程序，这里一定要把自己擅自申请的内存给释放掉，否则就杯具了。</description></item><item><title>研究报告：JAVA 与 Golang 在 UDP服务器上的性能对比</title><link>https://icorer.com/icorer_blog/posts/performance-comparison-between-java-and-golang-on-udp-server/</link><pubDate>Tue, 03 Jul 2018 15:43:18 +0800</pubDate><guid>https://icorer.com/icorer_blog/posts/performance-comparison-between-java-and-golang-on-udp-server/</guid><description>背景介绍因工作需求，目前需要采用UDP协议来存储用户日志信息，目前采用了JAVA 和 Golang 两种途径。
#Linux内核优化（非常重要） 可以使用netstat -su 查看UDP是否有错包，如果查看到有UDP receive errors，可以调整UDP缓冲区的大小以应对大规模请求，主要参数如下
1net.core.rmem_max=26214400 2net.core.rmem_default=26214400 #客户端情况介绍 客户端采用PHP语言进行编写，由于PHP底层采用C实现，所以UDP客户端的性能应该算是最佳了，相关代码如下：
1&amp;lt;?php 2$islocalUdp = true; 3$server_ip = &amp;#39;127.0.0.1&amp;#39;; 4$server_port = 10000; 5$message = &amp;#39;loginfo&amp;#39;; 6 7if($islocalUdp){ 8 $socket = socket_create(AF_INET, SOCK_DGRAM, SOL_UDP); 9 $ret = socket_sendto($socket, $message, strlen($message), 0, $server_ip, $server_port); 10}else{ 11 $message = &amp;#34;$server_ip**$server_port**$message&amp;#34;; 12 13 $ret = sendDataUds ($message,3,&amp;#39;/dev/shm/unix_udp_socks.sock&amp;#39;); 14} 15?&amp;gt; #JAVA服务端介绍 JAVA使用名声很大的Netty 网络包。
#Golang 服务端介绍 Golang服务端采用Net包中的ListenUDP进行程序编写，由于目前没有对大日志进行测试，所以不进行缓冲区中转编程，相关代码如下：
1package main 2 3import ( 4 &amp;#34;fmt&amp;#34; 5 &amp;#34;log&amp;#34; 6 &amp;#34;net&amp;#34; 7) 8 9const ( 10 BUF_SIZE = 1024 11) 12 13func main() { 14 udp_addr, err := net.</description></item><item><title>Nginx FAST-CGI缓存优化</title><link>https://icorer.com/icorer_blog/posts/nginx-fast-cgi-cache-optimization/</link><pubDate>Sun, 24 Jun 2018 20:42:18 +0800</pubDate><guid>https://icorer.com/icorer_blog/posts/nginx-fast-cgi-cache-optimization/</guid><description>背景描述传统的LNMP架构中，PHP-FPM对于PHP脚本进行解析工作，Nginx反向代理的时候，会把PHP请求转达给PHP-FPM。对于一个PHP站点，PHP-FPM的工作压力很巨大，所以，如果我们在Nginx层面上做一个FAST-CGI缓存，则会大大缓解解析器的压力，达到更好的响应效果。
NGINX 缓存配置1. HTTP层配置 1fastcgi_cache_path /tmp/cache/fastcgi_cache levels=1:2 keys_zone=fastcgi-cache:10m inactive=2d max_size=512m; 2 3fastcgi_cache_key $scheme$request_method$host$request_uri;; 4proxy_buffering on; 5proxy_cache_valid any 10m; 6proxy_temp_path /tmp/cache/tmp; 7proxy_buffer_size 4k; 8proxy_buffers 100 8k; 9fastcgi_cache_lock on; 10fastcgi_cache_use_stale error timeout invalid_header updating http_500; 11fastcgi_ignore_headers Cache-Control Expires Set-Cookie; 这里的key_zone = fastcgi-cache, 就是在server层需要用到的代理zone
2. Server层配置 1location ~ [^/]\.php(/|$) 2{ 3 try_files $uri =404; 4 fastcgi_pass unix:/tmp/php-cgi.sock; 5 fastcgi_index index.php; 6 include fastcgi.conf; 7 add_header PHP-Cache $upstream_cache_status; //添加响应头部 8 fastcgi_cache fastcgi-cache; //设置缓存zone 9 fastcgi_cache_valid 200 60m; 10} 测试总结经过测试，对于实时性要求不是很高的系统，启用了缓存机制后，能够大大提高系统的访问速度，下图是本博客的全国测试结果。</description></item><item><title>源码阅读：C语言epoll模型</title><link>https://icorer.com/icorer_blog/posts/source-code-reading-c-language-epoll-model/</link><pubDate>Fri, 08 Jun 2018 18:02:18 +0800</pubDate><guid>https://icorer.com/icorer_blog/posts/source-code-reading-c-language-epoll-model/</guid><description>背景epoll是Linux内核为处理大批量文件描述符而作了改进的poll，是Linux下多路复用IO接口select/poll的增强版本，它能显著提高程序在大量并发连接中只有少量活跃的情况下的系统CPU利用率。另一点原因就是获取事件的时候，它无须遍历整个被侦听的描述符集，只要遍历那些被内核IO事件异步唤醒而加入Ready队列的描述符集合就行了。epoll除了提供select/poll那种IO事件的水平触发（Level Triggered）外，还提供了边缘触发（Edge Triggered），这就使得用户空间程序有可能缓存IO状态，减少epoll_wait/epoll_pwait的调用，提高应用程序效率。
#模型代码 今天给大家分享一下EPOLL的相关模型代码：
服务端代码 1#include &amp;lt;sys/types.h&amp;gt; 2#include &amp;lt;sys/signalfd.h&amp;gt; 3#include &amp;lt;sys/epoll.h&amp;gt; 4#include &amp;lt;errno.h&amp;gt; 5#include &amp;lt;poll.h&amp;gt; 6#include &amp;lt;signal.h&amp;gt; 7#include &amp;lt;limits.h&amp;gt; 8#include &amp;lt;stdio.h&amp;gt; 9#include &amp;lt;stdlib.h&amp;gt; 10#include &amp;lt;unistd.h&amp;gt; 11#include &amp;lt;fcntl.h&amp;gt; 12#include &amp;lt;string.h&amp;gt; 13#include &amp;lt;assert.h&amp;gt; 14#include &amp;lt;sys/ioctl.h&amp;gt; 15#include &amp;lt;sys/socket.h&amp;gt; 16#include &amp;lt;netinet/in.h&amp;gt; 17#include &amp;lt;arpa/inet.h&amp;gt; 18#include &amp;#34;utarray.h&amp;#34; 19 20/***************************************************************************** 21 * This program demonstrates epoll-based event notification. It monitors for 22 * new client connections, input on existing connections or their closure, as 23 * well as signals.</description></item><item><title>解析 Go 中的函数调用</title><link>https://icorer.com/icorer_blog/posts/parsing-function-calls-in-go/</link><pubDate>Fri, 08 Jun 2018 10:17:18 +0800</pubDate><guid>https://icorer.com/icorer_blog/posts/parsing-function-calls-in-go/</guid><description>让我们来看一些简单的 Go 的函数，然后看看我们能否明白函数调用是怎么回事。我们将通过分析 Go 编译器根据函数生成的汇编来完成这件事。对于一个小小的博客来讲，这样的目标可能有点不切实际，但是别担心，汇编语言很简单。哪怕是 CPU 都能读懂。
这是我们的第一个函数。对，我们只是让两个数相加。 1func add(a, b int) int { 2 return a + b 3} 我们编译的时候需要关闭优化，这样方便我们去理解生成的汇编代码。我们用 go build -gcflags 'N -l' 这个命令来完成上述操作。然后我们可以用 go tool objdump -s main.add func 输出我们函数的具体细节（这里的 func 是我们的包名，也就是我们刚刚用 go build 编译出的可执行文件）。
如果你之前没有学过汇编，那么恭喜你，你将接触到一个全新的事物。另外我会在 Mac 上完成这篇博客的代码，因此所生成的是 Intel 64-bit 汇编。
1 main.go:20 0x22c0 48c744241800000000 MOVQ $0x0, 0x18(SP) 2 main.go:21 0x22c9 488b442408 MOVQ 0x8(SP), AX 3 main.go:21 0x22ce 488b4c2410 MOVQ 0x10(SP), CX 4 main.go:21 0x22d3 4801c8 ADDQ CX, AX 5 main.</description></item><item><title>微服务：请求熔断原理</title><link>https://icorer.com/icorer_blog/posts/microservices-principles-of-request-fusing/</link><pubDate>Wed, 06 Jun 2018 13:27:18 +0800</pubDate><guid>https://icorer.com/icorer_blog/posts/microservices-principles-of-request-fusing/</guid><description>伴随微服务，出现了很多新鲜的名词，其实剥去外衣并没有那么高大上。
今天要谈到的，叫做”熔断”，一个典型的开源实现是Hystrix（JAVA实现）。
背景一个分布式系统中，服务间互相调用错综复杂，假设某个基础服务宕机，那么就会导致若干上游调用方出现访问超时，进而引起上游重试，导致宕机的基础服务遭受到数倍的流量放大，更加无法恢复服务。
这种恶劣的情况并不会就此结束，上游因为调用基础服务超时而变慢，导致上游的上游超时…异常向上蔓延，最终导致整个分布式系统”雪崩”。
“熔断”就是为了避免”雪崩”而生的，它的思路是在调用方增加一种”避让”机制，当下游出现异常时能够停止（熔断）对下游的继续请求，当等待一段时间后缓慢放行部分的调用流量，并当这部分流量依旧正常的情况下，彻底解除”熔断”状态。
听起来，流程不算复杂吧？整个流程图如下，看不懂没关系，继续往下阅读吧。
#健康统计
判断下游正常的前提是统计最近一段时间内，下游的调用成功率，因此需要一个健康统计模块，记录最近N秒内的总请求数，成功请求数，失败请求数，是由业务调用后将结果打点到健康统计模块中。
下游健康的标志，是最近N秒的成功率大于某个阀值，那么代表下游健康。
因为时间不停的前进，要统计最近N秒内的成功率，显然仅仅维护3个数字是不足以表达的，因此这里一般会使用”时间窗口”来实现。
如最上面的图片所示，整个时间窗口由10个槽位（bucket）构成，每个槽位代表1秒钟，整个时间窗口表达了最近10秒的健康统计，最右侧的bucket记录了最近1秒的成功/失败请求数量，仅此而已。
随着时间每过去1秒，整个窗口会向右滑动1格，最左侧的1个槽位被淘汰，最右侧加入当前1秒的新槽位，这就是时间窗口的实现原理。
当然，我们在实现的时候不会写一个定时器每秒去更新时间窗口，而是当打点接口被调用的时候进行计算和窗口滑动。为了更清晰的帮助你理解，我写了一个简短的PHP实现：
1&amp;lt;?php 2 3// 时间窗口10个桶 4define(&amp;#34;BUCKET_NUM&amp;#34;, 10); 5// 成功率大于该值为健康 6define(&amp;#34;HEALTHY_RATE&amp;#34;, 0.8); 7 8// 健康统计 9class HealthStats { 10 private $service = &amp;#39;&amp;#39;; 11 private $buckets = []; 12 private $curTime = 0; 13 14 public function __construct($service) 15 { 16 $this-&amp;gt;service = $service; 17 $this-&amp;gt;buckets = array_fill(0, BUCKET_NUM, [&amp;#39;success&amp;#39; =&amp;gt; 0, &amp;#39;fail&amp;#39; =&amp;gt; 0,]); 18 } 19 20 private function shiftBuckets() 21 { 22 $now = time(); 23 24 $timeDiff = $now - $this-&amp;gt;curTime; 25 if (!</description></item><item><title>Pecl_Http 与 unix domain socket 客户端封装</title><link>https://icorer.com/icorer_blog/posts/pecl_http-and-unix-domain-socket-client-package/</link><pubDate>Tue, 05 Jun 2018 09:44:18 +0800</pubDate><guid>https://icorer.com/icorer_blog/posts/pecl_http-and-unix-domain-socket-client-package/</guid><description>1. 背景描述Pecl/HTTP是一个PHP扩展，历史非常悠久了，从2005年至2018年不断完善其功能，它主要帮助PHP对于HTTP请求的相关操作。不同于CURL，其具有更丰富的扩展接口，既包括平常的请求，也包括对于HTTP数据的封包或拆包操作。
对于PHP和HTTP，大部分程序员关心的如何完成一个请求。但是更深一步，我们会发现HTTP数据包的文件格式也很重要，比如传统的HTTP请求性能很弱，对于请求密集型业务，传统的HTTP并不能达到很好的RPS，就算是开启了Keep-Alive，性能还是很弱。对于这种情况，我们失望的是HTTP请求，而不是HTTP的数据包格式，所以我们可以在数据封包拆包上继续使用HTTP协议，但是对于数据传输这层，我们可以采用性能更高的一些通路，比如Unix domain socket。
2. 研究难点HTTP的通信协议数据包格式总体来说并不复杂，但是为了便于系统研发及维护，一般都站在巨人的肩膀上进行研发，目前针对PHP进行数据拆包与封包的库很少。一方面我们可以从网上比较火的一些Http Client库中抽取相关的调用层，另一方面我们可以从pecl中找寻一些扩展库，基于pecl的扩展库都是基于C语言进行的研发，性能更强，而且安装也很方便。
在本文中，我们主要围绕Pecl/HTTP库进行相关阐述，在接下来的文章中，我们也会专门围绕Guzzle或者更合适的PHP库来讲解数据包的装包和拆包。
3. HTTP数据包：封包-拆包3.1 扩展类设计思路本文主要讲解HTTP数据包的封包和拆包操作，我们首先封装一个HTTP数据包相关接口，接口主要包括对于Get、Post的封包；对于数据包的解包操作。
1&amp;lt;?php 2interface HttpPack{ 3 public function encodeGetPack($url,$header); 4 public function encodePostPack($url,$header,$body); 5 public function decodePack($packStr); 6} 7?&amp;gt; 随后，我们定义了一个SimpleTun类来实现这个接口，具体函数实现在各节详细描述，此处为框架代码。 1&amp;lt;?php 2class SimpleTun implements HttpPack 3{ 4 public function encodeGetPack($url, $header) 5 { 6 // TODO: Implement encodeGetPack() method. 7 8 } 9 10 public function encodePostPack($url, $header, $body) 11 { 12 // TODO: Implement encodePostPack() method. 13 } 14 15 public function decodePack($packStr) 16 { 17 // TODO: Implement decodePack() method.</description></item><item><title>测试报告：HTTP Post 与 Unix Domain Socket 通信性能对比</title><link>https://icorer.com/icorer_blog/posts/test-report-comparison-of-communication-performance-between-http-post-and-unix-domain-socket/</link><pubDate>Mon, 28 May 2018 09:35:18 +0800</pubDate><guid>https://icorer.com/icorer_blog/posts/test-report-comparison-of-communication-performance-between-http-post-and-unix-domain-socket/</guid><description>&lt;h2 id="背景描述">背景描述&lt;a class="anchorjs-link" href="#%e8%83%8c%e6%99%af%e6%8f%8f%e8%bf%b0">&lt;/a>&lt;/h2>&lt;p>因工作需求，项目需要在不同的程序语言框架中进行通信，目前对于进程通信的方式，互联网上主要有HTTP请求、IPC通信、Socket通信、共享内存通信，虽然共享内存效率最高，但是对于内存结构的设计与队列维持需要很高的系统实现能力，所以目前我测试了HTTP与Unix Socket这两种通信方案。&lt;/p>
&lt;h2 id="测试环境搭建">测试环境搭建&lt;a class="anchorjs-link" href="#%e6%b5%8b%e8%af%95%e7%8e%af%e5%a2%83%e6%90%ad%e5%bb%ba">&lt;/a>&lt;/h2>&lt;p>目前分为HTTP和Unix Socket通信两种测试环境，为了保持测试环境尽量统一，我们请求端用PHP语言、接受信息端用Go语言。
测试软件使用 Jmeter 4.0
操作系统：Centos 7
硬件条件：I5 CPU、8GB内存&lt;/p></description></item><item><title>Jmeter测试报表相关参数说明</title><link>https://icorer.com/icorer_blog/posts/jmeter-test-report-related-parameter-description/</link><pubDate>Fri, 18 May 2018 11:26:18 +0800</pubDate><guid>https://icorer.com/icorer_blog/posts/jmeter-test-report-related-parameter-description/</guid><description>背景介绍采用Jmeter测试工具对web系统作的负载测试，得出的响应报表，数据比较难懂，现作一具体说明。
以下是在一次具体负载测试中得出的具体数值，测试线程设置情况为：线程数：200，等待时间（ramp-up）：0秒，循环次数为永远，另：
线程组——这些元件用于指定运行的线程数和等候周期。每个线程模拟一个用户，而等候周期用于指定创建全部线程的时间。例如，线程数为5，等候时间为10秒，则创建每个线程之间的时间间隔为2秒。循环数定义了线程的运行时间。使用调度器，还可以设置运行的起始时间。 取样器——对于服务器HTTP、FTP或LDAP请求，这些元件是可配置请求。该教程仅侧重于Web Services请求。 监听器——这些元件用于请求数据的后期处理。例如，可以将数据保存到文件或用图表来说明结果。此时JMeter图表并没有提供许多配置选项；然而它是可扩展的，它始终可以添加额外的可视化效果或数据处理模块。 一、图形报表 图表底部参数的含义如下： 样本数目是总共发送到服务器的请求数。 最新样本是代表时间的数字,是服务器响应最后一个请求的时间。 吞吐量是服务器每分钟处理的请求数。 平均值是总运行时间除以发送到服务器的请求数。 中间值是代表时间的数字，有一半的服务器响应时间低于该值而另一半高于该值。 偏离表示服务器响应时间变化、离散程度测量值的大小，或者，换句话说，就是数据的分布。 二、 聚合报告 图表含义说明如下：
Label：说明是请求类型，如Http，FTP等请求。 Samples：也就是图形报表中的样本数目，总共发送到服务器的样本数目。 Average：也就是图形报表中的平均值，是总运行时间除以发送到服务器的请求数。 Median：也就是图形报表中的中间值，是代表时间的数字，有一半的服务器响应时间低于该值而另一半高于该值。 90%line：是指90%请求的响应时间比所得数值还要小。 Min：是代表时间的数字,是服务器响应的最短时间。 Max: 是代表时间的数字,是服务器响应的最长时间。 Error%:请求的错误百分比。 Throughput:也就是图形报表中的吞吐量，这里是服务器每单位时间处理的请求数，注意查看是秒或是分钟。 KB/sec:是每秒钟请求的字节数。 三、 使用分析在测试过程中，平均响应时间是我们性能测试的一个重要衡量指标，但是在测试中，特别是在聚合报告中，得出的90%Line,我这里参考《《LoadRunner 没有告诉你的》之一——描述性统计与性能结果分析》，我认为90%Line等同于该文作者提出的90%响应时间,这个数值对我们性能测试分析也很有参考价值。90%响应时间是说在发送的请求中，90%的用户响应时间都比得到的数值上要短，同时说明，一个系统在应用时，90%的用户响应时间都能达到这个数值，那么就为系统性能分析提供了很好的参考价值。
原文链接： https://blog.</description></item><item><title>Manjaro 安装 LNMP环境</title><link>https://icorer.com/icorer_blog/posts/manjaro-installs-lnmp-environment/</link><pubDate>Sat, 24 Mar 2018 13:03:18 +0800</pubDate><guid>https://icorer.com/icorer_blog/posts/manjaro-installs-lnmp-environment/</guid><description>&lt;h2 id="安装phpphp-fpm--编译安装-nginxmysql-详细配置信息">安装PHP、PHP-FPM ; 编译安装 Nginx、MYSQL; 详细配置信息。&lt;a class="anchorjs-link" href="#%e5%ae%89%e8%a3%85phpphp-fpm--%e7%bc%96%e8%af%91%e5%ae%89%e8%a3%85-nginxmysql-%e8%af%a6%e7%bb%86%e9%85%8d%e7%bd%ae%e4%bf%a1%e6%81%af">&lt;/a>&lt;/h2>&lt;h2 id="1-编译nginx">1. 编译Nginx&lt;a class="anchorjs-link" href="#1-%e7%bc%96%e8%af%91nginx">&lt;/a>&lt;/h2>&lt;h3 id="11-创建用户-及-用户组">1.1 创建用户 及 用户组&lt;a class="anchorjs-link" href="#11-%e5%88%9b%e5%bb%ba%e7%94%a8%e6%88%b7-%e5%8f%8a-%e7%94%a8%e6%88%b7%e7%bb%84">&lt;/a>&lt;/h3>&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-shell" data-lang="shell">&lt;span style="display:flex;">&lt;span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">1&lt;/span>&lt;span>sudo groupadd -r www
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">2&lt;/span>&lt;span>sudo useradd -s /sbin/nologin -g www -r www
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;h3 id="12-下载nginx源码包-并-解压">1.2 下载Nginx源码包 并 解压&lt;a class="anchorjs-link" href="#12-%e4%b8%8b%e8%bd%bdnginx%e6%ba%90%e7%a0%81%e5%8c%85-%e5%b9%b6-%e8%a7%a3%e5%8e%8b">&lt;/a>&lt;/h3>&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-shell" data-lang="shell">&lt;span style="display:flex;">&lt;span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">1&lt;/span>&lt;span>wget http://nginx.org/download/nginx-1.14.0.tar.gz
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div></description></item></channel></rss>