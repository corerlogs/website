<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>redis on 笔迹-工匠之芯</title><link>https://icorer.com/icorer_blog/tags/redis/</link><description>Recent content in redis on 笔迹-工匠之芯</description><generator>Hugo -- gohugo.io</generator><language>zh-cn</language><lastBuildDate>Tue, 25 May 2021 22:35:12 +0800</lastBuildDate><atom:link href="https://icorer.com/icorer_blog/tags/redis/index.xml" rel="self" type="application/rss+xml"/><item><title>⽤于区块链可扩展性的⾼效能 FPGA-Redis 混合 NoSQL 缓存系统</title><link>https://icorer.com/icorer_blog/posts/blockchain_fpga_redis_nosql/</link><pubDate>Tue, 25 May 2021 22:35:12 +0800</pubDate><guid>https://icorer.com/icorer_blog/posts/blockchain_fpga_redis_nosql/</guid><description>一、FPGA-Redis介绍鼓舞人心的区块链技术在加密货币以外的领域取得了很多采用和成功领域落地，因为它的好处已经被探索和成功测试。可扩展性是区块链的最大挑战之一，许多设备（轻量级节点）尤其是物联网依赖于完整的区块链服务器，因此需要减少服务器上的工作负载以获得高性能。这篇论文提出了一种高性能、高效的混合（多级）和分布式NoSQL缓存系统，用于提高区块链应用程序的可扩展（吞吐量）。我们研究了区块链中的性能瓶颈，并设计了一种高效的千兆以太网FPGA NoSQL缓存架构，该架构通过Hiredis C客户端与Redis数据库协同工作。Curl和Jansson用于连接区块链。我们为特定于区块链的高效缓存设计了一个定制的SHA-256核心。我们的结果显示，当FPGA上发生缓存命中时，性能提高了103倍。所提出的FPGA-Redis系统获得了高达4.09倍的改进，还实现了较小的FPGA面积利用率和较低的功耗。
二、概述区块链技术激励了许多人，帮助许多企业和政府改进系统，解决了信任、安全、速度、成本、效率和中心化等诸多瓶颈问题。英国政府办公室的报告确认区块链可以保护数据、降低成本并为记录提供透明度。区块链由中本聪于2008年首次提出并支持加密货币（比特币）和许多其他用于医疗保健、身份管理、网络安全等应用程序。Corda是R3的区块链（由200多家公司组成的联盟，主要是金融机构），用于增强商业交易和网络，R3一直在为企业使用和探索区块链。
尽管区块链很强大，但可扩展性（低吞吐量、高延迟、存储问题和读取性能差）是其巨大的挑战，但研究较少。与非区块链应用程序相比，区块链应用程序的吞吐量要低很多。比特币和以太坊支持每秒3-4和15-20笔交易（TPS），而Visa和PayPal分别支持1667和193TPS，另一方面，与非区块链服务器相比，区块链服务器的查询响应（读取性能）也很差。例如在我们处理约每秒96个响应的区块链系统中，查询延迟超过10毫秒。同样，Blockcypher 区块链服务器⽀持每秒3个请求。与⾮区块 链服务器相⽐，Google和YouTube分别处理每秒84,405个请求和每秒85,021次观看。糟糕的读取性能是由于区块链的结构和巨大的尺寸（比特币超过288GB）以及区块链数据存储在硬盘上的事实。与用于存储Redis等NoSQL缓存的RAM（快150,000倍）不同，硬盘具有较高的访问延迟。由于这种糟糕的读取性能，现有的区块链无法处理有效服务器所需的每秒大量客户端请求。许多轻量级节点（数以千计的物联网设备和简化验证（SPV）节点），仅依赖区块链服务器来获取区块链数据，因为其庞大的规模，它们无法存储完整的区块链。现在越来越多的轻量级客户端使用区块链并将更多的工作放在区块链服务器上，因此必须减少区块链服务器上的工作量以提升性能，从而更好地扩展区块量应用程序。
NoSQL缓存是提高和增强区块量服务器读取性能的一种有效方式。Redis、Hadoop和Memcached等NoSQL缓存如今已广泛用于大型Web数据中心，例如Yahoo、Twitter、Facebook、Youtube甚至Google，其中数百个分布式NoSQL部署缓存服务器是为了改善许多性能和可伸缩问题并节省成本。NoSQL缓存具有非常高的性能进行大规模水平扩展的优势，并且比使用更强大的CPU和内存（垂直扩展）更新现有服务器更经济。水平扩展是指使用廉价商品服务器的副本来获得更好的性能，而不是传统的垂直扩展，其中将更强大的资源添加到单个服务器使系统更加昂贵。仅苹果公司就使用了超过75000个NoSQL缓存（Cassandra）表格系列集群来存储超过10PB的数据。
分布式 NoSQL 缓存由于其⾼性能以及区块链请求（尤其是块头请求）的时间局部性，可以极⼤地提⾼区块链服务器响应的吞吐量和延迟性能。许多轻量级节点（如简化⽀付验证节点（特殊⽬的公司 )在添加新块的⼏个⼩时内。
尽管具有⾼性能，但软件 NoSQL 缓存在⾼性能时会消耗⾼功率和更多CPU 资源（在⽹络处理上）。因此，当 FPGA 发⽣缓存命中时，使⽤ FPGA来降低功耗和 CPU 资源消耗并提⾼性能。然⽽，FPGA 中的⼩尺⼨和有限的内存给可以缓存在 FPGA 上的数据量带来了缺陷和限制，从⽽通过增加 FPGA 的未命中率来影响系统性能。
本⽂研究了区块链中的性能瓶颈，并提出了⼀种⾼效的⾼性能混合分布式NoSQL FPGA-Redis 缓存系统，以减少区块链服务器的⼯作负载并提⾼其性能。我们设计并实现了⼀个千兆以太⽹ FPGA ⽹络接⼝控制器 (NIC)，该控制器包含键值存储，⽤于有效地缓存 FPGA 上的区块链数据。Redis 软件缓存和 Redis 应⽤程序内置在 Redis 服务器 PC 中，它通过 FPGA 上实现的千兆总线主控直接内存地址 (BMD) PCI Express (PCIe) 端点连接到 NIC。Redis 应⽤程序使⽤Hiredis API（实现与Redis缓存对话的Redi 的C客⼾端）。整个缓存系统通过我们的服务器应⽤程序中内置的Curl和Jansson API 连接到全节点区块链服务器。
该系统改善了FPGA NoSQL缓存内存⼩的缺点，同时以更低的功耗提⾼了 软件缓存的性能。FPGA 和 Redis 协同⼯作。Redis 通过提供另⼀个缓存层来补充 FPGA 缓存的有限内存。当在 FPGA 上未找到请求的数据（发⽣缓存未命中）时，数据从 Redis（如果缓存）⽽不是存储在主内存中的主区块链中获取。由于 Redis ⽐主存更快，因此整个系统的性能得到了提⾼。反过来，FPGA 通过处理⽹络处理来降低Redis的⾼性能和CPU资源消耗。我们只在FPGA和Redis（包括缓存）上缓存频繁的请求（即块头、确认、块⾼度、时间跨度和 Merkle根），⽽在Redis上缓存不频繁和⼤数据请求（例如块请求）只要。此外，仅当FPGA上发⽣缓存未命中时才检查Redis 缓存。</description></item><item><title>Redis6客户端缓存的相关设计</title><link>https://icorer.com/icorer_blog/posts/related-design-of-redis6-client-cache/</link><pubDate>Mon, 16 Mar 2020 13:15:18 +0800</pubDate><guid>https://icorer.com/icorer_blog/posts/related-design-of-redis6-client-cache/</guid><description>这篇文章翻译自Redis官方博客，这篇文章阐述了Redis6中将如何支持客户端缓存功能。
纽约Redis一天结束了，我于5:30在酒店起床，仍然与意大利时区保持同步，并立即走在曼哈顿的街道上，完全爱上了风景和美好的生活感觉。 但是我在Redis 6发行版中的感觉是，可能是最重要的功能，即新版本的Redis协议（RESP3）的采用曲线将非常缓慢，这是有充分理由的： 明智的人会在没有充分理由的情况下避免使用工具。 毕竟我为什么要这么严重地改进协议？主要有两个原因，即为客户提供更多的语义答复，并开放使用旧协议难以实现的新功能。 对我来说，最重要的功能之一就是客户端缓存。
让我们回到一年前。我来到旧金山的Redis Conf 2018，当时我坚信客户端缓存是Redis未来最重要的事情。 如果我们需要快速存储和高速缓存，那么我们需要在客户端中存储信息的子集。这是对延迟较小且规模较大的数据提供服务的想法的自然扩展。事实上，几乎所有的大公司都已经这样做了，因为这是唯一的生存之道。然而，Redis无法在此过程中协助客户。 一个幸运的巧合希望Ben Malec在Redis Conf上确切地谈论客户端缓存[1]，仅使用Redis提供的工具和许多非常聪明的想法。
[1] https://www.youtube.com/watch?v=kliQLwSikO4
本采取的方法确实打开了我的想象。 Ben为了使他的设计工作而使用了两个关键思想。首先是使用Redis Cluster的“哈希槽”概念，以将key分为16k组。这样，客户端将无需跟踪每个key的有效性，但可以将单个元数据条目用于一组key。Ben使用Pub / Sub来更改键时发送通知，因此他需要应用程序各个部分的帮助，但是该架构非常可靠。 修改key？同时发布一条使它无效的消息。 在客户端，您是否在缓存key？记住缓存每个key的时间戳，并且在接收到无效消息时，还要记住每个插槽的无效时间。 当使用给定的缓存key时，通过检查缓存的key是否具有比该key所属的插槽接收到的失效时间戳更旧的时间戳，来进行懒惰驱逐：在这种情况下，该key是陈旧数据， 必须再次询问服务器。
看完演讲之后，我意识到这是在服务器内部使用的好主意，以便允许Redis为客户端完成部分工作，并让客户端缓存更简单、更有效,所以我回家后,写了一个文档描述设计[2]。
[2] https://groups.google.com/d/msg/redis-db/xfcnYkbutDw/kTwCozpBBwAJ
但是，要使我的设计正常工作，我必须专注于将Redis协议切换到更好的协议，因此我开始编写规范，然后编写RESP3的代码，以及其他Redis 6之类的东西，例如ACL等，并且客户端缓存加入了 由于缺乏时间，我以某种方式放弃了Redis的许多构想的巨大空间。
但是我还是在纽约街头思考这个想法。 后来和会议的朋友一起去吃午餐和喝咖啡休息时间。 当我回到酒店房间时，剩下的整个晚上都是在飞机起飞前的第二天，所以我开始遵循我一年前写给小组的建议，开始编写Redis 6客户端缓存的实现。 看起来仍然很棒。
Redis服务器辅助的客户端缓存，最终称为跟踪(但我可能会改变想法)，是一个非常简单的功能，由几个关键的想法组成。
key空间被划分为“缓存槽”，但它们比Ben使用的哈希槽大得多。 我们使用CRC64输出的24位，因此有超过1600万个不同的插槽。为什么这么多?因为我认为您希望有一个拥有1亿key的服务器，而一条无效消息应该只影响客户端缓存中的几个key。Redis中无效表的内存开销是130mb:一个8字节的数组，指向16M个条目。这对我来说是可以的，如果你想要这个功能，你就要充分利用你在客户端的所有内存，所以使用130MB的服务器端是可以的;您所赢得的是一个更细粒度的失效。
客户端通过简单的命令以opt方式启用该特性：
1 CLIENT TRACKING on 服务器会回复旧的+ OK，从那一刻开始，命令表中标记为“只读”的每个命令不仅会把键返回给调用者，而且还会产生副作用 客户端到目前为止请求的所有键的缓存插槽（但只有使用只读命令的键才是，这是服务器与客户端之间的协议）。Redis存储此信息的方法很简单。每个Redis客户端都有一个唯一的ID，因此，如果客户端ID 123执行有关将key散列到插槽1、2和5的MGET，我们将获得带有以下条目的无效表：
11 -&amp;gt; [123] 22 -&amp;gt; [123] 35 -&amp;gt; [123] 但是稍后客户端ID 444也会询问插槽5中的key，因此该表将如下所示：
15 -&amp;gt; [123, 444] 现在，其他一些客户端更改了插槽5中的某些key。发生的事情是Redis将检查Invalidation Table，以发现客户端123和444都可能在该插槽上缓存了key。我们将向这两个客户端发送无效消息，因此他们可以自由地以任何形式处理该消息：要么记住上一次插槽无效的时间戳记，然后以懒惰的方式检查时间戳记（或者 如果您更喜欢此渐进式“时期”：它比较安全），然后根据比较结果将其逐出。否则，客户端可以通过获取其在此特定插槽中缓存的内容的表来直接直接回收对象。这种具有24位哈希函数的方法不是问题，因为即使缓存了数千万个key，我们也不会有很长的列表。发送无效消息后，我们可以从无效表中删除条目，这样，我们将不再向这些客户端发送无效消息，直到它们不再读取该插槽的key为止。
请注意，客户端不必真正使用hash函数的所有24位。例如，他们可能只使用20位，然后也会转移Redis发送给他们的无效消息槽。不确定这样做是否有很多好的理由，但在内存受限的系统中可能是一个想法。
如果您严格按照我所说的进行操作，您会认为相同的连接同时接收到正常的客户端响应和无效消息。对于RESP3，这是可能的，因为无效消息是作为“推送”消息类型发送的。 但是，如果客户端是阻塞客户端，而不是事件驱动的客户端，则这将变得很复杂：应用程序需要某种方式不时读取新数据，并且看起来复杂而脆弱。 在这种情况下，最好使用另一个应用程序线程和另一个客户端连接，以便接收无效消息。 因此，您可以执行以下操作：</description></item><item><title>Redis Client Side Cache - Redis客户端缓存 - RedisConf18</title><link>https://icorer.com/icorer_blog/posts/redis-client-side-cache-redis-client-side-cache-redisconf18/</link><pubDate>Sun, 15 Mar 2020 16:22:18 +0800</pubDate><guid>https://icorer.com/icorer_blog/posts/redis-client-side-cache-redis-client-side-cache-redisconf18/</guid><description>一. 背景描述客户端缓存是一个有意思的话题，它不是空穴来风的技术，在最新的Redis RC版本已经正式开始着手CSC方案的设计，虽然目前版本的CSC还不能真正的商用，但是市面上也有一些其他公司开始着手试探CSC相关方案的设计与实现。
目标比较有名的模型是两种：
Ben Malec paylocity公司方案 Redis6 RC方案 这两种方案并不是独立的，他们各有各的优势，paylocity公司的方案被redis团队所赞赏，并吸收了一些思路进入Redis RC版本中，Redis RC版本主要是提供了一些server端的协助，但是本质上还是没有完整的CSC方案。
二. RedisConf2018大会 Ben Malec分享这里，我们将阐述RedisConf 2018年的经典分享，这个分享围绕CSC机制的相关设计与实现，并且方案已经被广泛使用在paylocity公司，有很高的的借鉴意义。 Ben Malec的分享主要围绕如何实现一个和Redis缓存同步的本地内存缓存。
首先，我们看一下简单的网站模型，模型图如下：
接着，Ben提出很重要的缓存象限，缓存象限图如下所示：
缓存最好的应用场景就是针对更改少、请求频繁的数据读写场景。
客户端缓存，首先需要面对的问题就是 “缓存数据滞后”
这部分演讲，Ben发散思维了所有Web服务器尝使用的“文件系统观察”功能。
随后，客户端缓存会出现“跨服务器缓存数据不一致”问题。
这种问题并不是只会在不同的机器间出现，还会在同一台机器不同进程中出现。
比如在两台机器针对缓存都设置了相同的TTL生命期，但是由于机器间时间可能不同步，从而造成缓存不一致情况。更坏的情况就是，数据已经更新了，但是客户端缓存没办法及时更新，造成用户请求到旧的数据，如果再多台机器负载的情况下，极有可能出现一会新值、一会旧值得问题，这种飘忽不定的缓存返回会造成用户较差的使用体验。
接下来，Ben提出一个很重要的时间观点，服务器间想在大约相同的时间内更新相关的key，这个大约相同的时间证明这个缓存方案并不一定能够满足分布式强一致，只是在合理的时间范围内数据一致。
接下来，Ben提出第三个缓存问题，“缓存踩踏”问题
这里所说的就是如果自己完全制作一个进程内缓存，有很多需要考虑，比如启动数据加载，数据池的备份，服务器扩容过程，等等问题。
Redis可以提供简单的缓存解决方案。
Redis缓存可以很好地解决缓存一致性问题，也可以解决缓存数据滞后问题，也不会有数据践踏。
但是redis也有一些其他问题，比如每次缓存获取都需要tcp往返通信，虽然redis已经很快了，但是本地内存的访问速度仍然比网络io速度高太多。
这里，Ben提出如果在redis基础上，再增加进程内缓存，效果就会更好了。
针对这种本地缓存方案，首先提出了三个需要做的事情：
解决数据一致性问题 解决数据滞后问题，主要围绕进程内缓存和远程redis之间的滞后问题 不要让网络爆炸，要控制合理的网络通信 借助redis，我们是不是可以更好的实现这个功能呢？
上面这部分讲述了一个问题，如果我们想让机器间的数据保证一致性，如果仅仅通过广播变更的key-value，这将是致命的，因为大量的key-value将引爆网络，还有一个原因就是你广播了key-value数据，并不是所有的节点以后都会使用，这就会造成效率问题，这些问题几乎都是围绕网络，但是还没考虑网络的质量问题，比如网络质量很差的情况下，节点可能收到多组不同的改动，这些改动可能会数据践踏，但是你不知道践踏的顺序，从而造成数据的不一致问题。
因此，我们并不是广播key-value，而是只广播key，但是你也知道redis支持key数据，最大可以达到512MB，就算不是512MB，就算是1kb的数据，我们的网络就能抗住吗，所以简单的广播key是不理智的。
redis集群中采用hash槽位来进行数据分片，那么我们是否可以借鉴这种思路呢？我们不再广播key，而是广播key所计算的hash值，这样如果key的数据多么大，我们都能控制在网络上传输的数据大小。
我们放弃了广播key，而选择同步16bit的key hash槽数据，这样操作的优势明显，首先广播数据的大小被控制了，并且解决了数据一致性问题，我们只是广播hash，并没有广播数据，当某个hash出现了脏数据，它将会在下次访问时被感知并被更新。这个也有一点缺陷需要注意，因为我们借助了hash槽位，所以一个hash slot上会包含很多key，这些key中的一个被更新，则这组hash slot都将失效。
计算遍历所有的 key 吗？命中脏 slots 的话，就删除这个key？但是这样的话相当于对每一个缓存更新操作，客户端都要遍历计算一遍自己所有 key 的 slot，显然是不可接受的。
这里也是采用惰性计算的思想：客户端收到了 slot 更新的广播，只把 slot 存起来，当真正用到在此 slot 中的 key 的时候才去 Redis 更新。那么就会有这样一种情况，slot 中部分 key 更新了，部分 key 没有更新，如何区分开哪些 key 已经在 slot 更新之后更新过了呢？这里只要记一下 slot 更新的 timestamp 就可以，每一个 key-value 也带有一个 timestamp 属性。如果 key 的 timestamp 早于 slot 的 timestamp，那 key 就是需要更新的；更新之后 key 的 timestamp 就晚于 slot 的 timestamp 了。下次可以直接用。</description></item><item><title>Redis哨兵-官方文档翻译</title><link>https://icorer.com/icorer_blog/posts/redis-sentinel-official-document-translation/</link><pubDate>Mon, 24 Feb 2020 22:36:18 +0800</pubDate><guid>https://icorer.com/icorer_blog/posts/redis-sentinel-official-document-translation/</guid><description>Sentinel概述Redis Sentinel为Redis提供高可用性。实际上，这意味着使用&amp;quot;哨兵&amp;quot;可以创建一个不需要人工干预就能抵抗某些类型失败的Redis部署。
Redis Sentinel还提供其他附属任务，如监控、通知和为客户提供配置。
这是宏观上（即全局）Sentinel功能的完整列表：
监视：Sentinel会不断检查你的主实例和副本实例是否按预期工作。 通知：Sentinel可以通过API通知系统管理员或其他计算机程序，其中一个被监控的Redis实例出了问题。 自动故障转移：如果一个主服务器没有按照预期工作，Sentinel可以启动一个故障转移过程，其中一个副本被提升到主服务器，其他附加的副本被重新配置以使用新的主服务器，使用Redis服务器的应用程序在连接时被告知要使用的新地址。 组态设定提供者：Sentinel充当客户端服务发现的授权来源：客户端连接到Sentinels，以询问负责给定服务的当前Redis主服务器的地址。 如果发生故障转移，Sentinels将报告新地址。 Sentinel的分布式性质Redis Sentinel是一个分布式系统：
哨兵本身被设计成在一个有多个协作的哨兵进程的配置中运行。有多个哨兵进程协作的好处如下:
当多个哨兵一致认为某个主节点不再可用时，就会执行故障检测。这降低了误报的概率。 即使不是所有的哨兵进程都在工作，哨兵也能工作，这使得系统对故障具有健壮性。毕竟，拥有一个本身就是单点故障的故障转移系统是毫无乐趣的。 哨兵、Redis实例(主实例和副本实例)和连接到哨兵和Redis的客户机的所有组成部分是一个更大的具有特定属性的分布式系统。在本文档中，将逐步介绍概念，从为了理解Sentinel的基本属性所需的基本信息，到为了理解哨兵的工作原理的更复杂的信息（可选）。
快速入门获得哨兵当前版本的Sentinel称为Sentinel 2。它是对最初的哨兵实现的重写，使用了更强大、更简单的预测算法(在本文档中有解释)。
自Redis 2.8起已发布稳定版本的Redis Sentinel。
在不稳定分支中进行了新的开发，并且有时新功能一旦被认为是稳定的，便会立即移植回最新的稳定分支。
Redis Sentinel版本1(随Redis 2.6一起发布)是不推荐使用的。
运行哨兵如果您正在使用redis-sentinel可执行文件(或者如果您有一个与redis-server可执行文件同名的符号链接)，您可以使用以下命令行运行Sentinel：
1redis-sentinel /path/to/sentinel.conf 否则，您可以直接使用redis-server可执行文件以Sentinel模式启动它：
1redis-server /path/to/sentinel.conf --sentinel 这两种方法的工作方式相同。
但是，在运行Sentinel时必须使用一个配置文件，因为系统会使用这个文件来保存在重新启动时要重新载入的当前状态。如果没有配置文件，或者配置文件路径不可写，Sentinel将拒绝启动。
哨兵默认情况下会监听TCP端口26379的连接，因此，为了使哨兵正常工作，必须打开服务器的端口26379，以接收来自其他哨兵实例的IP地址的连接。 否则，哨兵无法讨论也不能就该做什么达成共识，因此将永远不会执行故障转移。
部署哨兵前需要了解的基本内容 一个健壮的部署至少需要三个Sentinel实例。 应将三个哨兵实例放置到被认为以独立方式发生故障的计算机或虚拟机中。例如在不同的可用区域上执行的不同物理服务器或虚拟机。 Sentinel + Redis分布式系统不保证在故障期间保留已确认的写入，因为Redis使用异步复制。但是，有一些部署Sentinel的方法使窗口丢失写入仅限于某些时刻，而还有其他一些不太安全的方法来部署它。 您的客户需要Sentinel支持。 流行的客户端库具有Sentinel支持，但不是全部。 如果您不经常在开发环境中进行测试，那么就没有HA设置是安全的，如果您可以在生产环境中进行测试，如果它们能够工作，那就更好了。你可能有一个错误的配置，只有当它变得太晚(凌晨3点当master停止工作)才会变得明显。 Sentinel，Docker或其他形式的网络地址转换或端口映射应该小心混合：Docker执行端口重新映射，破坏了其他Sentinel进程的Sentinel自动发现以及主数据库的副本列表。有关更多信息，请参阅本文档后面有关Sentinel和Docker的部分。 配置哨兵edis源发行版包含一个名为Sentinel .conf的文件，它是一个自文档化的示例配置文件，您可以使用它来配置Sentinel，但是典型的最小配置文件，如下所示：
1sentinel monitor mymaster 127.0.0.1 6379 2 2sentinel down-after-milliseconds mymaster 60000 3sentinel failover-timeout mymaster 180000 4sentinel parallel-syncs mymaster 1 5 6sentinel monitor resque 192.</description></item><item><title>MKV-高性能分布式内存KV-开篇</title><link>https://icorer.com/icorer_blog/posts/mkv-high-performance-distributed-memory-kv-opening/</link><pubDate>Wed, 19 Feb 2020 11:43:18 +0800</pubDate><guid>https://icorer.com/icorer_blog/posts/mkv-high-performance-distributed-memory-kv-opening/</guid><description>一. 背景描述目前缓存环境中，使用较多的是Redis缓存，但是Redis单线程机制，在特高并发场景中还是能达到吞吐瓶颈，又由于很多大数据应用场景需要单次GET 1000或者更多的key，所以直接打到Redis服务器上，很容易让Redis主线程出现阻塞情况，产生吞吐大大下降的情况。
在这样的情况下，我们就设想架构设计一个分布式内存的缓存系统（MKV），主要设计目标包括一下：
多线程机制保障多核使用，提高云服务器的CPU使用率。 实现高性能、并发安全、存储具备数据完整性的内存缓存存储，支撑单次1000以上的key获取操作。 支持Redis-RESP应用层协议，由于大部分业务方使用redis缓存，尽量避免缓存切换带来的系统调整成本。 服务可用性达到99.99% 支持分布式场景不是和使用。 等等。。。 二. 模型试验由于团队一直在研究Redis内核及其通信协议，因此我们首先需要对多线程版本的缓存MKV 进行模型实验，证明猜想的有效性。
于是，我们分别针对官方Redis内核 和 我们目前的多线程版本缓存KV组件 - MKV进行性能测试对比。
2.1 测试环境我们的测试在下面的环境中进行：
Linux 5.0.0 Kernel Intel(R) Core(TM) i7-8550U CPU @ 1.80GHz [4核] 16GB内存 单次请求 ：1000 个key 使用Redis官方 redis-benchmark 工具进行压测 2.2 Redis 官方版本压测【SET: 85w/s GET: 105w/s 】1redis-benchmark -p 6379 -t get -n 5000000 -P 1000 -c 10 压测结果如下：
1====== SET ====== 2 10000000 requests completed in 11.75 seconds 3 10 parallel clients 4 3 bytes payload 5 keep alive: 1 6 70.</description></item></channel></rss>