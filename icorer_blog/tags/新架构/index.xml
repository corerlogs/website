<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>新架构 on 笔迹-工匠之芯</title><link>https://icorer.com/icorer_blog/tags/%E6%96%B0%E6%9E%B6%E6%9E%84/</link><description>Recent content in 新架构 on 笔迹-工匠之芯</description><generator>Hugo -- gohugo.io</generator><language>zh-cn</language><lastBuildDate>Sat, 29 Jul 2023 22:15:12 +0800</lastBuildDate><atom:link href="https://icorer.com/icorer_blog/tags/%E6%96%B0%E6%9E%B6%E6%9E%84/index.xml" rel="self" type="application/rss+xml"/><item><title>Fleek Network：去中心化边缘平台</title><link>https://icorer.com/icorer_blog/posts/web3/fleek-network/</link><pubDate>Sat, 29 Jul 2023 22:15:12 +0800</pubDate><guid>https://icorer.com/icorer_blog/posts/web3/fleek-network/</guid><description>概要 背景：网络的演变 现代Web堆栈的演变 Web3 的模块化和可组合式演变 将现代 Web 引入 Web3 Fleek Network：去中心化边缘平台 关键概念和性能优化 地理意识 智能路由&amp;amp;工作分配 无状态执行 无虚拟机 核心 （VM-Less Core） 内置（外部可扩展）文件系统 内容可寻址核心 增量内容检索和验证 Fleek网络：协议 简洁链状态 Narwhal &amp;amp; Bullshark 共识 Delivery Acknowledgement SNARKs 基于绩效的声誉 Fleek Network: Services SDK 与Service交互 节点分配&amp;amp;洗牌 资源&amp;amp;商品 服务示例：边缘计算 在Fleek Network建设: Who, What &amp;amp; Why 构建/使用服务的想法 网络/边缘服务 Web 3 服务的特定用例 去中心化CDN 去中心化网站/应用程序托管 去中心化 IPFS Pinning 去中心化边缘计算（基于 Web3 协议） 区块链快照即服务 zkVM、EVM 和其他 VM 作为服务 替代Rollup Sequencer 临时Rollups 边缘证明生成 验证随机性 Web3 查询/事件 参考 附录A: 绩效信誉算法 概要Fleek Network 是一个去中心化边缘平台，经过优化，可促进高性能 Web 服务（CDN、无服务器功能等）的部署和运行。Fleek Network的全球分布式、自主控制的边缘节点网络使开发者可以轻松创建和利用多种边缘服务。这些服务继承了加密且经济安全的基础设施，保障节点和地理范围覆盖、稳定且可预测的成本、以及网络上运行的所有服务的一致质量和性能。Fleek Network的目标是提供一个平台，所有Web3协议、中间件、服务和应用程序都可以从中受益，以进一步分散其堆栈，而无需牺牲成本、性能、复杂性或开发人员/终端用户体验。</description></item><item><title>Tendermint ABCI分布式KV存储引擎分析</title><link>https://icorer.com/icorer_blog/posts/web3/tendermint-distributed-kv-storage-engine-analysis/</link><pubDate>Tue, 23 May 2023 21:25:16 +0800</pubDate><guid>https://icorer.com/icorer_blog/posts/web3/tendermint-distributed-kv-storage-engine-analysis/</guid><description>背景介绍 1.Tendermint KV 模块分析 1.1 ABCI应用拦截Tendermint状态机 1.2 ABCI应用Application结构体分析 1.3 ABCI应用处理Tendermint 区块Deliver事务 1.4 ABCI应用处理Tendermint 区块Commit事务 1.5 ABCI应用处理Tendermint 区块Query事务 1.6 ABCI应用处理Tendermint 区块Check事务 1.7 KV存储引擎状态处理 2.Tendermint KV运行实践 2.1 安装Tendermint 2.1.1 二进制安装 2.1.3 源代码安装 2.1.3 运行Tendermint 2.1.4 重新安装 2.2 Tendermint KV编译及运行 2.3 Tendermint KV 运行测试 2.3.1 Tendermint Core RPC 交易广播 2.3.2 Tendermint Core RPC 查询广播 3.总结 附录 背景介绍Tendermint 是一个基于共识算法的分布式系统，它提供了一种在去中心化环境下实现可靠、安全、高效的数据存储和交互的方法。在这个环境中，一个分布式 KV 存储引擎是非常有用的，它可以让不同的节点在共享一个数据集合的同时保持数据的一致性和可靠性。
Tendermint 为分布式 KV 存储引擎提供了一些核心组件，其中最重要的是 ABCI（Application Blockchain Interface）接口和 KV 存储引擎。ABCI 接口定义了应用程序和 Tendermint Core 之间的交互协议，它规定了应用程序需要实现哪些方法以处理交易、查询和状态更改。Tendermint开源的 ts-db存储引擎则提供了一个标准的键值存储接口，可以将数据持久化到磁盘中，同时支持可插拔的存储引擎（例如 LevelDB、RocksDB 等）。</description></item><item><title>EIP-4844改进提议：分片Blob事务</title><link>https://icorer.com/icorer_blog/posts/web3/eip-4844-reduced-l2-fees/</link><pubDate>Mon, 27 Feb 2023 23:35:16 +0800</pubDate><guid>https://icorer.com/icorer_blog/posts/web3/eip-4844-reduced-l2-fees/</guid><description>EIP-4844 分片Blob事务以简单、向前兼容的方式扩展以太坊的数据可用性。
一、摘要 二、动机 三、Specification 规范 3.1 Parameters 参数 3.2 Type aliases 类型别名 3.3 Cryptographic Helpers 加密助手 3.4 Helpers 3.5 New transaction type 新的交易类型 3.6 Header extension 头扩展 3.7 Beacon chain validation 信标链验证 3.8 Opcode to get versioned hashes 获取版本哈希的操作码 3.9 Point evaluation precompile 点评估预编译 3.10 Gas accounting 3.11 Networking 网络 四、基本原理 4.1 On the path to sharding 在分片的路上 4.2 How rollups would function 4.3 Versioned hashes &amp;amp; precompile return data 版本化哈希和预编译返回数据 4.</description></item><item><title>SBT vs SSI：Web3对数字身份解决方案的探索</title><link>https://icorer.com/icorer_blog/posts/web3/soulbound-tokens-vs-self-sovereign-identity/</link><pubDate>Wed, 14 Dec 2022 11:55:18 +0800</pubDate><guid>https://icorer.com/icorer_blog/posts/web3/soulbound-tokens-vs-self-sovereign-identity/</guid><description>在题为“去中心化社会:寻找Web 3的灵魂”的研究论文中，以太坊(ETH)的联合创始人Vitalik Buterin 与 Glen Weyl、Puja Ahluwalia Ohlhaver 一起，介绍了“灵魂绑定令牌”(SBTs)的概念，作为对数字身份的一种全新看法。这篇文章谈到了数字身份在Web3中的重要性，以及满足Web3的高度金融化，建立同等数量的信任和社会关系的重要性。
然而，我们不禁注意到SBTs的用例与自我主权身份(SSI)所做的是多么接近。SSI已经在为创造一个可信的社会铺平道路。我们想比较Vitalik等人的灵魂绑定令牌假说和SSI，看看当我们进入Web3时，哪一个最有效。
在其最简单的形式中，灵魂绑定令牌是可以在数字钱包中显示的不可转移的可替换令牌。这些代币是由一个灵魂(个体)发给另一个灵魂的。他们不能和任何人交易。一旦获得一个SBT，它就被绑定到那个人身上，因此得名soulbound。
SSI使用数据发布者、验证者和持有者之间的关系来创建一个以用户为中心的模型。在这种模式下，持有者可以选择与验证者共享他们需要的确切信息(而不是更多)。然后，验证者可以将信息与发行者的签名(有时存储在区块链上)进行交叉引用，以确保持有人的数据是有效的。
SBT的吸引力在于它们的不可转让性，它们与接受者绑定在一起。它们可以用于代表其所有者声明凭证和形成在线身份。类似于一组徽章，您可以有多个SBT用于各种凭证，从驾驶执照到代表音乐会门票的令牌。
另一方面，SSI 的不同之处在于它们的默认可见性是私有的和账本外的，而 SBT 默认是公开的和账本上的。SSI侧重于允许用户控制他们的数据，并将发布的文档保存在私人数字钱包中，默认的隐私模式让持有者对他们的个人数据以及如何访问这些数据有更多的控制权。
SBT vs NFT vs SSI 作为一种身份解决方案，SBT 的功能类似于不可替代令牌 ( NFT )。关键区别在于它们缺乏可转移性。SBT 现在正在建设中，但面临一个关键障碍：隐私。
SBT 是 Web3 中表达自我的一种方式，类似于加密货币和 NFT 的所有权。然而，他们可以将现代面临的许多当前身份问题复制到一个新的公共和不可变平台上，这是 SBT 的主要缺点。
围绕SBTs的建立存在紧张关系，一些人担心它可能会建立一个公共的社会价值体系，类似于中国的社会信用体系。有人担心，如果被广泛采用，我们在现实世界中取得的成就和犯下的错误可能等同于与该行动相关的SBT。这将为你的每一项成就和犯下的每一个错误建立一个终身的账本，没有交易功能。
从这个意义上说，SBT不能避免人为错误；发行人有可能将SBT发送给不正确的持有人，这可能会导致许多隐私问题。已经有一个案例，一个人创造了一个“混蛋SBT”，一个令牌，使用与NFT相同的技术，但可以被发送给一个人，然后他只能通过支付费用来删除它。SBTs的这一方面有可能造成巨大的伤害，并可能贬低Web3的灵魂。
SSI 的存在是为了解决当前在以数字为中心的社会中面临的关键身份问题。通过创建一个用户控制他们的数据并有权将其发送给他们希望的任何人的系统，我们开始促进真正的数据所有权成为一种社会规范。公司和个人之间的数据交易可以像消息传递一样简单。通过不建立固有的面向公众的身份系统，SSI 可以解决数据盗窃和中心化数据孤岛的问题，而发行人和持有人之间没有任何歧义。
SBTs是建立在预先存在的Web3概念上的，比如NFT，这为社区采用它们提供了一条强有力的途径，特别是因为开发人员已经习惯了这种工具。然而，随着社区开始理解SBTs的公共性质以及由此产生的隐私问题(例如，在线行为的可追溯性)，他们将开始寻找保护隐私的替代方案。
另一方面，SSI近年来受到大学的青睐，并在管理机构中拥有强大的市场，特别是考虑到最近发生的事件，如新冠肺炎。对SSI的兴趣已经开始增长，欧盟委员会提议所有欧洲人都应该拥有一个安全的数字身份。这种政府采用水平将有利于SSI进一步扩展到教育和医疗保健等全球关键领域。
SBTs和SSI都因解决了Web3当前的身份混乱而获得公众关注。SBT寻求利用社区对NFT的熟悉程度来确保快速无缝的采用。然而，SSI希望通过专注于隐私的技术来解决这些问题，这项技术是经过多年研究开发出来的。尽管如此，这两个系统都有潜力为我们的数字生活增加价值。尽管如此，SSI是唯一一个足够深入地解决身份和隐私问题的方案，让Web3真正被大众接受，并将我们置于我们自己生态系统的中心。
了解更多 Ethereum&amp;rsquo;s Vitalik Buterin Lists &amp;lsquo;Worthwhile&amp;rsquo; Ideas for Developers to Work On
6 Key Points in Vitalik Buterin&amp;rsquo;s Vision for Ethereum Presented at EthCC These Are Some Topics Ethereum Developers Disagree With Vitalik Buterin On</description></item><item><title>身份验证世界中的自主身份：架构和领域用例</title><link>https://icorer.com/icorer_blog/posts/web3/self-sovereign-identity-in-a-world-of-authenticationarchitecture-and-domain-usecases/</link><pubDate>Tue, 13 Dec 2022 11:55:18 +0800</pubDate><guid>https://icorer.com/icorer_blog/posts/web3/self-sovereign-identity-in-a-world-of-authenticationarchitecture-and-domain-usecases/</guid><description>摘要自我主权身份 (SSI) 预计将以某种形式成为每个人生活的一部分。在与第三方组织打交道时，验证和验证一个人是否是他们声称的真实人物的能力以及保护个人属性的能力可能会产生广泛的影响。利用区块链和其他去中心化技术，SSI 是一个不断发展的研究领域。在去中心化结构中保护个人信息的方面可能对公共和私营部门有益。
在本文中，我们描述了 SSI 框架架构以及跨领域（如医疗保健、金融、零售和政府）的可能用例。该论文还将 SSI 及其去中心化架构与当前广泛采用的公钥基础设施 (PKI) 模型进行了对比。
1.介绍在数字领域有目的地验证您的身份的能力是大多数（如果不是全部）在线活动的基础。我们根据妥协对我们生活的负面影响，在不同级别保护这种在线身份。随着我们生活中越来越多的时间在网上进行交易，人们在管理数字身份的方式上也越来越精明。对所有帐户使用相同的“简单”密码曾经是一种常见的做法。现在这被视为灾难的根源，知道如果一个在线帐户被泄露，那么您的所有帐户都可能暴露 [1]。组织正在帮助用户转向需要多因素身份验证和更强密码的更安全的在线身份实践。这些步骤极大地提高了在线身份安全性，但标准在线身份管理系统的架构本质上是不安全的。区块链和去中心化身份的发展促成了自我主权身份 (SSI) 框架的创建。 SSI 框架在许多领域都有巨大的实现可能性，在这些领域中存在对个人隐私的驱动 [2]。
这些框架的开发旨在提高用户个人身份信息 (PII) 的整体安全性。 PII 的示例包括用户姓名、地址、护照号码、驾照号码、纳税人识别号码、患者识别号码、财务记录等。个人健康信息 (PHI) 是最受追捧的信息之一，黑客在 PII 之后，主要原因是医疗保健中使用的身份与社会安全号码 (SSN) 相关联，而社会安全号码对于个人来说永远不会改变 [3]。组织使用其他 PHI（例如家庭住址和电话号码）来确定身份可能会发生变化。使用窃取的 PHI 进行冒充会使个人陷入可能导致严重经济损失的境地。 SSI 在医疗保健行业的使用可以帮助保护用户数据并限制患者 PHI 的扩散。使用 SSI 模型的医疗保健提供者只有在获得患者批准/许可的情况下才能访问患者 PHI。
与公钥基础设施 (PKI) 类似，SSI 使用非对称密钥作为加密体系结构以及数字签名来确保对等方之间的安全通信 [4]。 PKI 利用一组中央机构来存储身份、证书和公共加密密钥的关联数据库。相反，SSI 使用去中心化账本技术 (DLT) 来关联去中心化标识符 (DID) 和公共加密密钥。在 SSI 实现中，DID 及其对称密钥对的公共部分是唯一可公开访问的与实体相关的信息。该实体保留他们认为合适时共享的身份信息详细信息。
本文描述了 SSI 体系结构及其主要组件，以及 PKI 和 SSI 中使用的机制之间的比较。我们还研究了如何在医疗保健、金融、零售和政府等不同领域利用 SSI，在这些领域中需要身份验证和数据安全，并且在某些情况下是法规要求的
本文介绍的架构是一个利用区块链、去中心化身份 (DID) 以及其他去中心化和加密技术的身份框架。该框架侧重于个人身份的自我主权理念。自我主权可以定义为可以控制自己身份的细节。这包括用户能够根据信息的预期接收者共享特定身份属性和获得的凭证的能力。用户将向接收者提供一个配置文件，其中该配置文件仅包括接收者为特定操作所需的那些身份详细信息。
SSI 架构的主要目标是实现 CIA 三元组；机密性、完整性和可用性。其他框架通过依赖于不同结构的不同架构技术来实现这些目标。提出的框架优先考虑信息安全和用户访问控制。</description></item><item><title>Self-Sovereign Identity：什么是自我主权身份？</title><link>https://icorer.com/icorer_blog/posts/web3/what-is-self-sovereign-identity/</link><pubDate>Mon, 12 Dec 2022 11:55:18 +0800</pubDate><guid>https://icorer.com/icorer_blog/posts/web3/what-is-self-sovereign-identity/</guid><description>如今，我们日常生活的许多方面都依赖数字服务，从在线购物到所谓的 Web2.0 中的金融服务。我们使用多个（如果不是数百个）帐户与不同的集中式网络平台（例如社交媒体或电子邮件服务）进行交互。问题是，当我们无法访问我们的帐户时，我们就会失去我们的数字身份，因为网站无法再识别我们是谁。这意味着我们实际上并不拥有我们的身份和数据。这有问题。我们需要收回数据和数字身份的所有权，而自主身份可以实现这一点，为我们进入 Web3.0 铺平道路。
自我主权身份是指一种让个人控制其数字身份的方法。自我主权身份 (SSI) 是一项运动，它声称数字身份应该与一个人的人类身份一样合法，同时所有人都可以访问、保护隐私并且不依赖于单一的政府或公司。
那么究竟什么是自我主权身份呢？自我主权身份是指一种让个人控制其数字身份的方法。为了更好地理解这个概念，让我们看一下两个模型：
Web 2.0 - 集中式模型我们的电子邮件帐户、网站帐户和社交媒体帐户目前允许数字服务在线识别我们。我们要么为每个平台创建一个帐户，要么使用 Facebook 或 Google 等服务提供商提供的单点登录。无论我们使用哪种方法，我们的数据都由帐户提供商集中存储。这种模式产生了一些严重的问题：
管理困难：我们努力管理众多帐户以访问不同的数字平台。此外，这些平台可以单方面决定关闭我们的帐户，或代表我们管理它。
安全和依赖风险：由于我们的大多数帐户都与我们的电子邮件地址相关联，如果我们的电子邮件访问受到威胁，黑客可以通过“忘记我的密码”方法更改密码来轻松接管使用该电子邮件的其他帐户。例如，黑客可以伪装成数字化的你，并在 Facebook 上欺骗你的家人和朋友。
隐私的脆弱性：如果我们使用的服务被黑客入侵，我们的数据很可能会被泄露，因为它是集中存储的。根据身份盗窃研究中心的数据，到 2021 年 10 月，将近 2.815 亿人受到某种数据泄露的影响。
缺乏数据自主权：我们无法控制我们的数据如何被使用或与其他平台共享。更糟糕的是，这些数据是代表我们的身份。
Web 3.0 - 去中心化模型为了克服中心化身份模型的上述所有问题，我们需要引入去中心化身份模型，从而实现自我主权身份。个人与对应方（例如个人、组织或物联网）之间的关系是点对点的。它不再依赖中心化的实体，而是利用去中心化的网络，即区块链技术。这种方法的一些好处：
弹性网络：区块链网络永远不会宕机，而集中式网络由公司运营。 可验证凭证：数据和信息由身份所有者选择的受信任方（例如政府和银行）作为凭证发布。如果授予访问权限，其他节点可以验证链上的凭证。 建立信任：不变性是区块链的本质，它确保了可验证凭证的真实性。例如，同行可以通过链上证明来验证文凭是否由大学颁发。 控制数据：自主身份的所有者可以决定何时共享凭据，以及共享哪些凭据。 自我主权身份是一种以用户为中心的数字身份，我们作为用户可以完全控制我们的在线身份，但它不仅适用于个人，也适用于组织甚至设备 (IoT) 或程序。我们相信在不久的将来，我们都将使用自主身份在数字世界中进行点对点交互，而不是依赖于其他方基于账户的数字身份。
身份类型 真实身份人类身份是一个复杂的话题，几个世纪以来哲学家们一直在争论这个问题，而我所说的任何话都无法解决这些争论。我将人的身份简化为两部分，这两部分对于一个人成为社会上有生产力的成员来说都是必不可少的。
内在同一性：这就是我们照镜子时所看到的。这是我们的性别认同、政治认同或文化认同。在我们与最亲密的知己的关系中，这就是我们的身份。它是我们固有的，是身份的最真实形式。
外在身份：这是其他人（通常是机构）识别我们的方式。驾照是最普遍的例子。虽然旨在证明您有资格在公共道路上行驶，但它也是金融机构、机场和酒吧识别您的方式。它之所以有效，是因为机构信任，并且有了驾照，您始终可以得到担保。而且它不仅限于政府、教育、专业和会员凭证都以同样的方式工作。
数字身份一些最大的社交媒体、博客和其他互联网平台的存在基本上是为了帮助人们表达他们内在的身份。但是（值得注意的是）仍然没有很好的方法来数字化管理我们的外在身份。我们仍然使用纸质文件和塑料卡来访问我们生活中一些最重要的服务，使我们身份的一些最敏感和最重要的方面受到欺诈。令人恐惧的是，在日益数字化的世界中，我们有时必须扫描、通过电子邮件发送或发送这些文件的照片才能完成一些基本的事情，例如获得购房资格或开设银行账户。
自我主权身份自我主权身份是真实身份与数字世界的结合，最终将使人们的生活更美好。它仍处于起步阶段，要真正使数字身份像现实世界一样合法，还有很长的路要走身份。但最近有几项非常有前途的技术进步代表了巨大的突破，其中最重要的是数字钱包的出现和可验证凭证的标准化，这些共同创造了一条首次将我们的外在身份在线化的途径。
技术组成 SSI 架构由 W3C 定义的七项关键技术组成。这七项技术是：
去中心化标识符：Decentralized Identifiers 可验证凭证：Verifiable Credentials 去中心化公钥基础设施：Decentralized Public Key Infrastructure 区块链和分布式账本技术：Blockchain and Distributed Ledger Technology 可验证数据注册表：Verifiable Data Registry 代理程序：Agents 数字钱包：Digital Wallets 接下来详细描述每一个组成部分：</description></item><item><title>Drand去中心化可验证随机数</title><link>https://icorer.com/icorer_blog/posts/web3/verifiable-random-number-drand-program-experiment/</link><pubDate>Thu, 08 Dec 2022 11:55:18 +0800</pubDate><guid>https://icorer.com/icorer_blog/posts/web3/verifiable-random-number-drand-program-experiment/</guid><description>Drand最初来自DEDIS实验室，由于使用基于配对的密码学，drand 能够以非常简单和有效的方式生成随机性，并以可靠的方式将其交付给客户端。Drand 旨在成为一种分布式服务，以与应用程序无关、安全且高效的方式提供公共随机性。随着 drand 的成熟，越来越多的组织（包括 NIST、Cloudflare、Kudelski Security、智利大学和协议实验室）开始感兴趣，并决定共同努力建立一个跨越这些组织的 drand 网络。
Drand 旨在成为一种互联网基础设施级服务，为应用程序提供随机性，类似于 NTP 提供计时信息和证书透明服务器提供证书吊销信息的方式，Drand去中心化随机数方案可以提供 去中心化随机性与可验证性两大核心功能。
为什么去中心化随机性很重要多年来，一代公共随机性(通常称为common coins)吸引了密码学研究社区的持续兴趣。许多分布式系统，包括各种共识机制、Tor等匿名网络或区块链系统，都假定可以访问这种公共随机性。例如，在最近的权益证明区块链中，矿工在每个时期都是通过一个共同的随机源随机选出的。然而，拥有一个不可偏置的、分布式的、可扩展的公共随机资源仍然是一个主要的缺失部分。目前存在一些集中式解决方案，尽管它们确实提供了一个统一的随机性来源，但这些信标既不可验证也不分散。可验证性是必要的。对于权益证明系统中的示例，可验证性是必要的，在该系统中，区块生产者需要证明他已被选为给定时期的矿工。
实验代码 1 2package main 3 4import ( 5 &amp;#34;context&amp;#34; 6 &amp;#34;encoding/hex&amp;#34; 7 &amp;#34;log&amp;#34; 8 &amp;#34;time&amp;#34; 9 10 &amp;#34;github.com/drand/drand/client&amp;#34; 11 &amp;#34;github.com/drand/drand/client/http&amp;#34; 12) 13 14var urls = []string{ 15 &amp;#34;https://api.drand.sh&amp;#34;, 16 &amp;#34;https://drand.cloudflare.com&amp;#34;, 17} 18 19var chainHash, _ = hex.DecodeString(&amp;#34;8990e7a9aaed2ffed73dbd7092123d6f289930540d7651336225dc172e51b2ce&amp;#34;) 20 21func main() { 22 c, err := client.New( 23 client.From(http.ForURLs(urls, chainHash)...), 24 client.WithChainHash(chainHash), 25 ) 26 27 if err !</description></item><item><title>Gorilla：一个快速、可伸缩的内存时间序列数据库</title><link>https://icorer.com/icorer_blog/posts/gorilladb/</link><pubDate>Fri, 01 Apr 2022 17:26:18 +0800</pubDate><guid>https://icorer.com/icorer_blog/posts/gorilladb/</guid><description>摘要大规模互联网服务旨在出现意外故障时保持高可用性和高响应性。提供这种服务通常需要在大量系统上每秒钟监测和分析数千万次测量，一个特别有效的解决方案是在时间序列数据库(TSDB)中存储和查询这种测量。TSDB设计中的一个关键挑战是如何在效率、可伸缩性和可靠性之间取得平衡。在本文中，我们介绍Gorilla系统，脸书的内存TSDB。我们的见解是，监控系统的用户不太重视单个数据点，而是更重视综合分析，对于快速检测和诊断持续问题的根本原因而言，最新数据点比旧数据点更有价值。Gorilla优化了写入和读取的高可用性，即使在出现故障时也是如此，代价是可能会在写入路径上丢弃少量数据。为了提高查询效率，我们积极利用压缩技术，如增量时间戳和异或浮点值，将Gorilla的存储空间减少了10倍。这使我们能够将Gorilla的数据存储在内存中，与传统数据库(HBase)支持的时间序列数据相比，查询延迟减少了73倍，查询吞吐量提高了14倍。这种性能改进带来了新的监控和调试工具，比如时序关联搜索和更密集的可视化工具。Gorilla还可以优雅地处理从单个节点到整个区域的故障，几乎没有运营开销。
一、介绍大规模互联网服务即使在出现意外故障的情况下也能保持高可用性和对用户的响应。随着这些服务发展到支持全球客户，它们已经从运行在数百台机器上的几个系统扩展到服务数以千计的个人用户系统运行在数千台机器上，通常跨越多个地理复制的数据中心。
运行这些大规模服务的一个重要要求是准确监控底层系统的健康和性能，并在出现问题时快速识别和诊断问题。脸书使用时间序列数据库(TSDB)存储系统测量数据点，并在顶部提供快速查询功能。接下来，我们将指定监控和操作脸书需要满足的一些约束，然后描述Gorilla，这是我们新的内存TSDB，可以存储数千万个数据点(例如，CPU 负载、错误率、延迟等)。)并在几毫秒内响应对此数据的查询。
写占主导地位。我们对 TSDB 的主要要求是它应该始终可用于写入。由于我们有数百个公开数据项的系统，写入速率可能很容易超过每秒数千万个数据点。相比之下，读取速率通常要低几个数量级，因为它主要来自于观察“重要”时间序列数据的自动化系统、可视化系统或为希望诊断观察到问题的人类操作员提供仪表板。
状态转换。我们希望识别新软件发布中出现的问题、配置更改的意外副作用、网络中断以及导致重大状态转换的其他问题。因此，我们希望我们的TSDB支持短时间窗口内的细粒度聚合。在几十秒钟内显示状态转换的能力特别有价值，因为它允许自动化在问题变得广泛传播之前快速修复问题。
高可用性。即使网络分区或其他故障导致不同数据中心之间的连接断开，在任何给定数据中心内运行的系统都应该能够将数据写入本地TSDB机器，并且能够按需检索这些数据。
容错。我们希望将所有写入复制到多个区域，这样我们就可以在任何给定的数据中心或地理区域因灾难而丢失时幸存下来。
Gorilla是脸书的新TSDB，满足了这些限制。Gorilla用作进入监控系统的最新数据的直写缓存。我们的目标是确保大多数查询在几十毫秒内运行。Gorilla 的设计理念是，监控系统的用户不太重视单个数据点，而是更重视综合分析。此外，这些系统不存储任何用户数据，因此传统的 ACID保证不是TSDB的核心要求。 但是，高比例的写入必须始终成功，即使面临可能导致整个数据中心无法访问的灾难。此外，最近的数据点比旧的数据点具有更高的价值，因为直觉上，对于运营工程师来说，知道特定系统或服务现在是否被破坏比知道它是否在一个小时前被破坏更有价值，Gorilla 进行了优化，即使在出现故障的情况下也能保持高度的读写可用性，代价是可能会丢失少量数据写入路径。
高数据插入率、总数据量、实时聚合和可靠性要求带来了挑战。我们依次解决了这些问题。为了解决第一个要求，我们分析了 TSDB 操作数据存储(ODS),这是一个在脸书广泛使用的老的监控系统。我们注意到，对ODS的所有查询中，至少有85%是针对过去26小时内收集的数据。进一步的分析使我们能够确定，如果我们能够用内存中的数据库替换基于磁盘的数据库，我们可能能够为我们的用户提供最好的服务。此外，通过将这个内存中的数据库视为持久的基于磁盘的存储的缓存，我们可以实现具有基于磁盘的数据库的持久性的内存中系统的插入速度。
截至2015年春天，脸书的监控系统生成了超过20亿个独特的时间序列计数器，每秒钟增加约1200万个数据点。这代表每天超过1万亿个点。在每点16字节的情况下，产生的16TBRAM对于实际部署来说太耗费资源了。我们通过重新利用现有的基于XOR的浮点压缩方案来解决这一问题，使其以流的方式工作，从而允许我们将时间序列压缩到平均每点1.37字节，大小减少了12倍。
我们通过在不同的数据中心区域运行多个Gorilla实例并向每个实例传输数据流来满足可靠性要求，而不试图保证一致性。读取查询指向最近的可用Gorilla实例。请注意，这种设计利用了我们的观察，即在不影响数据聚合的情况下，单个数据点可能会丢失，除非Gorilla实例之间存在显著差异。Gorilla目前正在脸书的生产中运行，工程师们每天将其用于实时灭火和调试，并与Hive[27]和Scuba[3]等其他监控和分析系统结合使用，以检测和诊断问题。
二、背景和要求2.1 操作数据存储脸书的大型基础设施由分布在多个数据中心的数百个系统组成，如果没有能够跟踪其运行状况和性能的监控系统，运营和管理这些基础设施将会非常困难。业务数据储存库是脸书监测系统的一个重要部分。ODS由一个时间序列数据库(TSDB)、一个查询服务以及一个探测和警报系统组成。ODS的TSDB 构建在 HBase存储系统之上，如[26]中所述。图1显示了ODS组织方式的高级视图。来自运行在脸书主机上的服务的时间序列数据由ODS写入服务收集并写入 HBase。
ODS时间序列数据有两个消费者。第一个消费者是依赖制图系统的工程师，该系统从ODS生成图形和其他时间序列数据的直观表示，用于交互式分析。第二个消费者是我们的自动警报系统，该系统从 ODS读取计数器，将它们与健康、性能和诊断指标的预设阈值进行比较，并向oncall工程师和自动补救系统发出警报。
2.1.1 监控系统读取性能问题2013 年初，脸书的监控团队意识到其HBase时序存储系统无法扩展处理未来的读取负载。虽然交互式图表的平均读取延迟是可以接受的，但是P90的查询时间增加到了几秒钟，阻碍了我们的自动化。此外，用户正在自我审查他们的用户年龄，因为即使是几千个时间序列的中等规模查询的交互式分析也需要几十秒钟才能执行。在稀疏数据集上执行的较大查询会超时，因为HBase数据存储被调整为优先写入。虽然我们基于HBase的TSDB效率低下，但我们很快就对存储系统进行了大规模更换，因为 ODS的HBase存储拥有大约2PB 的数据[5]。脸书的数据仓库解决方案Hive也不合适，因为它的查询延迟比ODS 高几个数量级，而查询延迟和效率是我们主要关心的问题[27]。
接下来，我们将注意力转向内存缓存。ODS已经使用了一个简单的通读缓存，但它主要是针对多个仪表板共享相同时间序列的图表系统。一个特别困难的场景是当仪表板查询最近的数据点，在缓存中错过，然后发出请求直接发送到 HBase 数据存储。我们还考虑了基于独立Memcache[20]的直写缓存，但拒绝了它，因为向现有时间序列添加新数据需要一个读/写周期，从而导致Memcache服务器的流量非常高。我们需要更有效的解决方案。
2.2 Gorilla要求考虑到这些因素，我们确定了新服务的以下要求:
由一个字符串键标识的20亿个唯一的时间序列。 每分钟增加7亿个数据点(时间戳和值)。 存储数据26小时。 峰值时每秒超过40,000次查询。 读取在不到一毫秒的时间内成功。 支持15秒粒度的时间序列(每个时间序列每分钟 4 个点)。 两个内存中、不在同一位置的副本(用于灾难恢复容量)。 即使单个服务器崩溃，也始终提供读取服务。 能够快速扫描所有内存中的数据。 支持每年至少2倍的增长。 在第3节与其他 TSDB 系统进行简单比较后，我们在第4节详细介绍Gorilla的实现，首先在第4.1 节讨论其新的时间戳和数据值压缩方案。然后，我们将在第 4.4 节中描述Gorilla如何在单节点故障和区域性灾难的情况下保持高可用性。我们将在第5节描述Gorilla如何启用新工具。最后，我们在第6节描述了我们开发和部署Gorilla的经验。
三、与 TSDB 系统的比较有许多出版物详细介绍了数据挖掘技术，以有效地搜索、分类和聚类大量的时间序列数据[8,23,24]。这些系统展示了检查时间序列数据的许多用途，从聚类和分类[8,23]到异常检测[10,16] 到索引时间序列[9,12,24]。然而，很少有例子详细说明能够实时收集和存储大量时间序列数据的系统。Gorilla的设计侧重于对生产系统进行可靠的实时监控，与其他TSDB相比非常突出。Gorilla占据了一个有趣的设计空间，在面对优先于任何旧数据可用性的故障时，可用于读取和写入。
由于 Gorilla 从一开始就被设计为将所有数据存储在内存中，因此它的内存结构也不同于现有TSDB。但是，如果将Gorilla视为另一个磁盘上TSDB之前的时间序列数据内存存储的中间存储，那么Gorilla 可以用作任何 TSDB 的直写缓存(相对简单的修改)。Gorilla对摄取速度和水平扩展的关注与现有解决方案相似。
3.1 OpenTSDBOpenTSDB基于HBase[28]，非常接近我们用于长期数据的ODS HBase存储层。这两个系统依赖于相似的表结构，并且在优化和水平可伸缩性方面得出了相似的结论[26,28]。然而，我们发现支持构建高级监控工具所需的查询量需要比基于磁盘的存储所能支持的更快的查询。
与OpenTSDB不同，ODS HBase层确实为较旧的数据进行时间累积聚合以节省空间。这导致较旧的存档数据与ODS中较新的数据相比具有较低的时间粒度，而OpenTSDB将永远保留全分辨率数据。我们发现，更便宜的长时间查询和空间节省是值得的精度损失。</description></item></channel></rss>